{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import foolbox\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from lib.dataset_utils import *\n",
    "from lib.cifar_resnet import *\n",
    "from lib.adv_model import *\n",
    "from lib.dknn_attack import DKNNAttack\n",
    "from lib.cwl2_attack import CWL2Attack\n",
    "from lib.dknn import DKNN, DKNNL2\n",
    "from lib.utils import *\n",
    "from lib.lip_model import *\n",
    "from lib.knn import *\n",
    "from lib.nin import *\n",
    "from lib.cifar10_model import *\n",
    "\n",
    "from lib.cifar10_dcgan import Discriminator, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f82df8f3a10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set all random seeds\n",
    "seed = 2019\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_valid, y_valid), (x_test, y_test) = load_cifar10_all(\n",
    "    '/data', val_size=0.1, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = 2\n",
    "\n",
    "# model_name = 'adv_cifar10_exp%d.h5' % exp_id\n",
    "# model_name = 'train_cifar10_vae_exp%d.h5' % exp_id\n",
    "# model_name = 'rot_cifar10_exp%d.h5' % exp_id\n",
    "# model_name = 'ae_cifar10_exp%d.h5' % exp_id\n",
    "model_name = 'cifar10_resnet_exp%d.h5' % exp_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PreActResNet(PreActBlock, [2, 2, 2, 2], num_classes=10)\n",
    "net = torch.nn.DataParallel(net)\n",
    "cudnn.benchmark = True\n",
    "net.load_state_dict(torch.load('saved_models/' + model_name))\n",
    "net = net.module\n",
    "net = net.eval().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = PreActResNet(PreActBlock, [2, 2, 2, 2]).eval()\n",
    "config = {'num_steps': 8,\n",
    "          'step_size': 0.05,\n",
    "          'random_start': True,\n",
    "          'loss_func': 'xent'}\n",
    "net = PGDL2Model(net, config)\n",
    "\n",
    "net.load_state_dict(torch.load('saved_models/' + model_name))\n",
    "net = net.basic_net\n",
    "net = net.eval().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CIFAR10_VAE((3, 32, 32), latent_dim=128)\n",
    "net.load_state_dict(torch.load('saved_models/' + model_name))\n",
    "net = net.eval().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PreActResNet(PreActBlock, [2, 2, 2, 2], num_classes=4)\n",
    "net.load_state_dict(torch.load('saved_models/' + model_name))\n",
    "net = net.eval().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CIFAR10_AE((3, 32, 32), latent_dim=128)\n",
    "net.load_state_dict(torch.load('saved_models/' + model_name))\n",
    "net = net.eval().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreActResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9303\n"
     ]
    }
   ],
   "source": [
    "ind = np.zeros(x_test.size(0))\n",
    "with torch.no_grad():\n",
    "    num = 0\n",
    "    for i in range(x_test.size(0) // 100):\n",
    "        begin = i * 100\n",
    "        end = (i + 1) * 100\n",
    "        y_pred = net(x_test[begin:end].to('cuda'))\n",
    "        ind[begin:end] = (y_pred.argmax(1).cpu() == y_test[begin:end]).numpy()\n",
    "        num += (y_pred.argmax(1).cpu() == y_test[begin:end]).sum().numpy()\n",
    "    print(num / y_test.size(0))\n",
    "ind = np.where(ind)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    step: 0; loss: 0.127; l2dist: 0.000\n",
      "    step: 50; loss: 0.051; l2dist: 0.208\n",
      "    step: 100; loss: 0.055; l2dist: 0.210\n",
      "binary step: 0; number of successful adv: 72/100\n",
      "    step: 0; loss: 0.408; l2dist: 0.000\n",
      "    step: 50; loss: 0.106; l2dist: 0.273\n",
      "    step: 100; loss: 0.123; l2dist: 0.285\n",
      "binary step: 1; number of successful adv: 95/100\n",
      "    step: 0; loss: 0.852; l2dist: 0.000\n",
      "    step: 50; loss: 0.113; l2dist: 0.279\n",
      "    step: 100; loss: 0.110; l2dist: 0.240\n",
      "    step: 150; loss: 0.145; l2dist: 0.286\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.504; l2dist: 0.000\n",
      "    step: 50; loss: 0.092; l2dist: 0.255\n",
      "    step: 100; loss: 0.103; l2dist: 0.247\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.336; l2dist: 0.000\n",
      "    step: 50; loss: 0.072; l2dist: 0.228\n",
      "    step: 100; loss: 0.087; l2dist: 0.239\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.123; l2dist: 0.000\n",
      "    step: 50; loss: 0.054; l2dist: 0.208\n",
      "    step: 100; loss: 0.055; l2dist: 0.199\n",
      "binary step: 0; number of successful adv: 62/100\n",
      "    step: 0; loss: 0.497; l2dist: 0.000\n",
      "    step: 50; loss: 0.120; l2dist: 0.287\n",
      "    step: 100; loss: 0.213; l2dist: 0.383\n",
      "binary step: 1; number of successful adv: 97/100\n",
      "    step: 0; loss: 0.666; l2dist: 0.000\n",
      "    step: 50; loss: 0.106; l2dist: 0.280\n",
      "    step: 100; loss: 0.219; l2dist: 0.317\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.421; l2dist: 0.000\n",
      "    step: 50; loss: 0.090; l2dist: 0.252\n",
      "    step: 100; loss: 0.093; l2dist: 0.251\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.291; l2dist: 0.000\n",
      "    step: 50; loss: 0.077; l2dist: 0.238\n",
      "    step: 100; loss: 0.095; l2dist: 0.253\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.118; l2dist: 0.000\n",
      "    step: 50; loss: 0.051; l2dist: 0.205\n",
      "    step: 100; loss: 0.058; l2dist: 0.217\n",
      "binary step: 0; number of successful adv: 91/100\n",
      "    step: 0; loss: 0.153; l2dist: 0.000\n",
      "    step: 50; loss: 0.046; l2dist: 0.183\n",
      "    step: 100; loss: 0.044; l2dist: 0.169\n",
      "    step: 150; loss: 0.059; l2dist: 0.189\n",
      "binary step: 1; number of successful adv: 98/100\n",
      "    step: 0; loss: 0.254; l2dist: 0.000\n",
      "    step: 50; loss: 0.044; l2dist: 0.184\n",
      "    step: 100; loss: 0.045; l2dist: 0.162\n",
      "binary step: 2; number of successful adv: 99/100\n",
      "    step: 0; loss: 0.510; l2dist: 0.000\n",
      "    step: 50; loss: 0.055; l2dist: 0.196\n",
      "    step: 100; loss: 0.036; l2dist: 0.150\n",
      "    step: 150; loss: 0.045; l2dist: 0.163\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.317; l2dist: 0.000\n",
      "    step: 50; loss: 0.046; l2dist: 0.186\n",
      "    step: 100; loss: 0.034; l2dist: 0.143\n",
      "    step: 150; loss: 0.042; l2dist: 0.157\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.122; l2dist: 0.000\n",
      "    step: 50; loss: 0.051; l2dist: 0.202\n",
      "    step: 100; loss: 0.052; l2dist: 0.194\n",
      "binary step: 0; number of successful adv: 66/100\n",
      "    step: 0; loss: 0.478; l2dist: 0.000\n",
      "    step: 50; loss: 0.119; l2dist: 0.295\n",
      "    step: 100; loss: 0.123; l2dist: 0.302\n",
      "binary step: 1; number of successful adv: 99/100\n",
      "    step: 0; loss: 0.385; l2dist: 0.000\n",
      "    step: 50; loss: 0.080; l2dist: 0.249\n",
      "    step: 100; loss: 0.085; l2dist: 0.238\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.301; l2dist: 0.000\n",
      "    step: 50; loss: 0.074; l2dist: 0.238\n",
      "    step: 100; loss: 0.091; l2dist: 0.247\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.235; l2dist: 0.000\n",
      "    step: 50; loss: 0.065; l2dist: 0.223\n",
      "    step: 100; loss: 0.077; l2dist: 0.230\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.119; l2dist: 0.000\n",
      "    step: 50; loss: 0.056; l2dist: 0.217\n",
      "    step: 100; loss: 0.055; l2dist: 0.216\n",
      "    step: 150; loss: 0.067; l2dist: 0.241\n",
      "binary step: 0; number of successful adv: 88/100\n",
      "    step: 0; loss: 0.202; l2dist: 0.000\n",
      "    step: 50; loss: 0.058; l2dist: 0.204\n",
      "    step: 100; loss: 0.059; l2dist: 0.182\n",
      "binary step: 1; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.132; l2dist: 0.000\n",
      "    step: 50; loss: 0.055; l2dist: 0.203\n",
      "    step: 100; loss: 0.049; l2dist: 0.179\n",
      "    step: 150; loss: 0.076; l2dist: 0.215\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.106; l2dist: 0.000\n",
      "    step: 50; loss: 0.048; l2dist: 0.187\n",
      "    step: 100; loss: 0.046; l2dist: 0.169\n",
      "    step: 150; loss: 0.049; l2dist: 0.175\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.099; l2dist: 0.000\n",
      "    step: 50; loss: 0.047; l2dist: 0.186\n",
      "    step: 100; loss: 0.040; l2dist: 0.167\n",
      "    step: 150; loss: 0.046; l2dist: 0.180\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.147; l2dist: 0.000\n",
      "    step: 50; loss: 0.059; l2dist: 0.226\n",
      "    step: 100; loss: 0.057; l2dist: 0.208\n",
      "    step: 150; loss: 0.068; l2dist: 0.231\n",
      "binary step: 0; number of successful adv: 59/100\n",
      "    step: 0; loss: 0.676; l2dist: 0.000\n",
      "    step: 50; loss: 0.176; l2dist: 0.364\n",
      "    step: 100; loss: 0.188; l2dist: 0.377\n",
      "binary step: 1; number of successful adv: 98/100\n",
      "    step: 0; loss: 0.661; l2dist: 0.000\n",
      "    step: 50; loss: 0.108; l2dist: 0.293\n",
      "    step: 100; loss: 0.146; l2dist: 0.343\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.406; l2dist: 0.000\n",
      "    step: 50; loss: 0.088; l2dist: 0.263\n",
      "    step: 100; loss: 0.108; l2dist: 0.286\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.280; l2dist: 0.000\n",
      "    step: 50; loss: 0.081; l2dist: 0.251\n",
      "    step: 100; loss: 0.085; l2dist: 0.240\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.126; l2dist: 0.000\n",
      "    step: 50; loss: 0.056; l2dist: 0.218\n",
      "    step: 100; loss: 0.057; l2dist: 0.221\n",
      "binary step: 0; number of successful adv: 84/100\n",
      "    step: 0; loss: 0.245; l2dist: 0.000\n",
      "    step: 50; loss: 0.067; l2dist: 0.222\n",
      "    step: 100; loss: 0.054; l2dist: 0.196\n",
      "    step: 150; loss: 0.099; l2dist: 0.268\n",
      "binary step: 1; number of successful adv: 98/100\n",
      "    step: 0; loss: 0.366; l2dist: 0.000\n",
      "    step: 50; loss: 0.067; l2dist: 0.217\n",
      "    step: 100; loss: 0.050; l2dist: 0.180\n",
      "    step: 150; loss: 0.061; l2dist: 0.197\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.217; l2dist: 0.000\n",
      "    step: 50; loss: 0.049; l2dist: 0.191\n",
      "    step: 100; loss: 0.043; l2dist: 0.160\n",
      "    step: 150; loss: 0.051; l2dist: 0.181\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.150; l2dist: 0.000\n",
      "    step: 50; loss: 0.046; l2dist: 0.181\n",
      "    step: 100; loss: 0.036; l2dist: 0.151\n",
      "    step: 150; loss: 0.041; l2dist: 0.159\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.122; l2dist: 0.000\n",
      "    step: 50; loss: 0.054; l2dist: 0.209\n",
      "    step: 100; loss: 0.060; l2dist: 0.205\n",
      "binary step: 0; number of successful adv: 65/100\n",
      "    step: 0; loss: 0.492; l2dist: 0.000\n",
      "    step: 50; loss: 0.131; l2dist: 0.317\n",
      "    step: 100; loss: 0.195; l2dist: 0.358\n",
      "binary step: 1; number of successful adv: 94/100\n",
      "    step: 0; loss: 1.075; l2dist: 0.000\n",
      "    step: 50; loss: 0.148; l2dist: 0.314\n",
      "    step: 100; loss: 0.108; l2dist: 0.260\n",
      "    step: 150; loss: 0.273; l2dist: 0.396\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.644; l2dist: 0.000\n",
      "    step: 50; loss: 0.119; l2dist: 0.287\n",
      "    step: 100; loss: 0.116; l2dist: 0.272\n",
      "    step: 150; loss: 0.119; l2dist: 0.262\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.502; l2dist: 0.000\n",
      "    step: 50; loss: 0.085; l2dist: 0.251\n",
      "    step: 100; loss: 0.129; l2dist: 0.288\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.127; l2dist: 0.000\n",
      "    step: 50; loss: 0.055; l2dist: 0.215\n",
      "    step: 100; loss: 0.058; l2dist: 0.216\n",
      "binary step: 0; number of successful adv: 75/100\n",
      "    step: 0; loss: 0.365; l2dist: 0.000\n",
      "    step: 50; loss: 0.091; l2dist: 0.256\n",
      "    step: 100; loss: 0.106; l2dist: 0.260\n",
      "binary step: 1; number of successful adv: 95/100\n",
      "    step: 0; loss: 0.752; l2dist: 0.000\n",
      "    step: 50; loss: 0.085; l2dist: 0.246\n",
      "    step: 100; loss: 0.135; l2dist: 0.265\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.443; l2dist: 0.000\n",
      "    step: 50; loss: 0.077; l2dist: 0.228\n",
      "    step: 100; loss: 0.076; l2dist: 0.204\n",
      "    step: 150; loss: 0.083; l2dist: 0.225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.302; l2dist: 0.000\n",
      "    step: 50; loss: 0.068; l2dist: 0.222\n",
      "    step: 100; loss: 0.065; l2dist: 0.196\n",
      "    step: 150; loss: 0.101; l2dist: 0.249\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.126; l2dist: 0.000\n",
      "    step: 50; loss: 0.057; l2dist: 0.221\n",
      "    step: 100; loss: 0.061; l2dist: 0.215\n",
      "binary step: 0; number of successful adv: 65/100\n",
      "    step: 0; loss: 0.502; l2dist: 0.000\n",
      "    step: 50; loss: 0.152; l2dist: 0.336\n",
      "    step: 100; loss: 0.170; l2dist: 0.338\n",
      "binary step: 1; number of successful adv: 96/100\n",
      "    step: 0; loss: 0.745; l2dist: 0.000\n",
      "    step: 50; loss: 0.123; l2dist: 0.297\n",
      "    step: 100; loss: 0.143; l2dist: 0.293\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.460; l2dist: 0.000\n",
      "    step: 50; loss: 0.102; l2dist: 0.266\n",
      "    step: 100; loss: 0.105; l2dist: 0.258\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.311; l2dist: 0.000\n",
      "    step: 50; loss: 0.075; l2dist: 0.242\n",
      "    step: 100; loss: 0.095; l2dist: 0.241\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.143; l2dist: 0.000\n",
      "    step: 50; loss: 0.065; l2dist: 0.233\n",
      "    step: 100; loss: 0.068; l2dist: 0.213\n",
      "binary step: 0; number of successful adv: 55/100\n",
      "    step: 0; loss: 0.710; l2dist: 0.000\n",
      "    step: 50; loss: 0.177; l2dist: 0.368\n",
      "    step: 100; loss: 0.231; l2dist: 0.417\n",
      "binary step: 1; number of successful adv: 99/100\n",
      "    step: 0; loss: 0.530; l2dist: 0.000\n",
      "    step: 50; loss: 0.172; l2dist: 0.357\n",
      "    step: 100; loss: 0.161; l2dist: 0.322\n",
      "    step: 150; loss: 0.192; l2dist: 0.377\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.373; l2dist: 0.000\n",
      "    step: 50; loss: 0.114; l2dist: 0.291\n",
      "    step: 100; loss: 0.143; l2dist: 0.307\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.325; l2dist: 0.000\n",
      "    step: 50; loss: 0.113; l2dist: 0.296\n",
      "    step: 100; loss: 0.114; l2dist: 0.293\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.133; l2dist: 0.000\n",
      "    step: 50; loss: 0.057; l2dist: 0.218\n",
      "    step: 100; loss: 0.062; l2dist: 0.209\n",
      "binary step: 0; number of successful adv: 67/100\n",
      "    step: 0; loss: 0.490; l2dist: 0.000\n",
      "    step: 50; loss: 0.131; l2dist: 0.310\n",
      "    step: 100; loss: 0.137; l2dist: 0.282\n",
      "binary step: 1; number of successful adv: 96/100\n",
      "    step: 0; loss: 0.795; l2dist: 0.000\n",
      "    step: 50; loss: 0.127; l2dist: 0.289\n",
      "    step: 100; loss: 0.157; l2dist: 0.295\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.498; l2dist: 0.000\n",
      "    step: 50; loss: 0.113; l2dist: 0.274\n",
      "    step: 100; loss: 0.099; l2dist: 0.244\n",
      "    step: 150; loss: 0.131; l2dist: 0.280\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.422; l2dist: 0.000\n",
      "    step: 50; loss: 0.098; l2dist: 0.262\n",
      "    step: 100; loss: 0.109; l2dist: 0.261\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.129; l2dist: 0.000\n",
      "    step: 50; loss: 0.058; l2dist: 0.225\n",
      "    step: 100; loss: 0.058; l2dist: 0.215\n",
      "    step: 150; loss: 0.070; l2dist: 0.245\n",
      "binary step: 0; number of successful adv: 86/100\n",
      "    step: 0; loss: 0.211; l2dist: 0.000\n",
      "    step: 50; loss: 0.058; l2dist: 0.211\n",
      "    step: 100; loss: 0.067; l2dist: 0.208\n",
      "binary step: 1; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.131; l2dist: 0.000\n",
      "    step: 50; loss: 0.051; l2dist: 0.188\n",
      "    step: 100; loss: 0.046; l2dist: 0.169\n",
      "    step: 150; loss: 0.055; l2dist: 0.184\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.127; l2dist: 0.000\n",
      "    step: 50; loss: 0.045; l2dist: 0.189\n",
      "    step: 100; loss: 0.042; l2dist: 0.168\n",
      "    step: 150; loss: 0.052; l2dist: 0.187\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.111; l2dist: 0.000\n",
      "    step: 50; loss: 0.044; l2dist: 0.181\n",
      "    step: 100; loss: 0.042; l2dist: 0.156\n",
      "    step: 150; loss: 0.044; l2dist: 0.161\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.135; l2dist: 0.000\n",
      "    step: 50; loss: 0.059; l2dist: 0.227\n",
      "    step: 100; loss: 0.064; l2dist: 0.217\n",
      "binary step: 0; number of successful adv: 56/100\n",
      "    step: 0; loss: 0.653; l2dist: 0.000\n",
      "    step: 50; loss: 0.142; l2dist: 0.313\n",
      "    step: 100; loss: 0.205; l2dist: 0.380\n",
      "binary step: 1; number of successful adv: 95/100\n",
      "    step: 0; loss: 0.995; l2dist: 0.000\n",
      "    step: 50; loss: 0.130; l2dist: 0.305\n",
      "    step: 100; loss: 0.160; l2dist: 0.327\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.579; l2dist: 0.000\n",
      "    step: 50; loss: 0.119; l2dist: 0.290\n",
      "    step: 100; loss: 0.229; l2dist: 0.356\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.388; l2dist: 0.000\n",
      "    step: 50; loss: 0.084; l2dist: 0.247\n",
      "    step: 100; loss: 0.123; l2dist: 0.291\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.128; l2dist: 0.000\n",
      "    step: 50; loss: 0.057; l2dist: 0.213\n",
      "    step: 100; loss: 0.056; l2dist: 0.196\n",
      "    step: 150; loss: 0.074; l2dist: 0.230\n",
      "binary step: 0; number of successful adv: 59/100\n",
      "    step: 0; loss: 0.573; l2dist: 0.000\n",
      "    step: 50; loss: 0.144; l2dist: 0.331\n",
      "    step: 100; loss: 0.194; l2dist: 0.361\n",
      "binary step: 1; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.323; l2dist: 0.000\n",
      "    step: 50; loss: 0.100; l2dist: 0.277\n",
      "    step: 100; loss: 0.139; l2dist: 0.303\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.260; l2dist: 0.000\n",
      "    step: 50; loss: 0.082; l2dist: 0.246\n",
      "    step: 100; loss: 0.102; l2dist: 0.268\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.212; l2dist: 0.000\n",
      "    step: 50; loss: 0.078; l2dist: 0.250\n",
      "    step: 100; loss: 0.103; l2dist: 0.254\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.126; l2dist: 0.000\n",
      "    step: 50; loss: 0.054; l2dist: 0.211\n",
      "    step: 100; loss: 0.055; l2dist: 0.202\n",
      "binary step: 0; number of successful adv: 60/100\n",
      "    step: 0; loss: 0.577; l2dist: 0.000\n",
      "    step: 50; loss: 0.135; l2dist: 0.304\n",
      "    step: 100; loss: 0.160; l2dist: 0.337\n",
      "binary step: 1; number of successful adv: 99/100\n",
      "    step: 0; loss: 0.468; l2dist: 0.000\n",
      "    step: 50; loss: 0.114; l2dist: 0.283\n",
      "    step: 100; loss: 0.099; l2dist: 0.260\n",
      "    step: 150; loss: 0.117; l2dist: 0.301\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.282; l2dist: 0.000\n",
      "    step: 50; loss: 0.084; l2dist: 0.262\n",
      "    step: 100; loss: 0.114; l2dist: 0.278\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.220; l2dist: 0.000\n",
      "    step: 50; loss: 0.066; l2dist: 0.227\n",
      "    step: 100; loss: 0.089; l2dist: 0.238\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.127; l2dist: 0.000\n",
      "    step: 50; loss: 0.055; l2dist: 0.217\n",
      "    step: 100; loss: 0.052; l2dist: 0.198\n",
      "    step: 150; loss: 0.072; l2dist: 0.243\n",
      "binary step: 0; number of successful adv: 86/100\n",
      "    step: 0; loss: 0.244; l2dist: 0.000\n",
      "    step: 50; loss: 0.082; l2dist: 0.229\n",
      "    step: 100; loss: 0.088; l2dist: 0.228\n",
      "binary step: 1; number of successful adv: 97/100\n",
      "    step: 0; loss: 0.524; l2dist: 0.000\n",
      "    step: 50; loss: 0.066; l2dist: 0.215\n",
      "    step: 100; loss: 0.059; l2dist: 0.179\n",
      "    step: 150; loss: 0.078; l2dist: 0.202\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.335; l2dist: 0.000\n",
      "    step: 50; loss: 0.058; l2dist: 0.209\n",
      "    step: 100; loss: 0.069; l2dist: 0.192\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.240; l2dist: 0.000\n",
      "    step: 50; loss: 0.052; l2dist: 0.195\n",
      "    step: 100; loss: 0.047; l2dist: 0.174\n",
      "    step: 150; loss: 0.066; l2dist: 0.192\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.134; l2dist: 0.000\n",
      "    step: 50; loss: 0.058; l2dist: 0.215\n",
      "    step: 100; loss: 0.059; l2dist: 0.203\n",
      "binary step: 0; number of successful adv: 60/100\n",
      "    step: 0; loss: 0.599; l2dist: 0.000\n",
      "    step: 50; loss: 0.147; l2dist: 0.330\n",
      "    step: 100; loss: 0.173; l2dist: 0.340\n",
      "binary step: 1; number of successful adv: 97/100\n",
      "    step: 0; loss: 0.680; l2dist: 0.000\n",
      "    step: 50; loss: 0.122; l2dist: 0.296\n",
      "    step: 100; loss: 0.136; l2dist: 0.295\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.445; l2dist: 0.000\n",
      "    step: 50; loss: 0.113; l2dist: 0.284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    step: 100; loss: 0.108; l2dist: 0.275\n",
      "    step: 150; loss: 0.102; l2dist: 0.258\n",
      "    step: 200; loss: 0.206; l2dist: 0.350\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.323; l2dist: 0.000\n",
      "    step: 50; loss: 0.101; l2dist: 0.266\n",
      "    step: 100; loss: 0.111; l2dist: 0.267\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.112; l2dist: 0.000\n",
      "    step: 50; loss: 0.050; l2dist: 0.202\n",
      "    step: 100; loss: 0.055; l2dist: 0.196\n",
      "binary step: 0; number of successful adv: 62/100\n",
      "    step: 0; loss: 0.484; l2dist: 0.000\n",
      "    step: 50; loss: 0.140; l2dist: 0.320\n",
      "    step: 100; loss: 0.194; l2dist: 0.358\n",
      "binary step: 1; number of successful adv: 94/100\n",
      "    step: 0; loss: 0.920; l2dist: 0.000\n",
      "    step: 50; loss: 0.131; l2dist: 0.292\n",
      "    step: 100; loss: 0.154; l2dist: 0.295\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.548; l2dist: 0.000\n",
      "    step: 50; loss: 0.096; l2dist: 0.254\n",
      "    step: 100; loss: 0.110; l2dist: 0.251\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.423; l2dist: 0.000\n",
      "    step: 50; loss: 0.099; l2dist: 0.252\n",
      "    step: 100; loss: 0.090; l2dist: 0.226\n",
      "    step: 150; loss: 0.117; l2dist: 0.282\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.144; l2dist: 0.000\n",
      "    step: 50; loss: 0.065; l2dist: 0.238\n",
      "    step: 100; loss: 0.069; l2dist: 0.249\n",
      "binary step: 0; number of successful adv: 92/100\n",
      "    step: 0; loss: 0.181; l2dist: 0.000\n",
      "    step: 50; loss: 0.068; l2dist: 0.227\n",
      "    step: 100; loss: 0.077; l2dist: 0.219\n",
      "binary step: 1; number of successful adv: 98/100\n",
      "    step: 0; loss: 0.305; l2dist: 0.000\n",
      "    step: 50; loss: 0.055; l2dist: 0.205\n",
      "    step: 100; loss: 0.049; l2dist: 0.176\n",
      "    step: 150; loss: 0.077; l2dist: 0.205\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.218; l2dist: 0.000\n",
      "    step: 50; loss: 0.056; l2dist: 0.202\n",
      "    step: 100; loss: 0.050; l2dist: 0.179\n",
      "    step: 150; loss: 0.052; l2dist: 0.197\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.167; l2dist: 0.000\n",
      "    step: 50; loss: 0.058; l2dist: 0.205\n",
      "    step: 100; loss: 0.048; l2dist: 0.177\n",
      "    step: 150; loss: 0.054; l2dist: 0.194\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.134; l2dist: 0.000\n",
      "    step: 50; loss: 0.059; l2dist: 0.221\n",
      "    step: 100; loss: 0.066; l2dist: 0.222\n",
      "binary step: 0; number of successful adv: 61/100\n",
      "    step: 0; loss: 0.578; l2dist: 0.000\n",
      "    step: 50; loss: 0.178; l2dist: 0.346\n",
      "    step: 100; loss: 0.176; l2dist: 0.332\n",
      "    step: 150; loss: 0.294; l2dist: 0.446\n",
      "binary step: 1; number of successful adv: 93/100\n",
      "    step: 0; loss: 1.232; l2dist: 0.000\n",
      "    step: 50; loss: 0.173; l2dist: 0.334\n",
      "    step: 100; loss: 0.198; l2dist: 0.328\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.726; l2dist: 0.000\n",
      "    step: 50; loss: 0.125; l2dist: 0.289\n",
      "    step: 100; loss: 0.159; l2dist: 0.298\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.556; l2dist: 0.000\n",
      "    step: 50; loss: 0.168; l2dist: 0.322\n",
      "    step: 100; loss: 0.214; l2dist: 0.320\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.138; l2dist: 0.000\n",
      "    step: 50; loss: 0.061; l2dist: 0.220\n",
      "    step: 100; loss: 0.066; l2dist: 0.224\n",
      "binary step: 0; number of successful adv: 57/100\n",
      "    step: 0; loss: 0.656; l2dist: 0.000\n",
      "    step: 50; loss: 0.155; l2dist: 0.325\n",
      "    step: 100; loss: 0.182; l2dist: 0.370\n",
      "binary step: 1; number of successful adv: 99/100\n",
      "    step: 0; loss: 0.475; l2dist: 0.000\n",
      "    step: 50; loss: 0.114; l2dist: 0.296\n",
      "    step: 100; loss: 0.143; l2dist: 0.317\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.348; l2dist: 0.000\n",
      "    step: 50; loss: 0.087; l2dist: 0.263\n",
      "    step: 100; loss: 0.122; l2dist: 0.290\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.352; l2dist: 0.000\n",
      "    step: 50; loss: 0.086; l2dist: 0.263\n",
      "    step: 100; loss: 0.091; l2dist: 0.261\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.128; l2dist: 0.000\n",
      "    step: 50; loss: 0.060; l2dist: 0.216\n",
      "    step: 100; loss: 0.065; l2dist: 0.209\n",
      "binary step: 0; number of successful adv: 45/100\n",
      "    step: 0; loss: 0.727; l2dist: 0.000\n",
      "    step: 50; loss: 0.182; l2dist: 0.356\n",
      "    step: 100; loss: 0.222; l2dist: 0.405\n",
      "binary step: 1; number of successful adv: 94/100\n",
      "    step: 0; loss: 1.191; l2dist: 0.000\n",
      "    step: 50; loss: 0.167; l2dist: 0.355\n",
      "    step: 100; loss: 0.210; l2dist: 0.373\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.720; l2dist: 0.000\n",
      "    step: 50; loss: 0.137; l2dist: 0.316\n",
      "    step: 100; loss: 0.166; l2dist: 0.331\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.477; l2dist: 0.000\n",
      "    step: 50; loss: 0.112; l2dist: 0.289\n",
      "    step: 100; loss: 0.107; l2dist: 0.266\n",
      "    step: 150; loss: 0.144; l2dist: 0.310\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.120; l2dist: 0.000\n",
      "    step: 50; loss: 0.052; l2dist: 0.204\n",
      "    step: 100; loss: 0.051; l2dist: 0.192\n",
      "    step: 150; loss: 0.058; l2dist: 0.224\n",
      "binary step: 0; number of successful adv: 83/100\n",
      "    step: 0; loss: 0.241; l2dist: 0.000\n",
      "    step: 50; loss: 0.066; l2dist: 0.219\n",
      "    step: 100; loss: 0.088; l2dist: 0.239\n",
      "binary step: 1; number of successful adv: 97/100\n",
      "    step: 0; loss: 0.419; l2dist: 0.000\n",
      "    step: 50; loss: 0.063; l2dist: 0.209\n",
      "    step: 100; loss: 0.058; l2dist: 0.177\n",
      "    step: 150; loss: 0.067; l2dist: 0.192\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.270; l2dist: 0.000\n",
      "    step: 50; loss: 0.054; l2dist: 0.204\n",
      "    step: 100; loss: 0.053; l2dist: 0.178\n",
      "    step: 150; loss: 0.056; l2dist: 0.185\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.195; l2dist: 0.000\n",
      "    step: 50; loss: 0.049; l2dist: 0.191\n",
      "    step: 100; loss: 0.048; l2dist: 0.170\n",
      "    step: 150; loss: 0.057; l2dist: 0.195\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.134; l2dist: 0.000\n",
      "    step: 50; loss: 0.059; l2dist: 0.227\n",
      "    step: 100; loss: 0.065; l2dist: 0.220\n",
      "binary step: 0; number of successful adv: 62/100\n",
      "    step: 0; loss: 0.545; l2dist: 0.000\n",
      "    step: 50; loss: 0.169; l2dist: 0.333\n",
      "    step: 100; loss: 0.172; l2dist: 0.330\n",
      "binary step: 1; number of successful adv: 88/100\n",
      "    step: 0; loss: 1.758; l2dist: 0.000\n",
      "    step: 50; loss: 0.253; l2dist: 0.384\n",
      "    step: 100; loss: 0.133; l2dist: 0.269\n",
      "    step: 150; loss: 0.177; l2dist: 0.305\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 1.008; l2dist: 0.000\n",
      "    step: 50; loss: 0.170; l2dist: 0.341\n",
      "    step: 100; loss: 0.178; l2dist: 0.332\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.621; l2dist: 0.000\n",
      "    step: 50; loss: 0.129; l2dist: 0.282\n",
      "    step: 100; loss: 0.139; l2dist: 0.264\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.133; l2dist: 0.000\n",
      "    step: 50; loss: 0.059; l2dist: 0.214\n",
      "    step: 100; loss: 0.058; l2dist: 0.210\n",
      "    step: 150; loss: 0.068; l2dist: 0.233\n",
      "binary step: 0; number of successful adv: 68/100\n",
      "    step: 0; loss: 0.461; l2dist: 0.000\n",
      "    step: 50; loss: 0.102; l2dist: 0.272\n",
      "    step: 100; loss: 0.111; l2dist: 0.261\n",
      "binary step: 1; number of successful adv: 92/100\n",
      "    step: 0; loss: 1.337; l2dist: 0.000\n",
      "    step: 50; loss: 0.129; l2dist: 0.291\n",
      "    step: 100; loss: 0.110; l2dist: 0.243\n",
      "    step: 150; loss: 0.155; l2dist: 0.287\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.784; l2dist: 0.000\n",
      "    step: 50; loss: 0.088; l2dist: 0.251\n",
      "    step: 100; loss: 0.113; l2dist: 0.257\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.504; l2dist: 0.000\n",
      "    step: 50; loss: 0.076; l2dist: 0.228\n",
      "    step: 100; loss: 0.085; l2dist: 0.233\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.125; l2dist: 0.000\n",
      "    step: 50; loss: 0.054; l2dist: 0.209\n",
      "    step: 100; loss: 0.056; l2dist: 0.204\n",
      "binary step: 0; number of successful adv: 55/100\n",
      "    step: 0; loss: 0.594; l2dist: 0.000\n",
      "    step: 50; loss: 0.152; l2dist: 0.333\n",
      "    step: 100; loss: 0.200; l2dist: 0.362\n",
      "binary step: 1; number of successful adv: 85/100\n",
      "    step: 0; loss: 2.194; l2dist: 0.000\n",
      "    step: 50; loss: 0.295; l2dist: 0.424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    step: 100; loss: 0.196; l2dist: 0.324\n",
      "    step: 150; loss: 0.342; l2dist: 0.437\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 1.227; l2dist: 0.000\n",
      "    step: 50; loss: 0.158; l2dist: 0.323\n",
      "    step: 100; loss: 0.142; l2dist: 0.298\n",
      "    step: 150; loss: 0.208; l2dist: 0.319\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.806; l2dist: 0.000\n",
      "    step: 50; loss: 0.163; l2dist: 0.305\n",
      "    step: 100; loss: 0.204; l2dist: 0.346\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.130; l2dist: 0.000\n",
      "    step: 50; loss: 0.060; l2dist: 0.225\n",
      "    step: 100; loss: 0.060; l2dist: 0.224\n",
      "    step: 150; loss: 0.073; l2dist: 0.246\n",
      "binary step: 0; number of successful adv: 82/100\n",
      "    step: 0; loss: 0.297; l2dist: 0.000\n",
      "    step: 50; loss: 0.085; l2dist: 0.254\n",
      "    step: 100; loss: 0.084; l2dist: 0.236\n",
      "    step: 150; loss: 0.129; l2dist: 0.297\n",
      "binary step: 1; number of successful adv: 96/100\n",
      "    step: 0; loss: 0.669; l2dist: 0.000\n",
      "    step: 50; loss: 0.104; l2dist: 0.263\n",
      "    step: 100; loss: 0.117; l2dist: 0.245\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.415; l2dist: 0.000\n",
      "    step: 50; loss: 0.083; l2dist: 0.239\n",
      "    step: 100; loss: 0.104; l2dist: 0.250\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.290; l2dist: 0.000\n",
      "    step: 50; loss: 0.075; l2dist: 0.229\n",
      "    step: 100; loss: 0.074; l2dist: 0.220\n",
      "    step: 150; loss: 0.122; l2dist: 0.277\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.127; l2dist: 0.000\n",
      "    step: 50; loss: 0.058; l2dist: 0.217\n",
      "    step: 100; loss: 0.061; l2dist: 0.212\n",
      "binary step: 0; number of successful adv: 58/100\n",
      "    step: 0; loss: 0.564; l2dist: 0.000\n",
      "    step: 50; loss: 0.118; l2dist: 0.296\n",
      "    step: 100; loss: 0.162; l2dist: 0.334\n",
      "binary step: 1; number of successful adv: 98/100\n",
      "    step: 0; loss: 0.543; l2dist: 0.000\n",
      "    step: 50; loss: 0.138; l2dist: 0.313\n",
      "    step: 100; loss: 0.141; l2dist: 0.310\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.337; l2dist: 0.000\n",
      "    step: 50; loss: 0.080; l2dist: 0.243\n",
      "    step: 100; loss: 0.085; l2dist: 0.242\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.245; l2dist: 0.000\n",
      "    step: 50; loss: 0.073; l2dist: 0.240\n",
      "    step: 100; loss: 0.078; l2dist: 0.227\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.130; l2dist: 0.000\n",
      "    step: 50; loss: 0.056; l2dist: 0.213\n",
      "    step: 100; loss: 0.062; l2dist: 0.204\n",
      "binary step: 0; number of successful adv: 51/100\n",
      "    step: 0; loss: 0.683; l2dist: 0.000\n",
      "    step: 50; loss: 0.163; l2dist: 0.349\n",
      "    step: 100; loss: 0.212; l2dist: 0.381\n",
      "binary step: 1; number of successful adv: 91/100\n",
      "    step: 0; loss: 1.536; l2dist: 0.000\n",
      "    step: 50; loss: 0.182; l2dist: 0.360\n",
      "    step: 100; loss: 0.162; l2dist: 0.307\n",
      "    step: 150; loss: 0.289; l2dist: 0.435\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.936; l2dist: 0.000\n",
      "    step: 50; loss: 0.140; l2dist: 0.321\n",
      "    step: 100; loss: 0.200; l2dist: 0.350\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.626; l2dist: 0.000\n",
      "    step: 50; loss: 0.136; l2dist: 0.314\n",
      "    step: 100; loss: 0.141; l2dist: 0.304\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.122; l2dist: 0.000\n",
      "    step: 50; loss: 0.054; l2dist: 0.210\n",
      "    step: 100; loss: 0.059; l2dist: 0.202\n",
      "binary step: 0; number of successful adv: 62/100\n",
      "    step: 0; loss: 0.516; l2dist: 0.000\n",
      "    step: 50; loss: 0.151; l2dist: 0.315\n",
      "    step: 100; loss: 0.141; l2dist: 0.301\n",
      "    step: 150; loss: 0.189; l2dist: 0.370\n",
      "binary step: 1; number of successful adv: 99/100\n",
      "    step: 0; loss: 0.380; l2dist: 0.000\n",
      "    step: 50; loss: 0.132; l2dist: 0.290\n",
      "    step: 100; loss: 0.086; l2dist: 0.233\n",
      "    step: 150; loss: 0.114; l2dist: 0.275\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.234; l2dist: 0.000\n",
      "    step: 50; loss: 0.069; l2dist: 0.221\n",
      "    step: 100; loss: 0.076; l2dist: 0.207\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.245; l2dist: 0.000\n",
      "    step: 50; loss: 0.069; l2dist: 0.228\n",
      "    step: 100; loss: 0.066; l2dist: 0.201\n",
      "    step: 150; loss: 0.097; l2dist: 0.259\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.130; l2dist: 0.000\n",
      "    step: 50; loss: 0.057; l2dist: 0.216\n",
      "    step: 100; loss: 0.061; l2dist: 0.208\n",
      "binary step: 0; number of successful adv: 59/100\n",
      "    step: 0; loss: 0.561; l2dist: 0.000\n",
      "    step: 50; loss: 0.129; l2dist: 0.312\n",
      "    step: 100; loss: 0.141; l2dist: 0.306\n",
      "binary step: 1; number of successful adv: 95/100\n",
      "    step: 0; loss: 0.936; l2dist: 0.000\n",
      "    step: 50; loss: 0.125; l2dist: 0.299\n",
      "    step: 100; loss: 0.135; l2dist: 0.285\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.573; l2dist: 0.000\n",
      "    step: 50; loss: 0.109; l2dist: 0.265\n",
      "    step: 100; loss: 0.109; l2dist: 0.250\n",
      "    step: 150; loss: 0.131; l2dist: 0.288\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.396; l2dist: 0.000\n",
      "    step: 50; loss: 0.104; l2dist: 0.272\n",
      "    step: 100; loss: 0.104; l2dist: 0.255\n",
      "    step: 150; loss: 0.138; l2dist: 0.291\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.132; l2dist: 0.000\n",
      "    step: 50; loss: 0.057; l2dist: 0.213\n",
      "    step: 100; loss: 0.057; l2dist: 0.210\n",
      "binary step: 0; number of successful adv: 67/100\n",
      "    step: 0; loss: 0.501; l2dist: 0.000\n",
      "    step: 50; loss: 0.130; l2dist: 0.305\n",
      "    step: 100; loss: 0.153; l2dist: 0.324\n",
      "binary step: 1; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.284; l2dist: 0.000\n",
      "    step: 50; loss: 0.083; l2dist: 0.256\n",
      "    step: 100; loss: 0.092; l2dist: 0.249\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.222; l2dist: 0.000\n",
      "    step: 50; loss: 0.079; l2dist: 0.240\n",
      "    step: 100; loss: 0.095; l2dist: 0.237\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.219; l2dist: 0.000\n",
      "    step: 50; loss: 0.080; l2dist: 0.240\n",
      "    step: 100; loss: 0.096; l2dist: 0.264\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.120; l2dist: 0.000\n",
      "    step: 50; loss: 0.052; l2dist: 0.199\n",
      "    step: 100; loss: 0.059; l2dist: 0.200\n",
      "binary step: 0; number of successful adv: 61/100\n",
      "    step: 0; loss: 0.531; l2dist: 0.000\n",
      "    step: 50; loss: 0.148; l2dist: 0.322\n",
      "    step: 100; loss: 0.220; l2dist: 0.384\n",
      "binary step: 1; number of successful adv: 95/100\n",
      "    step: 0; loss: 0.867; l2dist: 0.000\n",
      "    step: 50; loss: 0.166; l2dist: 0.332\n",
      "    step: 100; loss: 0.135; l2dist: 0.291\n",
      "    step: 150; loss: 0.263; l2dist: 0.397\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.517; l2dist: 0.000\n",
      "    step: 50; loss: 0.114; l2dist: 0.287\n",
      "    step: 100; loss: 0.163; l2dist: 0.314\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.341; l2dist: 0.000\n",
      "    step: 50; loss: 0.100; l2dist: 0.272\n",
      "    step: 100; loss: 0.118; l2dist: 0.273\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.139; l2dist: 0.000\n",
      "    step: 50; loss: 0.059; l2dist: 0.225\n",
      "    step: 100; loss: 0.065; l2dist: 0.223\n",
      "binary step: 0; number of successful adv: 67/100\n",
      "    step: 0; loss: 0.495; l2dist: 0.000\n",
      "    step: 50; loss: 0.143; l2dist: 0.308\n",
      "    step: 100; loss: 0.153; l2dist: 0.326\n",
      "binary step: 1; number of successful adv: 94/100\n",
      "    step: 0; loss: 1.075; l2dist: 0.000\n",
      "    step: 50; loss: 0.120; l2dist: 0.288\n",
      "    step: 100; loss: 0.137; l2dist: 0.291\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.614; l2dist: 0.000\n",
      "    step: 50; loss: 0.090; l2dist: 0.247\n",
      "    step: 100; loss: 0.086; l2dist: 0.236\n",
      "    step: 150; loss: 0.192; l2dist: 0.327\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.407; l2dist: 0.000\n",
      "    step: 50; loss: 0.093; l2dist: 0.252\n",
      "    step: 100; loss: 0.100; l2dist: 0.256\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.126; l2dist: 0.000\n",
      "    step: 50; loss: 0.058; l2dist: 0.217\n",
      "    step: 100; loss: 0.071; l2dist: 0.228\n",
      "binary step: 0; number of successful adv: 56/100\n",
      "    step: 0; loss: 0.575; l2dist: 0.000\n",
      "    step: 50; loss: 0.143; l2dist: 0.325\n",
      "    step: 100; loss: 0.164; l2dist: 0.337\n",
      "binary step: 1; number of successful adv: 96/100\n",
      "    step: 0; loss: 0.857; l2dist: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    step: 50; loss: 0.130; l2dist: 0.298\n",
      "    step: 100; loss: 0.172; l2dist: 0.333\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.543; l2dist: 0.000\n",
      "    step: 50; loss: 0.102; l2dist: 0.276\n",
      "    step: 100; loss: 0.121; l2dist: 0.282\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.387; l2dist: 0.000\n",
      "    step: 50; loss: 0.085; l2dist: 0.249\n",
      "    step: 100; loss: 0.084; l2dist: 0.241\n",
      "    step: 150; loss: 0.148; l2dist: 0.322\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.128; l2dist: 0.000\n",
      "    step: 50; loss: 0.062; l2dist: 0.222\n",
      "    step: 100; loss: 0.066; l2dist: 0.222\n",
      "binary step: 0; number of successful adv: 64/100\n",
      "    step: 0; loss: 0.510; l2dist: 0.000\n",
      "    step: 50; loss: 0.134; l2dist: 0.316\n",
      "    step: 100; loss: 0.166; l2dist: 0.336\n",
      "binary step: 1; number of successful adv: 95/100\n",
      "    step: 0; loss: 0.876; l2dist: 0.000\n",
      "    step: 50; loss: 0.167; l2dist: 0.334\n",
      "    step: 100; loss: 0.177; l2dist: 0.323\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.539; l2dist: 0.000\n",
      "    step: 50; loss: 0.120; l2dist: 0.291\n",
      "    step: 100; loss: 0.164; l2dist: 0.295\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.359; l2dist: 0.000\n",
      "    step: 50; loss: 0.102; l2dist: 0.265\n",
      "    step: 100; loss: 0.094; l2dist: 0.241\n",
      "    step: 150; loss: 0.113; l2dist: 0.280\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.134; l2dist: 0.000\n",
      "    step: 50; loss: 0.057; l2dist: 0.215\n",
      "    step: 100; loss: 0.057; l2dist: 0.208\n",
      "    step: 150; loss: 0.082; l2dist: 0.243\n",
      "binary step: 0; number of successful adv: 56/100\n",
      "    step: 0; loss: 0.635; l2dist: 0.000\n",
      "    step: 50; loss: 0.165; l2dist: 0.348\n",
      "    step: 100; loss: 0.196; l2dist: 0.385\n",
      "binary step: 1; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.357; l2dist: 0.000\n",
      "    step: 50; loss: 0.104; l2dist: 0.284\n",
      "    step: 100; loss: 0.146; l2dist: 0.316\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.275; l2dist: 0.000\n",
      "    step: 50; loss: 0.087; l2dist: 0.258\n",
      "    step: 100; loss: 0.134; l2dist: 0.298\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.248; l2dist: 0.000\n",
      "    step: 50; loss: 0.087; l2dist: 0.254\n",
      "    step: 100; loss: 0.107; l2dist: 0.281\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.121; l2dist: 0.000\n",
      "    step: 50; loss: 0.052; l2dist: 0.211\n",
      "    step: 100; loss: 0.054; l2dist: 0.212\n",
      "binary step: 0; number of successful adv: 87/100\n",
      "    step: 0; loss: 0.205; l2dist: 0.000\n",
      "    step: 50; loss: 0.058; l2dist: 0.204\n",
      "    step: 100; loss: 0.061; l2dist: 0.191\n",
      "binary step: 1; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.131; l2dist: 0.000\n",
      "    step: 50; loss: 0.047; l2dist: 0.193\n",
      "    step: 100; loss: 0.044; l2dist: 0.167\n",
      "    step: 150; loss: 0.057; l2dist: 0.187\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.119; l2dist: 0.000\n",
      "    step: 50; loss: 0.043; l2dist: 0.184\n",
      "    step: 100; loss: 0.038; l2dist: 0.157\n",
      "    step: 150; loss: 0.052; l2dist: 0.182\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.110; l2dist: 0.000\n",
      "    step: 50; loss: 0.039; l2dist: 0.174\n",
      "    step: 100; loss: 0.048; l2dist: 0.161\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.139; l2dist: 0.000\n",
      "    step: 50; loss: 0.060; l2dist: 0.220\n",
      "    step: 100; loss: 0.061; l2dist: 0.206\n",
      "binary step: 0; number of successful adv: 57/100\n",
      "    step: 0; loss: 0.634; l2dist: 0.000\n",
      "    step: 50; loss: 0.177; l2dist: 0.347\n",
      "    step: 100; loss: 0.239; l2dist: 0.393\n",
      "binary step: 1; number of successful adv: 91/100\n",
      "    step: 0; loss: 1.644; l2dist: 0.000\n",
      "    step: 50; loss: 0.270; l2dist: 0.401\n",
      "    step: 100; loss: 0.182; l2dist: 0.332\n",
      "    step: 150; loss: 0.215; l2dist: 0.372\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.948; l2dist: 0.000\n",
      "    step: 50; loss: 0.138; l2dist: 0.309\n",
      "    step: 100; loss: 0.223; l2dist: 0.355\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.752; l2dist: 0.000\n",
      "    step: 50; loss: 0.129; l2dist: 0.295\n",
      "    step: 100; loss: 0.147; l2dist: 0.302\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.132; l2dist: 0.000\n",
      "    step: 50; loss: 0.058; l2dist: 0.220\n",
      "    step: 100; loss: 0.060; l2dist: 0.206\n",
      "binary step: 0; number of successful adv: 59/100\n",
      "    step: 0; loss: 0.565; l2dist: 0.000\n",
      "    step: 50; loss: 0.155; l2dist: 0.323\n",
      "    step: 100; loss: 0.180; l2dist: 0.340\n",
      "binary step: 1; number of successful adv: 95/100\n",
      "    step: 0; loss: 0.933; l2dist: 0.000\n",
      "    step: 50; loss: 0.246; l2dist: 0.363\n",
      "    step: 100; loss: 0.180; l2dist: 0.321\n",
      "    step: 150; loss: 0.163; l2dist: 0.319\n",
      "    step: 200; loss: 0.141; l2dist: 0.299\n",
      "    step: 250; loss: 0.185; l2dist: 0.329\n",
      "binary step: 2; number of successful adv: 99/100\n",
      "    step: 0; loss: 1.674; l2dist: 0.000\n",
      "    step: 50; loss: 0.142; l2dist: 0.292\n",
      "    step: 100; loss: 0.117; l2dist: 0.257\n",
      "    step: 150; loss: 0.288; l2dist: 0.341\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 1.049; l2dist: 0.000\n",
      "    step: 50; loss: 0.133; l2dist: 0.282\n",
      "    step: 100; loss: 0.110; l2dist: 0.254\n",
      "    step: 150; loss: 0.164; l2dist: 0.288\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.131; l2dist: 0.000\n",
      "    step: 50; loss: 0.050; l2dist: 0.208\n",
      "    step: 100; loss: 0.054; l2dist: 0.212\n",
      "binary step: 0; number of successful adv: 86/100\n",
      "    step: 0; loss: 0.232; l2dist: 0.000\n",
      "    step: 50; loss: 0.067; l2dist: 0.222\n",
      "    step: 100; loss: 0.074; l2dist: 0.212\n",
      "binary step: 1; number of successful adv: 96/100\n",
      "    step: 0; loss: 0.648; l2dist: 0.000\n",
      "    step: 50; loss: 0.080; l2dist: 0.232\n",
      "    step: 100; loss: 0.074; l2dist: 0.195\n",
      "    step: 150; loss: 0.080; l2dist: 0.215\n",
      "binary step: 2; number of successful adv: 99/100\n",
      "    step: 0; loss: 1.331; l2dist: 0.000\n",
      "    step: 50; loss: 0.113; l2dist: 0.246\n",
      "    step: 100; loss: 0.051; l2dist: 0.170\n",
      "    step: 150; loss: 0.067; l2dist: 0.176\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.777; l2dist: 0.000\n",
      "    step: 50; loss: 0.079; l2dist: 0.219\n",
      "    step: 100; loss: 0.053; l2dist: 0.170\n",
      "    step: 150; loss: 0.083; l2dist: 0.200\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.113; l2dist: 0.000\n",
      "    step: 50; loss: 0.050; l2dist: 0.194\n",
      "    step: 100; loss: 0.048; l2dist: 0.183\n",
      "    step: 150; loss: 0.062; l2dist: 0.227\n",
      "binary step: 0; number of successful adv: 88/100\n",
      "    step: 0; loss: 0.192; l2dist: 0.000\n",
      "    step: 50; loss: 0.057; l2dist: 0.207\n",
      "    step: 100; loss: 0.081; l2dist: 0.210\n",
      "binary step: 1; number of successful adv: 96/100\n",
      "    step: 0; loss: 0.586; l2dist: 0.000\n",
      "    step: 50; loss: 0.066; l2dist: 0.206\n",
      "    step: 100; loss: 0.049; l2dist: 0.168\n",
      "    step: 150; loss: 0.092; l2dist: 0.212\n",
      "binary step: 2; number of successful adv: 99/100\n",
      "    step: 0; loss: 1.306; l2dist: 0.000\n",
      "    step: 50; loss: 0.073; l2dist: 0.215\n",
      "    step: 100; loss: 0.046; l2dist: 0.151\n",
      "    step: 150; loss: 0.073; l2dist: 0.173\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.800; l2dist: 0.000\n",
      "    step: 50; loss: 0.059; l2dist: 0.195\n",
      "    step: 100; loss: 0.054; l2dist: 0.154\n",
      "    step: 150; loss: 0.080; l2dist: 0.181\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.135; l2dist: 0.000\n",
      "    step: 50; loss: 0.060; l2dist: 0.216\n",
      "    step: 100; loss: 0.055; l2dist: 0.204\n",
      "    step: 150; loss: 0.068; l2dist: 0.237\n",
      "binary step: 0; number of successful adv: 77/100\n",
      "    step: 0; loss: 0.375; l2dist: 0.000\n",
      "    step: 50; loss: 0.116; l2dist: 0.287\n",
      "    step: 100; loss: 0.148; l2dist: 0.321\n",
      "binary step: 1; number of successful adv: 93/100\n",
      "    step: 0; loss: 1.098; l2dist: 0.000\n",
      "    step: 50; loss: 0.115; l2dist: 0.272\n",
      "    step: 100; loss: 0.137; l2dist: 0.262\n",
      "binary step: 2; number of successful adv: 98/100\n",
      "    step: 0; loss: 2.269; l2dist: 0.000\n",
      "    step: 50; loss: 0.252; l2dist: 0.344\n",
      "    step: 100; loss: 0.099; l2dist: 0.215\n",
      "    step: 150; loss: 0.109; l2dist: 0.232\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 1.328; l2dist: 0.000\n",
      "    step: 50; loss: 0.129; l2dist: 0.277\n",
      "    step: 100; loss: 0.073; l2dist: 0.204\n",
      "    step: 150; loss: 0.150; l2dist: 0.247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.136; l2dist: 0.000\n",
      "    step: 50; loss: 0.056; l2dist: 0.217\n",
      "    step: 100; loss: 0.059; l2dist: 0.212\n",
      "binary step: 0; number of successful adv: 63/100\n",
      "    step: 0; loss: 0.555; l2dist: 0.000\n",
      "    step: 50; loss: 0.145; l2dist: 0.312\n",
      "    step: 100; loss: 0.153; l2dist: 0.332\n",
      "binary step: 1; number of successful adv: 95/100\n",
      "    step: 0; loss: 0.981; l2dist: 0.000\n",
      "    step: 50; loss: 0.118; l2dist: 0.299\n",
      "    step: 100; loss: 0.144; l2dist: 0.299\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.570; l2dist: 0.000\n",
      "    step: 50; loss: 0.110; l2dist: 0.280\n",
      "    step: 100; loss: 0.115; l2dist: 0.286\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.458; l2dist: 0.000\n",
      "    step: 50; loss: 0.104; l2dist: 0.264\n",
      "    step: 100; loss: 0.122; l2dist: 0.275\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.131; l2dist: 0.000\n",
      "    step: 50; loss: 0.059; l2dist: 0.220\n",
      "    step: 100; loss: 0.055; l2dist: 0.209\n",
      "    step: 150; loss: 0.071; l2dist: 0.252\n",
      "binary step: 0; number of successful adv: 89/100\n",
      "    step: 0; loss: 0.201; l2dist: 0.000\n",
      "    step: 50; loss: 0.056; l2dist: 0.208\n",
      "    step: 100; loss: 0.067; l2dist: 0.209\n",
      "binary step: 1; number of successful adv: 96/100\n",
      "    step: 0; loss: 0.610; l2dist: 0.000\n",
      "    step: 50; loss: 0.071; l2dist: 0.222\n",
      "    step: 100; loss: 0.076; l2dist: 0.201\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.369; l2dist: 0.000\n",
      "    step: 50; loss: 0.064; l2dist: 0.211\n",
      "    step: 100; loss: 0.061; l2dist: 0.182\n",
      "    step: 150; loss: 0.065; l2dist: 0.188\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.292; l2dist: 0.000\n",
      "    step: 50; loss: 0.061; l2dist: 0.204\n",
      "    step: 100; loss: 0.051; l2dist: 0.171\n",
      "    step: 150; loss: 0.069; l2dist: 0.211\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.123; l2dist: 0.000\n",
      "    step: 50; loss: 0.055; l2dist: 0.212\n",
      "    step: 100; loss: 0.055; l2dist: 0.214\n",
      "    step: 150; loss: 0.077; l2dist: 0.239\n",
      "binary step: 0; number of successful adv: 61/100\n",
      "    step: 0; loss: 0.534; l2dist: 0.000\n",
      "    step: 50; loss: 0.167; l2dist: 0.346\n",
      "    step: 100; loss: 0.188; l2dist: 0.342\n",
      "binary step: 1; number of successful adv: 90/100\n",
      "    step: 0; loss: 1.556; l2dist: 0.000\n",
      "    step: 50; loss: 0.220; l2dist: 0.373\n",
      "    step: 100; loss: 0.202; l2dist: 0.341\n",
      "    step: 150; loss: 0.163; l2dist: 0.314\n",
      "    step: 200; loss: 0.382; l2dist: 0.431\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.929; l2dist: 0.000\n",
      "    step: 50; loss: 0.143; l2dist: 0.313\n",
      "    step: 100; loss: 0.131; l2dist: 0.274\n",
      "    step: 150; loss: 0.232; l2dist: 0.368\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.598; l2dist: 0.000\n",
      "    step: 50; loss: 0.114; l2dist: 0.275\n",
      "    step: 100; loss: 0.126; l2dist: 0.271\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.137; l2dist: 0.000\n",
      "    step: 50; loss: 0.059; l2dist: 0.218\n",
      "    step: 100; loss: 0.060; l2dist: 0.220\n",
      "binary step: 0; number of successful adv: 78/100\n",
      "    step: 0; loss: 0.340; l2dist: 0.000\n",
      "    step: 50; loss: 0.087; l2dist: 0.243\n",
      "    step: 100; loss: 0.101; l2dist: 0.262\n",
      "binary step: 1; number of successful adv: 97/100\n",
      "    step: 0; loss: 0.547; l2dist: 0.000\n",
      "    step: 50; loss: 0.086; l2dist: 0.233\n",
      "    step: 100; loss: 0.075; l2dist: 0.203\n",
      "    step: 150; loss: 0.094; l2dist: 0.232\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.356; l2dist: 0.000\n",
      "    step: 50; loss: 0.069; l2dist: 0.222\n",
      "    step: 100; loss: 0.068; l2dist: 0.199\n",
      "    step: 150; loss: 0.072; l2dist: 0.208\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.250; l2dist: 0.000\n",
      "    step: 50; loss: 0.056; l2dist: 0.204\n",
      "    step: 100; loss: 0.052; l2dist: 0.169\n",
      "    step: 150; loss: 0.066; l2dist: 0.208\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.121; l2dist: 0.000\n",
      "    step: 50; loss: 0.054; l2dist: 0.209\n",
      "    step: 100; loss: 0.056; l2dist: 0.207\n",
      "binary step: 0; number of successful adv: 74/100\n",
      "    step: 0; loss: 0.371; l2dist: 0.000\n",
      "    step: 50; loss: 0.103; l2dist: 0.268\n",
      "    step: 100; loss: 0.106; l2dist: 0.269\n",
      "binary step: 1; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.207; l2dist: 0.000\n",
      "    step: 50; loss: 0.065; l2dist: 0.215\n",
      "    step: 100; loss: 0.067; l2dist: 0.197\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.173; l2dist: 0.000\n",
      "    step: 50; loss: 0.061; l2dist: 0.210\n",
      "    step: 100; loss: 0.066; l2dist: 0.198\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.158; l2dist: 0.000\n",
      "    step: 50; loss: 0.056; l2dist: 0.202\n",
      "    step: 100; loss: 0.067; l2dist: 0.207\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.135; l2dist: 0.000\n",
      "    step: 50; loss: 0.060; l2dist: 0.233\n",
      "    step: 100; loss: 0.065; l2dist: 0.218\n",
      "binary step: 0; number of successful adv: 49/100\n",
      "    step: 0; loss: 0.745; l2dist: 0.000\n",
      "    step: 50; loss: 0.183; l2dist: 0.378\n",
      "    step: 100; loss: 0.176; l2dist: 0.341\n",
      "    step: 150; loss: 0.271; l2dist: 0.419\n",
      "binary step: 1; number of successful adv: 88/100\n",
      "    step: 0; loss: 2.074; l2dist: 0.000\n",
      "    step: 50; loss: 0.191; l2dist: 0.366\n",
      "    step: 100; loss: 0.194; l2dist: 0.334\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 1.227; l2dist: 0.000\n",
      "    step: 50; loss: 0.183; l2dist: 0.357\n",
      "    step: 100; loss: 0.203; l2dist: 0.359\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 1.070; l2dist: 0.000\n",
      "    step: 50; loss: 0.157; l2dist: 0.329\n",
      "    step: 100; loss: 0.157; l2dist: 0.325\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.127; l2dist: 0.000\n",
      "    step: 50; loss: 0.056; l2dist: 0.215\n",
      "    step: 100; loss: 0.055; l2dist: 0.202\n",
      "    step: 150; loss: 0.064; l2dist: 0.227\n",
      "binary step: 0; number of successful adv: 67/100\n",
      "    step: 0; loss: 0.484; l2dist: 0.000\n",
      "    step: 50; loss: 0.112; l2dist: 0.290\n",
      "    step: 100; loss: 0.117; l2dist: 0.275\n",
      "binary step: 1; number of successful adv: 98/100\n",
      "    step: 0; loss: 0.532; l2dist: 0.000\n",
      "    step: 50; loss: 0.094; l2dist: 0.258\n",
      "    step: 100; loss: 0.099; l2dist: 0.248\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.354; l2dist: 0.000\n",
      "    step: 50; loss: 0.084; l2dist: 0.254\n",
      "    step: 100; loss: 0.112; l2dist: 0.263\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.265; l2dist: 0.000\n",
      "    step: 50; loss: 0.069; l2dist: 0.226\n",
      "    step: 100; loss: 0.081; l2dist: 0.224\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.132; l2dist: 0.000\n",
      "    step: 50; loss: 0.066; l2dist: 0.224\n",
      "    step: 100; loss: 0.068; l2dist: 0.225\n",
      "binary step: 0; number of successful adv: 55/100\n",
      "    step: 0; loss: 0.647; l2dist: 0.000\n",
      "    step: 50; loss: 0.156; l2dist: 0.336\n",
      "    step: 100; loss: 0.210; l2dist: 0.390\n",
      "binary step: 1; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.360; l2dist: 0.000\n",
      "    step: 50; loss: 0.109; l2dist: 0.288\n",
      "    step: 100; loss: 0.147; l2dist: 0.318\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.283; l2dist: 0.000\n",
      "    step: 50; loss: 0.085; l2dist: 0.256\n",
      "    step: 100; loss: 0.125; l2dist: 0.285\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.269; l2dist: 0.000\n",
      "    step: 50; loss: 0.080; l2dist: 0.249\n",
      "    step: 100; loss: 0.120; l2dist: 0.296\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.121; l2dist: 0.000\n",
      "    step: 50; loss: 0.051; l2dist: 0.204\n",
      "    step: 100; loss: 0.050; l2dist: 0.193\n",
      "    step: 150; loss: 0.066; l2dist: 0.210\n",
      "binary step: 0; number of successful adv: 41/100\n",
      "    step: 0; loss: 0.741; l2dist: 0.000\n",
      "    step: 50; loss: 0.155; l2dist: 0.334\n",
      "    step: 100; loss: 0.203; l2dist: 0.393\n",
      "binary step: 1; number of successful adv: 97/100\n",
      "    step: 0; loss: 0.780; l2dist: 0.000\n",
      "    step: 50; loss: 0.130; l2dist: 0.311\n",
      "    step: 100; loss: 0.191; l2dist: 0.372\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.457; l2dist: 0.000\n",
      "    step: 50; loss: 0.109; l2dist: 0.285\n",
      "    step: 100; loss: 0.093; l2dist: 0.240\n",
      "    step: 150; loss: 0.116; l2dist: 0.278\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.312; l2dist: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    step: 50; loss: 0.089; l2dist: 0.253\n",
      "    step: 100; loss: 0.091; l2dist: 0.261\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.125; l2dist: 0.000\n",
      "    step: 50; loss: 0.057; l2dist: 0.225\n",
      "    step: 100; loss: 0.056; l2dist: 0.210\n",
      "    step: 150; loss: 0.070; l2dist: 0.224\n",
      "binary step: 0; number of successful adv: 59/100\n",
      "    step: 0; loss: 0.564; l2dist: 0.000\n",
      "    step: 50; loss: 0.148; l2dist: 0.333\n",
      "    step: 100; loss: 0.147; l2dist: 0.322\n",
      "    step: 150; loss: 0.217; l2dist: 0.410\n",
      "binary step: 1; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.313; l2dist: 0.000\n",
      "    step: 50; loss: 0.106; l2dist: 0.272\n",
      "    step: 100; loss: 0.095; l2dist: 0.256\n",
      "    step: 150; loss: 0.128; l2dist: 0.295\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.273; l2dist: 0.000\n",
      "    step: 50; loss: 0.081; l2dist: 0.239\n",
      "    step: 100; loss: 0.123; l2dist: 0.269\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.261; l2dist: 0.000\n",
      "    step: 50; loss: 0.081; l2dist: 0.242\n",
      "    step: 100; loss: 0.093; l2dist: 0.254\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.121; l2dist: 0.000\n",
      "    step: 50; loss: 0.052; l2dist: 0.211\n",
      "    step: 100; loss: 0.056; l2dist: 0.200\n",
      "binary step: 0; number of successful adv: 57/100\n",
      "    step: 0; loss: 0.551; l2dist: 0.000\n",
      "    step: 50; loss: 0.131; l2dist: 0.298\n",
      "    step: 100; loss: 0.160; l2dist: 0.330\n",
      "binary step: 1; number of successful adv: 99/100\n",
      "    step: 0; loss: 0.439; l2dist: 0.000\n",
      "    step: 50; loss: 0.100; l2dist: 0.263\n",
      "    step: 100; loss: 0.125; l2dist: 0.286\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.267; l2dist: 0.000\n",
      "    step: 50; loss: 0.064; l2dist: 0.220\n",
      "    step: 100; loss: 0.113; l2dist: 0.250\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.224; l2dist: 0.000\n",
      "    step: 50; loss: 0.059; l2dist: 0.210\n",
      "    step: 100; loss: 0.061; l2dist: 0.202\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.121; l2dist: 0.000\n",
      "    step: 50; loss: 0.050; l2dist: 0.206\n",
      "    step: 100; loss: 0.055; l2dist: 0.195\n",
      "binary step: 0; number of successful adv: 58/100\n",
      "    step: 0; loss: 0.559; l2dist: 0.000\n",
      "    step: 50; loss: 0.129; l2dist: 0.313\n",
      "    step: 100; loss: 0.164; l2dist: 0.325\n",
      "binary step: 1; number of successful adv: 94/100\n",
      "    step: 0; loss: 1.057; l2dist: 0.000\n",
      "    step: 50; loss: 0.140; l2dist: 0.309\n",
      "    step: 100; loss: 0.153; l2dist: 0.304\n",
      "binary step: 2; number of successful adv: 99/100\n",
      "    step: 0; loss: 1.707; l2dist: 0.000\n",
      "    step: 50; loss: 0.127; l2dist: 0.286\n",
      "    step: 100; loss: 0.096; l2dist: 0.235\n",
      "    step: 150; loss: 0.153; l2dist: 0.300\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 1.089; l2dist: 0.000\n",
      "    step: 50; loss: 0.108; l2dist: 0.273\n",
      "    step: 100; loss: 0.104; l2dist: 0.250\n",
      "    step: 150; loss: 0.162; l2dist: 0.287\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.125; l2dist: 0.000\n",
      "    step: 50; loss: 0.054; l2dist: 0.212\n",
      "    step: 100; loss: 0.054; l2dist: 0.194\n",
      "binary step: 0; number of successful adv: 68/100\n",
      "    step: 0; loss: 0.456; l2dist: 0.000\n",
      "    step: 50; loss: 0.110; l2dist: 0.276\n",
      "    step: 100; loss: 0.161; l2dist: 0.329\n",
      "binary step: 1; number of successful adv: 96/100\n",
      "    step: 0; loss: 0.749; l2dist: 0.000\n",
      "    step: 50; loss: 0.116; l2dist: 0.277\n",
      "    step: 100; loss: 0.107; l2dist: 0.244\n",
      "    step: 150; loss: 0.117; l2dist: 0.274\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.436; l2dist: 0.000\n",
      "    step: 50; loss: 0.073; l2dist: 0.222\n",
      "    step: 100; loss: 0.080; l2dist: 0.217\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.289; l2dist: 0.000\n",
      "    step: 50; loss: 0.062; l2dist: 0.210\n",
      "    step: 100; loss: 0.064; l2dist: 0.186\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.126; l2dist: 0.000\n",
      "    step: 50; loss: 0.053; l2dist: 0.203\n",
      "    step: 100; loss: 0.054; l2dist: 0.197\n",
      "binary step: 0; number of successful adv: 55/100\n",
      "    step: 0; loss: 0.589; l2dist: 0.000\n",
      "    step: 50; loss: 0.131; l2dist: 0.307\n",
      "    step: 100; loss: 0.190; l2dist: 0.352\n",
      "binary step: 1; number of successful adv: 99/100\n",
      "    step: 0; loss: 0.446; l2dist: 0.000\n",
      "    step: 50; loss: 0.104; l2dist: 0.274\n",
      "    step: 100; loss: 0.135; l2dist: 0.305\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.296; l2dist: 0.000\n",
      "    step: 50; loss: 0.077; l2dist: 0.239\n",
      "    step: 100; loss: 0.096; l2dist: 0.243\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.301; l2dist: 0.000\n",
      "    step: 50; loss: 0.075; l2dist: 0.235\n",
      "    step: 100; loss: 0.087; l2dist: 0.237\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.131; l2dist: 0.000\n",
      "    step: 50; loss: 0.058; l2dist: 0.218\n",
      "    step: 100; loss: 0.064; l2dist: 0.218\n",
      "binary step: 0; number of successful adv: 63/100\n",
      "    step: 0; loss: 0.508; l2dist: 0.000\n",
      "    step: 50; loss: 0.130; l2dist: 0.310\n",
      "    step: 100; loss: 0.155; l2dist: 0.312\n",
      "binary step: 1; number of successful adv: 93/100\n",
      "    step: 0; loss: 1.215; l2dist: 0.000\n",
      "    step: 50; loss: 0.138; l2dist: 0.308\n",
      "    step: 100; loss: 0.195; l2dist: 0.293\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.725; l2dist: 0.000\n",
      "    step: 50; loss: 0.086; l2dist: 0.251\n",
      "    step: 100; loss: 0.093; l2dist: 0.231\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.477; l2dist: 0.000\n",
      "    step: 50; loss: 0.111; l2dist: 0.267\n",
      "    step: 100; loss: 0.090; l2dist: 0.224\n",
      "    step: 150; loss: 0.106; l2dist: 0.264\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.118; l2dist: 0.000\n",
      "    step: 50; loss: 0.057; l2dist: 0.213\n",
      "    step: 100; loss: 0.059; l2dist: 0.215\n",
      "binary step: 0; number of successful adv: 79/100\n",
      "    step: 0; loss: 0.311; l2dist: 0.000\n",
      "    step: 50; loss: 0.076; l2dist: 0.240\n",
      "    step: 100; loss: 0.093; l2dist: 0.229\n",
      "binary step: 1; number of successful adv: 95/100\n",
      "    step: 0; loss: 0.793; l2dist: 0.000\n",
      "    step: 50; loss: 0.096; l2dist: 0.252\n",
      "    step: 100; loss: 0.089; l2dist: 0.216\n",
      "    step: 150; loss: 0.120; l2dist: 0.258\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.487; l2dist: 0.000\n",
      "    step: 50; loss: 0.079; l2dist: 0.237\n",
      "    step: 100; loss: 0.070; l2dist: 0.204\n",
      "    step: 150; loss: 0.087; l2dist: 0.228\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.330; l2dist: 0.000\n",
      "    step: 50; loss: 0.067; l2dist: 0.215\n",
      "    step: 100; loss: 0.090; l2dist: 0.215\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.129; l2dist: 0.000\n",
      "    step: 50; loss: 0.056; l2dist: 0.219\n",
      "    step: 100; loss: 0.057; l2dist: 0.216\n",
      "binary step: 0; number of successful adv: 83/100\n",
      "    step: 0; loss: 0.264; l2dist: 0.000\n",
      "    step: 50; loss: 0.070; l2dist: 0.224\n",
      "    step: 100; loss: 0.070; l2dist: 0.221\n",
      "binary step: 1; number of successful adv: 99/100\n",
      "    step: 0; loss: 0.244; l2dist: 0.000\n",
      "    step: 50; loss: 0.056; l2dist: 0.200\n",
      "    step: 100; loss: 0.064; l2dist: 0.203\n",
      "binary step: 2; number of successful adv: 99/100\n",
      "    step: 0; loss: 1.064; l2dist: 0.000\n",
      "    step: 50; loss: 0.067; l2dist: 0.217\n",
      "    step: 100; loss: 0.040; l2dist: 0.156\n",
      "    step: 150; loss: 0.052; l2dist: 0.164\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.634; l2dist: 0.000\n",
      "    step: 50; loss: 0.054; l2dist: 0.202\n",
      "    step: 100; loss: 0.054; l2dist: 0.172\n",
      "    step: 150; loss: 0.048; l2dist: 0.167\n",
      "    step: 200; loss: 0.070; l2dist: 0.190\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.129; l2dist: 0.000\n",
      "    step: 50; loss: 0.062; l2dist: 0.225\n",
      "    step: 100; loss: 0.055; l2dist: 0.212\n",
      "    step: 150; loss: 0.071; l2dist: 0.249\n",
      "binary step: 0; number of successful adv: 92/100\n",
      "    step: 0; loss: 0.167; l2dist: 0.000\n",
      "    step: 50; loss: 0.053; l2dist: 0.199\n",
      "    step: 100; loss: 0.054; l2dist: 0.183\n",
      "binary step: 1; number of successful adv: 97/100\n",
      "    step: 0; loss: 0.405; l2dist: 0.000\n",
      "    step: 50; loss: 0.053; l2dist: 0.196\n",
      "    step: 100; loss: 0.057; l2dist: 0.193\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.240; l2dist: 0.000\n",
      "    step: 50; loss: 0.046; l2dist: 0.181\n",
      "    step: 100; loss: 0.044; l2dist: 0.163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    step: 150; loss: 0.049; l2dist: 0.160\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.191; l2dist: 0.000\n",
      "    step: 50; loss: 0.042; l2dist: 0.177\n",
      "    step: 100; loss: 0.040; l2dist: 0.161\n",
      "    step: 150; loss: 0.046; l2dist: 0.168\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.123; l2dist: 0.000\n",
      "    step: 50; loss: 0.053; l2dist: 0.211\n",
      "    step: 100; loss: 0.057; l2dist: 0.197\n",
      "binary step: 0; number of successful adv: 52/100\n",
      "    step: 0; loss: 0.623; l2dist: 0.000\n",
      "    step: 50; loss: 0.151; l2dist: 0.328\n",
      "    step: 100; loss: 0.203; l2dist: 0.384\n",
      "binary step: 1; number of successful adv: 90/100\n",
      "    step: 0; loss: 1.584; l2dist: 0.000\n",
      "    step: 50; loss: 0.150; l2dist: 0.332\n",
      "    step: 100; loss: 0.157; l2dist: 0.291\n",
      "binary step: 2; number of successful adv: 96/100\n",
      "    step: 0; loss: 5.629; l2dist: 0.000\n",
      "    step: 50; loss: 0.397; l2dist: 0.450\n",
      "    step: 100; loss: 0.147; l2dist: 0.248\n",
      "    step: 150; loss: 0.118; l2dist: 0.242\n",
      "    step: 200; loss: 0.157; l2dist: 0.277\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 3.166; l2dist: 0.000\n",
      "    step: 50; loss: 0.216; l2dist: 0.359\n",
      "    step: 100; loss: 0.122; l2dist: 0.231\n",
      "    step: 150; loss: 0.168; l2dist: 0.276\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.125; l2dist: 0.000\n",
      "    step: 50; loss: 0.051; l2dist: 0.201\n",
      "    step: 100; loss: 0.057; l2dist: 0.198\n",
      "binary step: 0; number of successful adv: 63/100\n",
      "    step: 0; loss: 0.515; l2dist: 0.000\n",
      "    step: 50; loss: 0.118; l2dist: 0.295\n",
      "    step: 100; loss: 0.126; l2dist: 0.295\n",
      "binary step: 1; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.285; l2dist: 0.000\n",
      "    step: 50; loss: 0.085; l2dist: 0.251\n",
      "    step: 100; loss: 0.101; l2dist: 0.247\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.262; l2dist: 0.000\n",
      "    step: 50; loss: 0.082; l2dist: 0.248\n",
      "    step: 100; loss: 0.090; l2dist: 0.245\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.216; l2dist: 0.000\n",
      "    step: 50; loss: 0.060; l2dist: 0.212\n",
      "    step: 100; loss: 0.075; l2dist: 0.219\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.117; l2dist: 0.000\n",
      "    step: 50; loss: 0.048; l2dist: 0.198\n",
      "    step: 100; loss: 0.054; l2dist: 0.209\n",
      "binary step: 0; number of successful adv: 90/100\n",
      "    step: 0; loss: 0.166; l2dist: 0.000\n",
      "    step: 50; loss: 0.055; l2dist: 0.193\n",
      "    step: 100; loss: 0.044; l2dist: 0.163\n",
      "    step: 150; loss: 0.050; l2dist: 0.187\n",
      "binary step: 1; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.102; l2dist: 0.000\n",
      "    step: 50; loss: 0.040; l2dist: 0.173\n",
      "    step: 100; loss: 0.033; l2dist: 0.140\n",
      "    step: 150; loss: 0.037; l2dist: 0.152\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.093; l2dist: 0.000\n",
      "    step: 50; loss: 0.036; l2dist: 0.167\n",
      "    step: 100; loss: 0.031; l2dist: 0.134\n",
      "    step: 150; loss: 0.035; l2dist: 0.145\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.089; l2dist: 0.000\n",
      "    step: 50; loss: 0.037; l2dist: 0.171\n",
      "    step: 100; loss: 0.028; l2dist: 0.131\n",
      "    step: 150; loss: 0.033; l2dist: 0.142\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.136; l2dist: 0.000\n",
      "    step: 50; loss: 0.064; l2dist: 0.225\n",
      "    step: 100; loss: 0.062; l2dist: 0.223\n",
      "    step: 150; loss: 0.071; l2dist: 0.241\n",
      "binary step: 0; number of successful adv: 79/100\n",
      "    step: 0; loss: 0.349; l2dist: 0.000\n",
      "    step: 50; loss: 0.095; l2dist: 0.258\n",
      "    step: 100; loss: 0.134; l2dist: 0.291\n",
      "binary step: 1; number of successful adv: 90/100\n",
      "    step: 0; loss: 1.595; l2dist: 0.000\n",
      "    step: 50; loss: 0.148; l2dist: 0.313\n",
      "    step: 100; loss: 0.113; l2dist: 0.238\n",
      "    step: 150; loss: 0.280; l2dist: 0.321\n",
      "binary step: 2; number of successful adv: 99/100\n",
      "    step: 0; loss: 2.300; l2dist: 0.000\n",
      "    step: 50; loss: 0.163; l2dist: 0.316\n",
      "    step: 100; loss: 0.107; l2dist: 0.238\n",
      "    step: 150; loss: 0.184; l2dist: 0.292\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 1.371; l2dist: 0.000\n",
      "    step: 50; loss: 0.147; l2dist: 0.302\n",
      "    step: 100; loss: 0.140; l2dist: 0.264\n",
      "    step: 150; loss: 0.110; l2dist: 0.244\n",
      "    step: 200; loss: 0.144; l2dist: 0.277\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.122; l2dist: 0.000\n",
      "    step: 50; loss: 0.050; l2dist: 0.204\n",
      "    step: 100; loss: 0.052; l2dist: 0.200\n",
      "binary step: 0; number of successful adv: 76/100\n",
      "    step: 0; loss: 0.342; l2dist: 0.000\n",
      "    step: 50; loss: 0.089; l2dist: 0.249\n",
      "    step: 100; loss: 0.101; l2dist: 0.264\n",
      "binary step: 1; number of successful adv: 99/100\n",
      "    step: 0; loss: 0.283; l2dist: 0.000\n",
      "    step: 50; loss: 0.076; l2dist: 0.234\n",
      "    step: 100; loss: 0.081; l2dist: 0.216\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.202; l2dist: 0.000\n",
      "    step: 50; loss: 0.058; l2dist: 0.206\n",
      "    step: 100; loss: 0.053; l2dist: 0.189\n",
      "    step: 150; loss: 0.074; l2dist: 0.231\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.156; l2dist: 0.000\n",
      "    step: 50; loss: 0.049; l2dist: 0.196\n",
      "    step: 100; loss: 0.051; l2dist: 0.180\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.134; l2dist: 0.000\n",
      "    step: 50; loss: 0.063; l2dist: 0.225\n",
      "    step: 100; loss: 0.058; l2dist: 0.211\n",
      "    step: 150; loss: 0.079; l2dist: 0.240\n",
      "binary step: 0; number of successful adv: 57/100\n",
      "    step: 0; loss: 0.605; l2dist: 0.000\n",
      "    step: 50; loss: 0.153; l2dist: 0.329\n",
      "    step: 100; loss: 0.171; l2dist: 0.337\n",
      "binary step: 1; number of successful adv: 94/100\n",
      "    step: 0; loss: 1.017; l2dist: 0.000\n",
      "    step: 50; loss: 0.138; l2dist: 0.310\n",
      "    step: 100; loss: 0.149; l2dist: 0.312\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.602; l2dist: 0.000\n",
      "    step: 50; loss: 0.130; l2dist: 0.297\n",
      "    step: 100; loss: 0.124; l2dist: 0.285\n",
      "    step: 150; loss: 0.135; l2dist: 0.289\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.464; l2dist: 0.000\n",
      "    step: 50; loss: 0.108; l2dist: 0.278\n",
      "    step: 100; loss: 0.130; l2dist: 0.279\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.114; l2dist: 0.000\n",
      "    step: 50; loss: 0.050; l2dist: 0.203\n",
      "    step: 100; loss: 0.053; l2dist: 0.210\n",
      "binary step: 0; number of successful adv: 87/100\n",
      "    step: 0; loss: 0.212; l2dist: 0.000\n",
      "    step: 50; loss: 0.070; l2dist: 0.218\n",
      "    step: 100; loss: 0.058; l2dist: 0.193\n",
      "    step: 150; loss: 0.063; l2dist: 0.197\n",
      "binary step: 1; number of successful adv: 97/100\n",
      "    step: 0; loss: 0.473; l2dist: 0.000\n",
      "    step: 50; loss: 0.079; l2dist: 0.226\n",
      "    step: 100; loss: 0.043; l2dist: 0.157\n",
      "    step: 150; loss: 0.081; l2dist: 0.193\n",
      "binary step: 2; number of successful adv: 99/100\n",
      "    step: 0; loss: 1.125; l2dist: 0.000\n",
      "    step: 50; loss: 0.084; l2dist: 0.229\n",
      "    step: 100; loss: 0.073; l2dist: 0.167\n",
      "    step: 150; loss: 0.055; l2dist: 0.161\n",
      "    step: 200; loss: 0.065; l2dist: 0.178\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.665; l2dist: 0.000\n",
      "    step: 50; loss: 0.068; l2dist: 0.212\n",
      "    step: 100; loss: 0.050; l2dist: 0.152\n",
      "    step: 150; loss: 0.097; l2dist: 0.204\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.126; l2dist: 0.000\n",
      "    step: 50; loss: 0.054; l2dist: 0.208\n",
      "    step: 100; loss: 0.056; l2dist: 0.204\n",
      "binary step: 0; number of successful adv: 68/100\n",
      "    step: 0; loss: 0.453; l2dist: 0.000\n",
      "    step: 50; loss: 0.109; l2dist: 0.287\n",
      "    step: 100; loss: 0.110; l2dist: 0.268\n",
      "binary step: 1; number of successful adv: 94/100\n",
      "    step: 0; loss: 0.951; l2dist: 0.000\n",
      "    step: 50; loss: 0.206; l2dist: 0.310\n",
      "    step: 100; loss: 0.151; l2dist: 0.289\n",
      "    step: 150; loss: 0.114; l2dist: 0.258\n",
      "    step: 200; loss: 0.117; l2dist: 0.266\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.566; l2dist: 0.000\n",
      "    step: 50; loss: 0.108; l2dist: 0.271\n",
      "    step: 100; loss: 0.154; l2dist: 0.271\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.388; l2dist: 0.000\n",
      "    step: 50; loss: 0.082; l2dist: 0.233\n",
      "    step: 100; loss: 0.096; l2dist: 0.223\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.133; l2dist: 0.000\n",
      "    step: 50; loss: 0.057; l2dist: 0.217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    step: 100; loss: 0.063; l2dist: 0.231\n",
      "binary step: 0; number of successful adv: 87/100\n",
      "    step: 0; loss: 0.227; l2dist: 0.000\n",
      "    step: 50; loss: 0.051; l2dist: 0.203\n",
      "    step: 100; loss: 0.057; l2dist: 0.186\n",
      "binary step: 1; number of successful adv: 99/100\n",
      "    step: 0; loss: 0.253; l2dist: 0.000\n",
      "    step: 50; loss: 0.050; l2dist: 0.195\n",
      "    step: 100; loss: 0.041; l2dist: 0.165\n",
      "    step: 150; loss: 0.076; l2dist: 0.204\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.174; l2dist: 0.000\n",
      "    step: 50; loss: 0.042; l2dist: 0.180\n",
      "    step: 100; loss: 0.036; l2dist: 0.145\n",
      "    step: 150; loss: 0.039; l2dist: 0.156\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.141; l2dist: 0.000\n",
      "    step: 50; loss: 0.041; l2dist: 0.178\n",
      "    step: 100; loss: 0.034; l2dist: 0.145\n",
      "    step: 150; loss: 0.055; l2dist: 0.176\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.135; l2dist: 0.000\n",
      "    step: 50; loss: 0.063; l2dist: 0.223\n",
      "    step: 100; loss: 0.068; l2dist: 0.220\n",
      "binary step: 0; number of successful adv: 54/100\n",
      "    step: 0; loss: 0.666; l2dist: 0.000\n",
      "    step: 50; loss: 0.191; l2dist: 0.367\n",
      "    step: 100; loss: 0.168; l2dist: 0.360\n",
      "    step: 150; loss: 0.270; l2dist: 0.470\n",
      "binary step: 1; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.375; l2dist: 0.000\n",
      "    step: 50; loss: 0.120; l2dist: 0.302\n",
      "    step: 100; loss: 0.128; l2dist: 0.306\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.307; l2dist: 0.000\n",
      "    step: 50; loss: 0.106; l2dist: 0.277\n",
      "    step: 100; loss: 0.139; l2dist: 0.320\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.248; l2dist: 0.000\n",
      "    step: 50; loss: 0.097; l2dist: 0.278\n",
      "    step: 100; loss: 0.107; l2dist: 0.259\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.128; l2dist: 0.000\n",
      "    step: 50; loss: 0.054; l2dist: 0.212\n",
      "    step: 100; loss: 0.062; l2dist: 0.208\n",
      "binary step: 0; number of successful adv: 62/100\n",
      "    step: 0; loss: 0.546; l2dist: 0.000\n",
      "    step: 50; loss: 0.166; l2dist: 0.348\n",
      "    step: 100; loss: 0.158; l2dist: 0.339\n",
      "    step: 150; loss: 0.202; l2dist: 0.392\n",
      "binary step: 1; number of successful adv: 97/100\n",
      "    step: 0; loss: 0.691; l2dist: 0.000\n",
      "    step: 50; loss: 0.110; l2dist: 0.272\n",
      "    step: 100; loss: 0.261; l2dist: 0.359\n",
      "binary step: 2; number of successful adv: 99/100\n",
      "    step: 0; loss: 1.665; l2dist: 0.000\n",
      "    step: 50; loss: 0.131; l2dist: 0.274\n",
      "    step: 100; loss: 0.073; l2dist: 0.209\n",
      "    step: 150; loss: 0.198; l2dist: 0.297\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 1.039; l2dist: 0.000\n",
      "    step: 50; loss: 0.105; l2dist: 0.269\n",
      "    step: 100; loss: 0.132; l2dist: 0.243\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.140; l2dist: 0.000\n",
      "    step: 50; loss: 0.057; l2dist: 0.217\n",
      "    step: 100; loss: 0.061; l2dist: 0.229\n",
      "binary step: 0; number of successful adv: 80/100\n",
      "    step: 0; loss: 0.332; l2dist: 0.000\n",
      "    step: 50; loss: 0.082; l2dist: 0.240\n",
      "    step: 100; loss: 0.088; l2dist: 0.236\n",
      "binary step: 1; number of successful adv: 96/100\n",
      "    step: 0; loss: 0.714; l2dist: 0.000\n",
      "    step: 50; loss: 0.088; l2dist: 0.247\n",
      "    step: 100; loss: 0.105; l2dist: 0.247\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.415; l2dist: 0.000\n",
      "    step: 50; loss: 0.088; l2dist: 0.246\n",
      "    step: 100; loss: 0.068; l2dist: 0.209\n",
      "    step: 150; loss: 0.173; l2dist: 0.281\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.289; l2dist: 0.000\n",
      "    step: 50; loss: 0.068; l2dist: 0.227\n",
      "    step: 100; loss: 0.070; l2dist: 0.207\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.136; l2dist: 0.000\n",
      "    step: 50; loss: 0.057; l2dist: 0.215\n",
      "    step: 100; loss: 0.052; l2dist: 0.206\n",
      "    step: 150; loss: 0.070; l2dist: 0.253\n",
      "binary step: 0; number of successful adv: 91/100\n",
      "    step: 0; loss: 0.178; l2dist: 0.000\n",
      "    step: 50; loss: 0.061; l2dist: 0.214\n",
      "    step: 100; loss: 0.054; l2dist: 0.199\n",
      "    step: 150; loss: 0.057; l2dist: 0.198\n",
      "binary step: 1; number of successful adv: 97/100\n",
      "    step: 0; loss: 0.495; l2dist: 0.000\n",
      "    step: 50; loss: 0.061; l2dist: 0.212\n",
      "    step: 100; loss: 0.055; l2dist: 0.189\n",
      "    step: 150; loss: 0.114; l2dist: 0.241\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.295; l2dist: 0.000\n",
      "    step: 50; loss: 0.054; l2dist: 0.201\n",
      "    step: 100; loss: 0.053; l2dist: 0.179\n",
      "    step: 150; loss: 0.056; l2dist: 0.187\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.199; l2dist: 0.000\n",
      "    step: 50; loss: 0.048; l2dist: 0.195\n",
      "    step: 100; loss: 0.046; l2dist: 0.171\n",
      "    step: 150; loss: 0.068; l2dist: 0.202\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.125; l2dist: 0.000\n",
      "    step: 50; loss: 0.054; l2dist: 0.215\n",
      "    step: 100; loss: 0.058; l2dist: 0.213\n",
      "binary step: 0; number of successful adv: 86/100\n",
      "    step: 0; loss: 0.223; l2dist: 0.000\n",
      "    step: 50; loss: 0.073; l2dist: 0.226\n",
      "    step: 100; loss: 0.071; l2dist: 0.209\n",
      "    step: 150; loss: 0.085; l2dist: 0.227\n",
      "binary step: 1; number of successful adv: 96/100\n",
      "    step: 0; loss: 0.598; l2dist: 0.000\n",
      "    step: 50; loss: 0.075; l2dist: 0.223\n",
      "    step: 100; loss: 0.063; l2dist: 0.189\n",
      "    step: 150; loss: 0.064; l2dist: 0.194\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.353; l2dist: 0.000\n",
      "    step: 50; loss: 0.057; l2dist: 0.202\n",
      "    step: 100; loss: 0.061; l2dist: 0.174\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.238; l2dist: 0.000\n",
      "    step: 50; loss: 0.051; l2dist: 0.197\n",
      "    step: 100; loss: 0.051; l2dist: 0.174\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.116; l2dist: 0.000\n",
      "    step: 50; loss: 0.055; l2dist: 0.219\n",
      "    step: 100; loss: 0.049; l2dist: 0.200\n",
      "    step: 150; loss: 0.064; l2dist: 0.207\n",
      "binary step: 0; number of successful adv: 54/100\n",
      "    step: 0; loss: 0.595; l2dist: 0.000\n",
      "    step: 50; loss: 0.165; l2dist: 0.334\n",
      "    step: 100; loss: 0.193; l2dist: 0.376\n",
      "binary step: 1; number of successful adv: 98/100\n",
      "    step: 0; loss: 0.517; l2dist: 0.000\n",
      "    step: 50; loss: 0.122; l2dist: 0.285\n",
      "    step: 100; loss: 0.149; l2dist: 0.313\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.365; l2dist: 0.000\n",
      "    step: 50; loss: 0.117; l2dist: 0.293\n",
      "    step: 100; loss: 0.104; l2dist: 0.253\n",
      "    step: 150; loss: 0.184; l2dist: 0.339\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.356; l2dist: 0.000\n",
      "    step: 50; loss: 0.082; l2dist: 0.247\n",
      "    step: 100; loss: 0.120; l2dist: 0.296\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.126; l2dist: 0.000\n",
      "    step: 50; loss: 0.055; l2dist: 0.221\n",
      "    step: 100; loss: 0.054; l2dist: 0.211\n",
      "    step: 150; loss: 0.064; l2dist: 0.229\n",
      "binary step: 0; number of successful adv: 81/100\n",
      "    step: 0; loss: 0.308; l2dist: 0.000\n",
      "    step: 50; loss: 0.083; l2dist: 0.242\n",
      "    step: 100; loss: 0.087; l2dist: 0.236\n",
      "binary step: 1; number of successful adv: 99/100\n",
      "    step: 0; loss: 0.307; l2dist: 0.000\n",
      "    step: 50; loss: 0.070; l2dist: 0.224\n",
      "    step: 100; loss: 0.068; l2dist: 0.207\n",
      "    step: 150; loss: 0.083; l2dist: 0.230\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.212; l2dist: 0.000\n",
      "    step: 50; loss: 0.069; l2dist: 0.223\n",
      "    step: 100; loss: 0.059; l2dist: 0.204\n",
      "    step: 150; loss: 0.078; l2dist: 0.225\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.162; l2dist: 0.000\n",
      "    step: 50; loss: 0.051; l2dist: 0.197\n",
      "    step: 100; loss: 0.054; l2dist: 0.193\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.128; l2dist: 0.000\n",
      "    step: 50; loss: 0.061; l2dist: 0.223\n",
      "    step: 100; loss: 0.065; l2dist: 0.218\n",
      "binary step: 0; number of successful adv: 63/100\n",
      "    step: 0; loss: 0.535; l2dist: 0.000\n",
      "    step: 50; loss: 0.143; l2dist: 0.292\n",
      "    step: 100; loss: 0.172; l2dist: 0.342\n",
      "binary step: 1; number of successful adv: 94/100\n",
      "    step: 0; loss: 1.036; l2dist: 0.000\n",
      "    step: 50; loss: 0.162; l2dist: 0.324\n",
      "    step: 100; loss: 0.165; l2dist: 0.295\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.597; l2dist: 0.000\n",
      "    step: 50; loss: 0.123; l2dist: 0.286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    step: 100; loss: 0.134; l2dist: 0.275\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.446; l2dist: 0.000\n",
      "    step: 50; loss: 0.117; l2dist: 0.274\n",
      "    step: 100; loss: 0.131; l2dist: 0.265\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.126; l2dist: 0.000\n",
      "    step: 50; loss: 0.055; l2dist: 0.210\n",
      "    step: 100; loss: 0.056; l2dist: 0.221\n",
      "binary step: 0; number of successful adv: 77/100\n",
      "    step: 0; loss: 0.336; l2dist: 0.000\n",
      "    step: 50; loss: 0.102; l2dist: 0.275\n",
      "    step: 100; loss: 0.109; l2dist: 0.272\n",
      "binary step: 1; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.202; l2dist: 0.000\n",
      "    step: 50; loss: 0.075; l2dist: 0.240\n",
      "    step: 100; loss: 0.070; l2dist: 0.223\n",
      "    step: 150; loss: 0.083; l2dist: 0.244\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.152; l2dist: 0.000\n",
      "    step: 50; loss: 0.057; l2dist: 0.213\n",
      "    step: 100; loss: 0.059; l2dist: 0.206\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.133; l2dist: 0.000\n",
      "    step: 50; loss: 0.053; l2dist: 0.204\n",
      "    step: 100; loss: 0.059; l2dist: 0.194\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.109; l2dist: 0.000\n",
      "    step: 50; loss: 0.047; l2dist: 0.197\n",
      "    step: 100; loss: 0.052; l2dist: 0.200\n",
      "binary step: 0; number of successful adv: 80/100\n",
      "    step: 0; loss: 0.264; l2dist: 0.000\n",
      "    step: 50; loss: 0.084; l2dist: 0.237\n",
      "    step: 100; loss: 0.091; l2dist: 0.226\n",
      "binary step: 1; number of successful adv: 96/100\n",
      "    step: 0; loss: 0.501; l2dist: 0.000\n",
      "    step: 50; loss: 0.082; l2dist: 0.231\n",
      "    step: 100; loss: 0.066; l2dist: 0.197\n",
      "    step: 150; loss: 0.107; l2dist: 0.234\n",
      "binary step: 2; number of successful adv: 99/100\n",
      "    step: 0; loss: 1.683; l2dist: 0.000\n",
      "    step: 50; loss: 0.111; l2dist: 0.251\n",
      "    step: 100; loss: 0.079; l2dist: 0.189\n",
      "    step: 150; loss: 0.091; l2dist: 0.193\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.963; l2dist: 0.000\n",
      "    step: 50; loss: 0.071; l2dist: 0.216\n",
      "    step: 100; loss: 0.043; l2dist: 0.156\n",
      "    step: 150; loss: 0.077; l2dist: 0.191\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.120; l2dist: 0.000\n",
      "    step: 50; loss: 0.049; l2dist: 0.202\n",
      "    step: 100; loss: 0.051; l2dist: 0.194\n",
      "binary step: 0; number of successful adv: 68/100\n",
      "    step: 0; loss: 0.418; l2dist: 0.000\n",
      "    step: 50; loss: 0.111; l2dist: 0.285\n",
      "    step: 100; loss: 0.142; l2dist: 0.319\n",
      "binary step: 1; number of successful adv: 98/100\n",
      "    step: 0; loss: 0.471; l2dist: 0.000\n",
      "    step: 50; loss: 0.085; l2dist: 0.250\n",
      "    step: 100; loss: 0.096; l2dist: 0.243\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.305; l2dist: 0.000\n",
      "    step: 50; loss: 0.075; l2dist: 0.223\n",
      "    step: 100; loss: 0.080; l2dist: 0.221\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.220; l2dist: 0.000\n",
      "    step: 50; loss: 0.059; l2dist: 0.212\n",
      "    step: 100; loss: 0.058; l2dist: 0.196\n",
      "    step: 150; loss: 0.089; l2dist: 0.255\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.126; l2dist: 0.000\n",
      "    step: 50; loss: 0.051; l2dist: 0.210\n",
      "    step: 100; loss: 0.050; l2dist: 0.204\n",
      "    step: 150; loss: 0.066; l2dist: 0.232\n",
      "binary step: 0; number of successful adv: 84/100\n",
      "    step: 0; loss: 0.264; l2dist: 0.000\n",
      "    step: 50; loss: 0.076; l2dist: 0.241\n",
      "    step: 100; loss: 0.078; l2dist: 0.227\n",
      "binary step: 1; number of successful adv: 99/100\n",
      "    step: 0; loss: 0.284; l2dist: 0.000\n",
      "    step: 50; loss: 0.059; l2dist: 0.215\n",
      "    step: 100; loss: 0.103; l2dist: 0.236\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.205; l2dist: 0.000\n",
      "    step: 50; loss: 0.058; l2dist: 0.205\n",
      "    step: 100; loss: 0.065; l2dist: 0.194\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.167; l2dist: 0.000\n",
      "    step: 50; loss: 0.053; l2dist: 0.202\n",
      "    step: 100; loss: 0.049; l2dist: 0.172\n",
      "    step: 150; loss: 0.059; l2dist: 0.196\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.132; l2dist: 0.000\n",
      "    step: 50; loss: 0.059; l2dist: 0.222\n",
      "    step: 100; loss: 0.058; l2dist: 0.206\n",
      "    step: 150; loss: 0.080; l2dist: 0.239\n",
      "binary step: 0; number of successful adv: 60/100\n",
      "    step: 0; loss: 0.562; l2dist: 0.000\n",
      "    step: 50; loss: 0.160; l2dist: 0.323\n",
      "    step: 100; loss: 0.191; l2dist: 0.360\n",
      "binary step: 1; number of successful adv: 93/100\n",
      "    step: 0; loss: 1.153; l2dist: 0.000\n",
      "    step: 50; loss: 0.124; l2dist: 0.287\n",
      "    step: 100; loss: 0.121; l2dist: 0.267\n",
      "    step: 150; loss: 0.175; l2dist: 0.308\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.727; l2dist: 0.000\n",
      "    step: 50; loss: 0.122; l2dist: 0.284\n",
      "    step: 100; loss: 0.124; l2dist: 0.277\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.504; l2dist: 0.000\n",
      "    step: 50; loss: 0.112; l2dist: 0.283\n",
      "    step: 100; loss: 0.141; l2dist: 0.296\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.132; l2dist: 0.000\n",
      "    step: 50; loss: 0.059; l2dist: 0.229\n",
      "    step: 100; loss: 0.058; l2dist: 0.211\n",
      "    step: 150; loss: 0.081; l2dist: 0.249\n",
      "binary step: 0; number of successful adv: 54/100\n",
      "    step: 0; loss: 0.667; l2dist: 0.000\n",
      "    step: 50; loss: 0.154; l2dist: 0.337\n",
      "    step: 100; loss: 0.241; l2dist: 0.411\n",
      "binary step: 1; number of successful adv: 90/100\n",
      "    step: 0; loss: 1.601; l2dist: 0.000\n",
      "    step: 50; loss: 0.165; l2dist: 0.339\n",
      "    step: 100; loss: 0.165; l2dist: 0.326\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.905; l2dist: 0.000\n",
      "    step: 50; loss: 0.124; l2dist: 0.304\n",
      "    step: 100; loss: 0.103; l2dist: 0.256\n",
      "    step: 150; loss: 0.215; l2dist: 0.366\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.723; l2dist: 0.000\n",
      "    step: 50; loss: 0.116; l2dist: 0.285\n",
      "    step: 100; loss: 0.136; l2dist: 0.282\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.130; l2dist: 0.000\n",
      "    step: 50; loss: 0.058; l2dist: 0.221\n",
      "    step: 100; loss: 0.058; l2dist: 0.209\n",
      "binary step: 0; number of successful adv: 74/100\n",
      "    step: 0; loss: 0.383; l2dist: 0.000\n",
      "    step: 50; loss: 0.096; l2dist: 0.271\n",
      "    step: 100; loss: 0.091; l2dist: 0.247\n",
      "    step: 150; loss: 0.134; l2dist: 0.300\n",
      "binary step: 1; number of successful adv: 95/100\n",
      "    step: 0; loss: 0.740; l2dist: 0.000\n",
      "    step: 50; loss: 0.092; l2dist: 0.259\n",
      "    step: 100; loss: 0.100; l2dist: 0.255\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.429; l2dist: 0.000\n",
      "    step: 50; loss: 0.078; l2dist: 0.236\n",
      "    step: 100; loss: 0.074; l2dist: 0.209\n",
      "    step: 150; loss: 0.076; l2dist: 0.218\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.346; l2dist: 0.000\n",
      "    step: 50; loss: 0.068; l2dist: 0.225\n",
      "    step: 100; loss: 0.065; l2dist: 0.209\n",
      "    step: 150; loss: 0.081; l2dist: 0.237\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.128; l2dist: 0.000\n",
      "    step: 50; loss: 0.055; l2dist: 0.221\n",
      "    step: 100; loss: 0.052; l2dist: 0.211\n",
      "    step: 150; loss: 0.066; l2dist: 0.237\n",
      "binary step: 0; number of successful adv: 84/100\n",
      "    step: 0; loss: 0.259; l2dist: 0.000\n",
      "    step: 50; loss: 0.057; l2dist: 0.211\n",
      "    step: 100; loss: 0.071; l2dist: 0.212\n",
      "binary step: 1; number of successful adv: 95/100\n",
      "    step: 0; loss: 0.753; l2dist: 0.000\n",
      "    step: 50; loss: 0.090; l2dist: 0.241\n",
      "    step: 100; loss: 0.072; l2dist: 0.195\n",
      "    step: 150; loss: 0.086; l2dist: 0.209\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.458; l2dist: 0.000\n",
      "    step: 50; loss: 0.066; l2dist: 0.217\n",
      "    step: 100; loss: 0.083; l2dist: 0.206\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.302; l2dist: 0.000\n",
      "    step: 50; loss: 0.060; l2dist: 0.211\n",
      "    step: 100; loss: 0.054; l2dist: 0.186\n",
      "    step: 150; loss: 0.074; l2dist: 0.207\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.122; l2dist: 0.000\n",
      "    step: 50; loss: 0.048; l2dist: 0.195\n",
      "    step: 100; loss: 0.049; l2dist: 0.196\n",
      "binary step: 0; number of successful adv: 76/100\n",
      "    step: 0; loss: 0.349; l2dist: 0.000\n",
      "    step: 50; loss: 0.084; l2dist: 0.248\n",
      "    step: 100; loss: 0.108; l2dist: 0.245\n",
      "binary step: 1; number of successful adv: 94/100\n",
      "    step: 0; loss: 0.918; l2dist: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    step: 50; loss: 0.107; l2dist: 0.257\n",
      "    step: 100; loss: 0.088; l2dist: 0.216\n",
      "    step: 150; loss: 0.116; l2dist: 0.247\n",
      "binary step: 2; number of successful adv: 98/100\n",
      "    step: 0; loss: 2.805; l2dist: 0.000\n",
      "    step: 50; loss: 0.169; l2dist: 0.308\n",
      "    step: 100; loss: 0.100; l2dist: 0.211\n",
      "    step: 150; loss: 0.079; l2dist: 0.201\n",
      "    step: 200; loss: 0.167; l2dist: 0.249\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 1.642; l2dist: 0.000\n",
      "    step: 50; loss: 0.106; l2dist: 0.264\n",
      "    step: 100; loss: 0.068; l2dist: 0.193\n",
      "    step: 150; loss: 0.099; l2dist: 0.209\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.134; l2dist: 0.000\n",
      "    step: 50; loss: 0.061; l2dist: 0.227\n",
      "    step: 100; loss: 0.064; l2dist: 0.212\n",
      "binary step: 0; number of successful adv: 58/100\n",
      "    step: 0; loss: 0.627; l2dist: 0.000\n",
      "    step: 50; loss: 0.155; l2dist: 0.337\n",
      "    step: 100; loss: 0.221; l2dist: 0.424\n",
      "binary step: 1; number of successful adv: 98/100\n",
      "    step: 0; loss: 0.643; l2dist: 0.000\n",
      "    step: 50; loss: 0.149; l2dist: 0.324\n",
      "    step: 100; loss: 0.160; l2dist: 0.345\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.390; l2dist: 0.000\n",
      "    step: 50; loss: 0.128; l2dist: 0.291\n",
      "    step: 100; loss: 0.129; l2dist: 0.316\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.257; l2dist: 0.000\n",
      "    step: 50; loss: 0.088; l2dist: 0.255\n",
      "    step: 100; loss: 0.113; l2dist: 0.277\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.145; l2dist: 0.000\n",
      "    step: 50; loss: 0.067; l2dist: 0.229\n",
      "    step: 100; loss: 0.067; l2dist: 0.227\n",
      "    step: 150; loss: 0.086; l2dist: 0.253\n",
      "binary step: 0; number of successful adv: 48/100\n",
      "    step: 0; loss: 0.802; l2dist: 0.000\n",
      "    step: 50; loss: 0.200; l2dist: 0.375\n",
      "    step: 100; loss: 0.243; l2dist: 0.428\n",
      "binary step: 1; number of successful adv: 92/100\n",
      "    step: 0; loss: 1.597; l2dist: 0.000\n",
      "    step: 50; loss: 0.204; l2dist: 0.380\n",
      "    step: 100; loss: 0.261; l2dist: 0.404\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 1.016; l2dist: 0.000\n",
      "    step: 50; loss: 0.163; l2dist: 0.345\n",
      "    step: 100; loss: 0.255; l2dist: 0.423\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.794; l2dist: 0.000\n",
      "    step: 50; loss: 0.146; l2dist: 0.336\n",
      "    step: 100; loss: 0.183; l2dist: 0.347\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.114; l2dist: 0.000\n",
      "    step: 50; loss: 0.046; l2dist: 0.201\n",
      "    step: 100; loss: 0.042; l2dist: 0.190\n",
      "    step: 150; loss: 0.064; l2dist: 0.217\n",
      "binary step: 0; number of successful adv: 62/100\n",
      "    step: 0; loss: 0.472; l2dist: 0.000\n",
      "    step: 50; loss: 0.126; l2dist: 0.309\n",
      "    step: 100; loss: 0.127; l2dist: 0.300\n",
      "binary step: 1; number of successful adv: 99/100\n",
      "    step: 0; loss: 0.390; l2dist: 0.000\n",
      "    step: 50; loss: 0.100; l2dist: 0.271\n",
      "    step: 100; loss: 0.096; l2dist: 0.267\n",
      "    step: 150; loss: 0.208; l2dist: 0.338\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.283; l2dist: 0.000\n",
      "    step: 50; loss: 0.070; l2dist: 0.226\n",
      "    step: 100; loss: 0.075; l2dist: 0.225\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.217; l2dist: 0.000\n",
      "    step: 50; loss: 0.068; l2dist: 0.218\n",
      "    step: 100; loss: 0.083; l2dist: 0.225\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.126; l2dist: 0.000\n",
      "    step: 50; loss: 0.055; l2dist: 0.215\n",
      "    step: 100; loss: 0.053; l2dist: 0.197\n",
      "    step: 150; loss: 0.078; l2dist: 0.234\n",
      "binary step: 0; number of successful adv: 54/100\n",
      "    step: 0; loss: 0.629; l2dist: 0.000\n",
      "    step: 50; loss: 0.153; l2dist: 0.341\n",
      "    step: 100; loss: 0.195; l2dist: 0.389\n",
      "binary step: 1; number of successful adv: 99/100\n",
      "    step: 0; loss: 0.517; l2dist: 0.000\n",
      "    step: 50; loss: 0.118; l2dist: 0.298\n",
      "    step: 100; loss: 0.154; l2dist: 0.326\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.329; l2dist: 0.000\n",
      "    step: 50; loss: 0.084; l2dist: 0.250\n",
      "    step: 100; loss: 0.127; l2dist: 0.285\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.261; l2dist: 0.000\n",
      "    step: 50; loss: 0.089; l2dist: 0.256\n",
      "    step: 100; loss: 0.084; l2dist: 0.232\n",
      "    step: 150; loss: 0.114; l2dist: 0.280\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.134; l2dist: 0.000\n",
      "    step: 50; loss: 0.059; l2dist: 0.217\n",
      "    step: 100; loss: 0.068; l2dist: 0.235\n",
      "binary step: 0; number of successful adv: 78/100\n",
      "    step: 0; loss: 0.341; l2dist: 0.000\n",
      "    step: 50; loss: 0.095; l2dist: 0.256\n",
      "    step: 100; loss: 0.110; l2dist: 0.271\n",
      "binary step: 1; number of successful adv: 94/100\n",
      "    step: 0; loss: 0.921; l2dist: 0.000\n",
      "    step: 50; loss: 0.142; l2dist: 0.289\n",
      "    step: 100; loss: 0.137; l2dist: 0.261\n",
      "    step: 150; loss: 0.116; l2dist: 0.258\n",
      "    step: 200; loss: 0.131; l2dist: 0.268\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.531; l2dist: 0.000\n",
      "    step: 50; loss: 0.118; l2dist: 0.266\n",
      "    step: 100; loss: 0.108; l2dist: 0.242\n",
      "    step: 150; loss: 0.105; l2dist: 0.239\n",
      "    step: 200; loss: 0.143; l2dist: 0.277\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 0.396; l2dist: 0.000\n",
      "    step: 50; loss: 0.095; l2dist: 0.248\n",
      "    step: 100; loss: 0.077; l2dist: 0.203\n",
      "    step: 150; loss: 0.093; l2dist: 0.219\n",
      "binary step: 4; number of successful adv: 100/100\n"
     ]
    }
   ],
   "source": [
    "attack = CWL2Attack()\n",
    "\n",
    "def attack_batch(x, y, batch_size):\n",
    "    x_adv = torch.zeros_like(x)\n",
    "    total_num = x.size(0)\n",
    "    num_batches = total_num // batch_size\n",
    "    for i in range(num_batches):\n",
    "        begin = i * batch_size\n",
    "        end = (i + 1) * batch_size\n",
    "        x_adv[begin:end] = attack(\n",
    "            net, x[begin:end], y[begin:end], targeted=False,\n",
    "            binary_search_steps=5, max_iterations=500,\n",
    "            confidence=0, learning_rate=1e-1,\n",
    "            initial_const=1e-2, abort_early=True)\n",
    "    return x_adv\n",
    "\n",
    "x_adv = attack_batch(x_test[ind].cuda(), y_test[ind].cuda(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "ind_adv = np.zeros(x_adv.size(0))\n",
    "with torch.no_grad():\n",
    "    num = 0\n",
    "    for i in range(x_adv.size(0) // 100):\n",
    "        begin = i * 100\n",
    "        end = (i + 1) * 100\n",
    "        y_pred = net(x_adv[begin:end].to('cuda'))\n",
    "        ind_adv[begin:end] = (y_pred.argmax(1).cpu() != y_test[ind][begin:end]).numpy()\n",
    "        num += (y_pred.argmax(1).cpu() == y_test[ind][begin:end]).sum().numpy()\n",
    "    print(num / x_adv.size(0))\n",
    "ind_adv = np.where(ind_adv)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& 0.0012 & 0.0001 & 0.0001\n"
     ]
    }
   ],
   "source": [
    "pert = (x_adv.cpu() - x_test[ind]).view(x_adv.size(0), -1).norm(2, 1)\n",
    "d1 = (len(ind) - (pert[ind_adv] < 0.5).sum().numpy()) / y_test.size(0)\n",
    "d2 = (len(ind) - (pert[ind_adv] < 1).sum().numpy()) / y_test.size(0)\n",
    "d3 = (len(ind) - (pert[ind_adv] < 1.5).sum().numpy()) / y_test.size(0)\n",
    "print('& %.4f & %.4f & %.4f' % (d1, d2, d3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1429)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pert[ind_adv].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## DkNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# layers = ['relu1', 'relu2', 'relu3', 'fc']\n",
    "# layers = ['relu1', 'relu2', 'relu3']\n",
    "layers = ['layer4']\n",
    "\n",
    "dknn = DKNNL2(net, x_train, y_train, x_valid, y_valid, layers, \n",
    "              k=75, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9301\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = dknn.classify(x_test)\n",
    "    ind = np.where(y_pred.argmax(1) == y_test.numpy())[0]\n",
    "    print((y_pred.argmax(1) == y_test.numpy()).sum() / y_test.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adv = pickle.load(open('x_adv_cifar10_resnet_exp2.h5.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a73daef1acb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_adv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mind_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = dknn.classify(x_adv)\n",
    "    ind_adv = np.where(y_pred.argmax(1) != y_test[ind].numpy())[0]\n",
    "    print((y_pred.argmax(1) == y_test[ind].numpy()).sum() / y_pred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    step: 0; loss: 1384.783; l2dist: 0.215\n",
      "    step: 50; loss: 614.108; l2dist: 4.353\n",
      "    step: 100; loss: 556.940; l2dist: 5.110\n",
      "    step: 150; loss: 537.592; l2dist: 5.359\n",
      "    step: 200; loss: 528.239; l2dist: 5.473\n",
      "    step: 250; loss: 522.978; l2dist: 5.524\n",
      "    step: 300; loss: 519.639; l2dist: 5.557\n",
      "    step: 350; loss: 517.231; l2dist: 5.582\n",
      "    step: 400; loss: 515.285; l2dist: 5.601\n",
      "    step: 450; loss: 513.837; l2dist: 5.613\n",
      "tensor(89., device='cuda:0')\n",
      "binary step: 0; number of successful adv: 89/100\n",
      "    step: 0; loss: 1637.253; l2dist: 0.215\n",
      "    step: 50; loss: 823.230; l2dist: 4.173\n",
      "    step: 100; loss: 760.735; l2dist: 4.711\n",
      "    step: 150; loss: 738.345; l2dist: 4.882\n",
      "    step: 200; loss: 727.399; l2dist: 4.978\n",
      "    step: 250; loss: 721.813; l2dist: 5.030\n",
      "    step: 300; loss: 718.166; l2dist: 5.065\n",
      "    step: 350; loss: 715.612; l2dist: 5.089\n",
      "    step: 400; loss: 713.656; l2dist: 5.112\n",
      "    step: 450; loss: 712.050; l2dist: 5.130\n",
      "tensor(89., device='cuda:0')\n",
      "binary step: 1; number of successful adv: 92/100\n",
      "    step: 0; loss: 7767.937; l2dist: 0.215\n",
      "    step: 50; loss: 4208.803; l2dist: 3.836\n",
      "    step: 100; loss: 3900.898; l2dist: 4.146\n",
      "    step: 150; loss: 3782.921; l2dist: 4.272\n",
      "    step: 200; loss: 3724.693; l2dist: 4.349\n",
      "    step: 250; loss: 3694.487; l2dist: 4.402\n",
      "    step: 300; loss: 3671.768; l2dist: 4.442\n",
      "    step: 350; loss: 3652.844; l2dist: 4.479\n",
      "    step: 400; loss: 3636.539; l2dist: 4.511\n",
      "    step: 450; loss: 3625.285; l2dist: 4.535\n",
      "tensor(89., device='cuda:0')\n",
      "binary step: 2; number of successful adv: 92/100\n",
      "    step: 0; loss: 73101.828; l2dist: 0.215\n",
      "    step: 50; loss: 39867.406; l2dist: 3.373\n",
      "    step: 100; loss: 37042.125; l2dist: 3.550\n",
      "    step: 150; loss: 35850.391; l2dist: 3.664\n",
      "    step: 200; loss: 35277.469; l2dist: 3.736\n",
      "    step: 250; loss: 34968.254; l2dist: 3.785\n",
      "    step: 300; loss: 34728.793; l2dist: 3.825\n",
      "    step: 350; loss: 34522.250; l2dist: 3.862\n",
      "    step: 400; loss: 34362.133; l2dist: 3.892\n",
      "    step: 450; loss: 34242.328; l2dist: 3.916\n",
      "tensor(86., device='cuda:0')\n",
      "binary step: 3; number of successful adv: 93/100\n",
      "    step: 0; loss: 633759.750; l2dist: 0.214\n",
      "    step: 50; loss: 342897.500; l2dist: 2.872\n",
      "    step: 100; loss: 316133.562; l2dist: 3.022\n",
      "    step: 150; loss: 305632.625; l2dist: 3.122\n",
      "    step: 200; loss: 300516.562; l2dist: 3.190\n",
      "    step: 250; loss: 297674.438; l2dist: 3.237\n",
      "    step: 300; loss: 295510.156; l2dist: 3.277\n",
      "    step: 350; loss: 293807.188; l2dist: 3.311\n",
      "    step: 400; loss: 292509.438; l2dist: 3.340\n",
      "    step: 450; loss: 291556.156; l2dist: 3.365\n",
      "tensor(84., device='cuda:0')\n",
      "binary step: 4; number of successful adv: 93/100\n",
      "    step: 0; loss: 6280514.500; l2dist: 0.215\n",
      "    step: 50; loss: 3400012.500; l2dist: 2.446\n",
      "    step: 100; loss: 3131049.500; l2dist: 2.594\n",
      "    step: 150; loss: 3026785.250; l2dist: 2.685\n",
      "    step: 200; loss: 2976183.000; l2dist: 2.748\n",
      "    step: 250; loss: 2948314.500; l2dist: 2.794\n",
      "    step: 300; loss: 2927576.250; l2dist: 2.828\n",
      "    step: 350; loss: 2911439.500; l2dist: 2.860\n",
      "    step: 400; loss: 2898148.000; l2dist: 2.889\n",
      "    step: 450; loss: 2888707.250; l2dist: 2.912\n",
      "tensor(75., device='cuda:0')\n",
      "binary step: 5; number of successful adv: 93/100\n",
      "    step: 0; loss: 62813592.000; l2dist: 0.215\n",
      "    step: 50; loss: 33981436.000; l2dist: 2.167\n",
      "    step: 100; loss: 31302400.000; l2dist: 2.317\n",
      "    step: 150; loss: 30246904.000; l2dist: 2.411\n",
      "    step: 200; loss: 29733344.000; l2dist: 2.473\n",
      "    step: 250; loss: 29462266.000; l2dist: 2.520\n",
      "    step: 300; loss: 29251424.000; l2dist: 2.557\n",
      "    step: 350; loss: 29079994.000; l2dist: 2.591\n",
      "    step: 400; loss: 28946922.000; l2dist: 2.620\n",
      "    step: 450; loss: 28857684.000; l2dist: 2.643\n",
      "tensor(63., device='cuda:0')\n",
      "binary step: 6; number of successful adv: 93/100\n",
      "    step: 0; loss: 628172608.000; l2dist: 0.215\n",
      "    step: 50; loss: 339839040.000; l2dist: 2.035\n",
      "    step: 100; loss: 313057312.000; l2dist: 2.185\n",
      "    step: 150; loss: 302389984.000; l2dist: 2.276\n",
      "    step: 200; loss: 297193568.000; l2dist: 2.339\n",
      "    step: 250; loss: 294549216.000; l2dist: 2.383\n",
      "    step: 300; loss: 292504672.000; l2dist: 2.417\n",
      "    step: 350; loss: 290871616.000; l2dist: 2.449\n",
      "    step: 400; loss: 289487776.000; l2dist: 2.480\n",
      "    step: 450; loss: 288556832.000; l2dist: 2.503\n",
      "tensor(55., device='cuda:0')\n",
      "binary step: 7; number of successful adv: 93/100\n",
      "    step: 0; loss: 6285846016.000; l2dist: 0.215\n",
      "    step: 50; loss: 3398082048.000; l2dist: 1.995\n",
      "    step: 100; loss: 3129257472.000; l2dist: 2.146\n",
      "    step: 150; loss: 3024638976.000; l2dist: 2.237\n",
      "    step: 200; loss: 2972958208.000; l2dist: 2.300\n",
      "    step: 250; loss: 2944802816.000; l2dist: 2.344\n",
      "    step: 300; loss: 2924182528.000; l2dist: 2.379\n",
      "    step: 350; loss: 2908250368.000; l2dist: 2.410\n",
      "    step: 400; loss: 2894615296.000; l2dist: 2.438\n",
      "    step: 450; loss: 2884367872.000; l2dist: 2.463\n",
      "tensor(54., device='cuda:0')\n",
      "binary step: 8; number of successful adv: 93/100\n",
      "    step: 0; loss: 627719268204544.000; l2dist: 0.215\n",
      "    step: 50; loss: 339670240067584.000; l2dist: 2.056\n",
      "    step: 100; loss: 312987822850048.000; l2dist: 2.207\n",
      "    step: 150; loss: 302352309420032.000; l2dist: 2.302\n",
      "    step: 200; loss: 297123992043520.000; l2dist: 2.367\n",
      "    step: 250; loss: 294478761951232.000; l2dist: 2.410\n",
      "    step: 300; loss: 292485427363840.000; l2dist: 2.446\n",
      "    step: 350; loss: 290921388179456.000; l2dist: 2.477\n",
      "    step: 400; loss: 289606792642560.000; l2dist: 2.507\n",
      "    step: 450; loss: 288618715283456.000; l2dist: 2.531\n",
      "tensor(84., device='cuda:0')\n",
      "binary step: 9; number of successful adv: 93/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-98dec44d7549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mx_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-98dec44d7549>\u001b[0m in \u001b[0;36mattack_batch\u001b[0;34m(x, y, batch_size)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mguide_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_search_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mmax_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_const\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             abort_early=False, random_start=True, guide=2)\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx_adv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/research/entangle-rep/lib/dknn_attack_l2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, dknn, x_orig, label, guide_layer, m, binary_search_steps, max_iterations, learning_rate, initial_const, abort_early, max_linf, random_start, guide)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 x_guide = self.find_guide_samples_v2(\n\u001b[0;32m---> 78\u001b[0;31m                     dknn, x_orig, label, k=m, layer=guide_layer)\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mguide_reps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/research/entangle-rep/lib/dknn_attack_l2.py\u001b[0m in \u001b[0;36mfind_guide_samples_v2\u001b[0;34m(cls, dknn, x, label, k, layer)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_guide_samples_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdknn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# find nearest sample with different class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_nn_diff_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0;31m# now find k neighbors that has the same class as x_nn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mx_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_nn_same_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdknn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/research/entangle-rep/lib/dknn.py\u001b[0m in \u001b[0;36mfind_nn_diff_class\u001b[0;34m(self, x, label)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;31m# least one sample of a different class is found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound_diff_class\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m                 \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/research/entangle-rep/lib/dknn.py\u001b[0m in \u001b[0;36mget_neighbors\u001b[0;34m(self, x, k, layers)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mreps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/research/entangle-rep/lib/dknn.py\u001b[0m in \u001b[0;36mget_activations\u001b[0;34m(self, x, batch_size, requires_grad, device)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                 \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/research/entangle-rep/lib/cifar_resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/research/entangle-rep/lib/cifar_resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mshortcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shortcut'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# attack = DKNNAttack()\n",
    "\n",
    "from lib.dknn_attack_l2 import DKNNL2Attack\n",
    "attack = DKNNL2Attack()\n",
    "\n",
    "def attack_batch(x, y, batch_size, layer):\n",
    "    x_a = torch.zeros_like(x)\n",
    "    total_num = x.size(0)\n",
    "    num_batches = total_num // batch_size\n",
    "    for i in range(num_batches):\n",
    "        begin = i * batch_size\n",
    "        end = (i + 1) * batch_size\n",
    "        x_a[begin:end] = attack(\n",
    "            dknn, x[begin:end], y[begin:end],\n",
    "            guide_layer=layer, m=300, binary_search_steps=10,\n",
    "            max_iterations=500, learning_rate=1e-2, initial_const=1e-3,\n",
    "            abort_early=False, random_start=True, guide=2)\n",
    "    return x_a\n",
    "\n",
    "num = 1000\n",
    "ind = np.where(y_pred.argmax(1) == y_test.numpy())[0]\n",
    "x_adv = attack_batch(x_test[ind][:num].cuda(), y_test[ind][:num], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dknn.classify(x_adv)\n",
    "(y_pred.argmax(1) == y_test[ind][:num].numpy()).sum() / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0.,    0.,    0.,    0.,    0., 1000.,    0.,    0.,    0.,\n",
       "           0.]),\n",
       " array([0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3, 1.4, 1.5]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cred = dknn.credibility(y_pred)\n",
    "plt.hist(cred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0761013"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_clean = dknn.classify(x_test[:num])\n",
    "# ind = (y_clean.argmax(1) == y_test[:num].numpy()) & (y_pred.argmax(1) != y_test[:num].numpy())\n",
    "dist = np.sqrt(np.sum((x_adv.cpu().detach().numpy() - x_test.numpy()[ind][:num])**2, (1, 2, 3)))\n",
    "np.mean(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnXlwXPdx5789B+4bIIgbvMBLJEVR1H1RsmQdkSPJdlSysy7Vxis63rgS18a7q5J3196tlMtJxXZpt1LeomOt5ZRjSbFlSVFkS7QuijpIgvcBHiAJggABAiBu4hjMoPcPDKsoqL8gJJADyq8/VSwM+zs97zdvXs+beT3dLaoKx3GCR2i2F+A4zuzgwe84AcWD33ECige/4wQUD37HCSge/I4TUDz4HSegePA7TkDx4HecgBKZibOI3APgSQBhAP+oqt+/wP3pzwlrp/ArFNvem8V9Mke4Nj7FjxqneEiMp9l2DZEFAkhk5VItmpmg2liCr0Qye6nWEc8w7ZEh/qSHe8uphgT3y5Mo1dLCw6Y9nB7m28oZo5Ikhqg2GueHcSJ21rRHE/wAGY1nUy0m5CAAEALXxubEqZY3aGtdOfx5zTtj76uTY4Pojo/wA/I8PnHwi0gYwD8AuAtAC4BtIvKSqh6Yyi8Utl/8/wZ+kD1M9ukLK/h2Vh3hj3d2lPutnmK3DdXY4ngGD4LutTdSrXx5D9VO911DtciVv6Ha/+laYtrn7ORvNHtffIJq6OZ+n8koo1p13j7TXrCQB1bo5tNUi/btoFpj11yq9TZvNe2VvQf543VfTbWW6HyqZaGCaqce66LaZ7acMe0/u76U+vy/n7eY9ruP/xv1mcxMPvZfC6BRVY+pagzAMwAemMHjOY6TQmYS/JUATp73/5akzXGcTwEz+c5vfQb+yGdtEVkPYP0MtuM4ziVgJsHfAqD6vP9XATg1+U6qugHABmDqC36O46SWmXzs3wagTkTmi0gagEcAvHRxluU4zqXmE5/5VTUuIt8A8ComUn1Pqer+qXwkFEY4M9/Uev/xz6jfltgbpn1z7l9Rn46l/0y1tN4iqvWM8VTA/tGlpr1759epzzzpoFpZ9d9RrbSpmWrpR+6n2n+KFJv20G1bqE/0bZ6taDzLkzeboulUOzXXvrrdvOgV6pPec4Rqx+fyy0k1x7hWsfKPTfu/FT5KfbJ/x6/2V462Um2gaoBqWbU8W3Hw5Bp7W1dspD6hTDszIiGeEp3MjPL8qvoKAP5qOo5z2eK/8HOcgOLB7zgBxYPfcQKKB7/jBBQPfscJKDO62v9xSZsXQe33SkztSP8c6hce/JJpX32UF4LMabfTcgDQUMSLM3a22lVxADAQsqvfbnmrj/rsVZ7+QRt/760v5FVLhS0nqJYosAs+atvsFCAAlF31A6rVzl9EtQfyeTry3SG7yKUik1dOHY21U+3zxzupFsrhBVKj7Xbx0XXZ/dRnec2TVOutrKNaVjp/rUfiPAUXC9t+4y/xys7IADl2eB3WR/Azv+MEFA9+xwkoHvyOE1A8+B0noHjwO05ASenV/vBoJnKbV5raZ4f5ld6sAbtNU4/wfnDZ26+l2rziQarN7Z6iMCJK+sH187XnVe6iWlk3zyxEYo1UGzpTQLWcHPvK8b7eK6jPm1P0IMy8oo1qN+fz/Vi+027X1aC89dfYSBXVDvKL8xhsraZa2Ry7+OhoF2+RdaCOXzKPtPM+fZFBvo8zhu2CNgAoK7P3cXywifrEE6Tf4ceYuu1nfscJKB78jhNQPPgdJ6B48DtOQPHgd5yA4sHvOAElpam+9EgMdcV2MUjRB1dSv0OV46Y93sPTJwOZfPRT7gjX9kb5eK3MfjulVFvD04PtwoszshfyqTH7Q9zvGuXjutrjdj++usSb1KcywlOOdQf5/hi5macBO+6wx2FVN2ZSn+wpaqAO5kyRns22pwMBQHavnRZdHOXPuf8oX8cVafx1aX7wfaoV7bZ7CQJAZyLHtFc28eccG/5Io2wAwLjGqM9k/MzvOAHFg99xAooHv+MEFA9+xwkoHvyOE1A8+B0noMwo1SciTQAGMNE5LK6qa6e6f/pgFPM22VVdB6vsdAcADHXZKb38eJz68EcDYgNTVAPeaY8GAwActFOOeU1N1KX/NN8lmm+nawAgVraAasN9PMU5frLQtHdn8NRW7xI+kuudDLuiEgDS3/ks1ebeety0XxPl1XR5Cd6LL79zirRiOR83dkbsisWiEzzleHx8igq8wW6q7eix9z0A3D7C+02eLLKrGSsy+Ws2PGK/LjrOx4lN5mLk+W9XVXswm+M4ly3+sd9xAspMg18BvCYi20Vk/cVYkOM4qWGmH/tvUtVTIlIKYKOIHFTVTeffIfmmsB4A8rL59yzHcVLLjM78qnoq+bcDwG8AfKR3lqpuUNW1qro2K4O3QHIcJ7V84uAXkWwRyT13G8BnAfAKC8dxLitm8rF/LoDfyEQqJQLgn1X1d1M5jGsaRmM1plazrZL6tZHRRJXDvPHkvvk8nVe67FmqnazmzRvTst6x7XsfoD5VU6Tl3urlabQVZ+xmoQBweNRuSgkAZ8/YKbahTJ783Ce8KjEU5vujYyFvMnrF0cWmfTiXP+erl3Ete4ynsI4189e6+pg9Si02xj+FJkI8LXeohIfMVcd4Rd3cszwhduqMPQIs1r6E+qi+a9thp6MtPnHwq+oxALwO13GcyxpP9TlOQPHgd5yA4sHvOAHFg99xAooHv+MElJQ28NQhwfAuOy3TPof/+m9rxhzTvubGTaYdALLlJNWODvAOjSMv83lxNzTba/ynfj6jrbCap5T+NHEL1Rpvf4ZqbVl3Uq10f4NpT5Ty9/niN/j6m27hswbn7+MzAyvETqeWVf8R9TlZsZRqKFxHpTVPHqHaG0vt2XU3b7NTgABQOsBn/83vsfcvAHQVV1CtO5sPGwyF7DTgUO986tMLO9XHE7PGdj/GfR3H+QPCg99xAooHv+MEFA9+xwkoHvyOE1BSerUf8UyEelab0jWdo9Tt2LW7TXtpxUbq07Wb94M708eLXIqreAFGZ9zOINwavpH6bLv7EaqtHP4m1UYaD1Nt1d3tVDs9bpdbyBE+GmzgKj6Sa2U3zwQ0V26nWt3IStM+2L+N+iRWlFDtSPetVCuv44U9VYfsjES8kGcI+mKdVDtWUU61nE5+7MQr+ZX7rpY80x5p5z0qxyJ24ZfK9At7/MzvOAHFg99xAooHv+MEFA9+xwkoHvyOE1A8+B0noKQ01RcLjeFkht2LTcZ4umbuikOmfV8fL8IZzLcLOgAgvZuPfuoZL6JaNGSP15qbs4f63JB9N9Wac5upNprgKaXCjGVUGyqzUz37CrnP1VG+H1uOvk21G/7VTlEBwPGFdjFWxyD3mdfEewkuK+A9DQszeHqrZ/mYad/TxUdhLU7wtPNQMe/vt/MmnkJe+Pww1a4tto/Hoe5rqM9oxD5OVfnaJ+NnfscJKB78jhNQPPgdJ6B48DtOQPHgd5yA4sHvOAHlgqk+EXkKwP0AOlR1RdJWBOBZAPMANAF4WFV5GV2SgfEevDn8nKmd+If/Sv1Gztj91hYM87RRcxfvZtazmFfFDfXziq5Tq+3qt2U9PEV1oqmFatE6Pm6sKMZ7Gp7dkk21eVfbKaVX3ztAfVYW8W31dGVRre9z3VTL2mP3wSuq3E998oZ55Vtx9AzVGvJ5NWCR2unZzEHeW7F1AZWQP8b3VcUefi5NrLbT1QCwcEehad/Ms9VYO2z3cRwff5E7TWI6Z/6fAbhnku1xAK+rah2A15P/dxznU8QFg19VNwGY/Bb/AICnk7efBvDgRV6X4ziXmE/6nX+uqrYBQPJv6cVbkuM4qeCS/7xXRNYDWA8AEope6s05jjNNPumZ/7SIlANA8m8Hu6OqblDVtaq6VkKp7RrmOA7nkwb/SwAeTd5+FMD0LzE6jnNZMJ1U3y8BrANQIiItAL4D4PsAnhORrwJoBvAn09mYagyxmJ16OTjAU0pFC+xRR7KVp/oi736Laolr11Mt42q76hAA0GF/bRmdf4y6PLCbj4XaX1JJtd5sfhllZZyn2AbH7DRgtIVXiEWvspttAsCSEV7FdqK1l2q5JXbD0LG2OurTUW1XAgJA5fAA1U4V11Itc0e6bR+vpz5SwZ9Xzwg/5q4+xL/Wbl/Bz7NlS+3jp7qRpzdPjNiNSWPg1bGTuWDwq+qXiPSZaW/FcZzLDv+Fn+MEFA9+xwkoHvyOE1A8+B0noHjwO05ASemvblQF46N2JdvS0ibq1/juctN+ZYxX042U8Oq83D1fp9quxDNUmz/HTuUU1PIUz6lFvFnoykyuHczk6bwT3QuptnjUnid4qpg3duwOX0+1WK2dZgWAnlZ++BQXLDLtrQX23EUAuCe6lGqvLuMNMMuHeErs8B12U83Kel4Z2drKm7jWhE5QTfN4U9ClMb4fD9TZTUbvzuRzDYvG7Dl+aYP2Y1n4md9xAooHv+MEFA9+xwkoHvyOE1A8+B0noHjwO05ASWmqLwQgE3aq78h7xdRvuNiuenquns+YKynj1XmnttsNEwGguGk11drL3zHt/Sf5Oq4p3U61vLPcr7z2Cqrt6GqgWnenXb1X2sFn7mW8+RLV+lbNo1pRLX/Mvka72Wl4jFfFNaXzNFXhFj7X8I3cO6i2cMiuIm3CPOpTMo/3otUEr8SMNdsVhAAwFumi2kCBnY7cs4hXuv7RYfv4Dg3zxrUfue+07+k4zh8UHvyOE1A8+B0noHjwO05A8eB3nICS0qv9pWmCP6u1r4hGE09Rv+4d9tXQSBYfhdV9dC7VCrLHqZbfzws+xvfbve56qj+gPjsH+bZK82+hWvj3PFsxb8ESqu3Jes2033r956lPVi4vkBpr3UK1/ijvxzcyYheyREd50cz7u3kWY+g43x+1y3kRVNqCm037aD7vrSgH+P4dXMVf6+wiPm4sszWfaqsG7cfsnjfFyLk++1hM9GylPpPxM7/jBBQPfscJKB78jhNQPPgdJ6B48DtOQPHgd5yAMp1xXU8BuB9Ah6quSNq+C+AxAOca5T2hqq9c6LES5UD3t+3UV9k23mNuqNIupphzhvdF62tfRrX+St7z7UAWLzDKWW0XZ/Sl26OTACD/1SaqPT+wk2p/ee/nqDZQYxdHAUDHm4dN+4mqd6lP0d6jVOu91u6fCADp7bz4qAV2mmqx/I76bBzhqa3Sfv5alzfaqWAAGBywU4Sy9irqkyjfRTVEeGHSkPJ0ZOjk3fwxq+z03ND4IHXpvs7uURlvGeHbmbymadznZwDuMew/UtXVyX8XDHzHcS4vLhj8qroJAP8VheM4n0pm8p3/GyKyR0SeEhFeIO84zmXJJw3+HwNYCGA1gDYAP2B3FJH1IlIvIvXD/fynro7jpJZPFPyqelpVE6o6DuAnAK6d4r4bVHWtqq7NzPPkguNcLnyiaBSR8vP++xCAfRdnOY7jpIrppPp+CWAdgBIRaQHwHQDrRGQ1AAXQBOBr09nYaDiEY/l21VxOFU/X5Hfaqa3RwQq+sW6eOizrT6Na4fxNVMv5rZ1G6SrOpD49D++g2u6XeY+29a/xdN73D9xOtZL/cL9pz440UZ8D+V+m2qYl/HVJNPHRW1dtetm077yXp69GCngPvMODfF+Fh/gaa9RO6175Lk/n9dZM0RtyrIRqncX8XFpRFKZaeptdgdqe4Psq7Uq7z6BE7TFeFhcMflX9kmH+6bS34DjOZYl/CXecgOLB7zgBxYPfcQKKB7/jBBQPfscJKClt4ClQRMWu3Eof5e9DkZO2z/jbV1Kf4YFSqp3M5uOpOk/Q3yshXvgvpv3sFL9cvO3XvGHlF2v4aLCKIl5d+NK6zVTLONVo2k+HeCXjnHd4OvLO3Xw81b333Ua1benrTPv2V16kPssHeUVacz4/VEdHBqjWGrabk/ZmRKlPVTpPK+qpRVQLF/BxY2OFTVSLxex9HC3jlZgnE3Y6MqZ7qM9k/MzvOAHFg99xAooHv+MEFA9+xwkoHvyOE1A8+B0noKQ01ReJRVB8wq6KSt+6gPoN96yw7V28CmyhDlOtSPh73j59j2qjvR2mPTeTVxAeXsB3cXGz/XgAUHzPdVT73Ps8tfXCv7O3d1ucNwSt+WO+P04Lf24Hd71Ktcxyu/JwVeWfUJ+tuzdSLa/Ubp4KAOlDvPqtL8+uIq1qbac+8X7emLQyl++P5iLe7a5kiB8H4dBJ057o5unIlbl2WjFLlfpMxs/8jhNQPPgdJ6B48DtOQPHgd5yA4sHvOAElpVf7x+PpGO6tMbXyE2XUb+/p+aZ9IfhV7/3KC3ui8Ueo1nn2W1S7n4xP6ozb2QgAiDbwK8c9pdxv7QneE7X3jvuodu9p+2rv1rh9RRkAQnV8TFZluX21HAB2jdhFMwBQ+ltbG8riz/mOEB+FtXHb76mWvdjuZwcAuQ29pj2/lPe6y6rl+6otja9xaYJfae8cjVEtZ3GGaT82xDMLea+/bdpD/TwmPnLfad/TcZw/KDz4HSegePA7TkDx4HecgOLB7zgBxYPfcQLKdMZ1VQP4OYAyAOMANqjqkyJSBOBZAPMwMbLrYVXlORcAOSNh3NqQb2rD/Tw1l15jF8CM9PPCGImXU+1vImup9twoLyDZFrLHg5UleBFR8ZCdagKAgjaeKutJrKTayrk8pdTc0WTa1819jPrUj/DUVv9hfn64ppb399tBiq6W11MXvAg+Qutm1FHt7KEWqq3JsotjtJe/LpvT+fiv/i/w0WzDu2qpllnaSrXdg3bfyPuy+bb+/a5tpr01ztO2k5nOmT8O4K9VdRmA6wH8hYgsB/A4gNdVtQ7A68n/O47zKeGCwa+qbaq6I3l7AEADgEoADwB4Onm3pwE8eKkW6TjOxedjfecXkXkArgKwBcBcVW0DJt4gAPDP7Y7jXHZMO/hFJAfArwF8U1X7P4bfehGpF5H6wVH+3dhxnNQyreAXkSgmAv8Xqvp80nxaRMqTejkA8+qbqm5Q1bWqujYnnV/AcBwntVww+EVEAPwUQIOq/vA86SUAjyZvPwqAj2JxHOeyYzpVfTcB+AqAvSJyLhfzBIDvA3hORL4KoBkAb86WZDCUhs3ZdlVfXc0x6ldwkIzlKrUrmwAgp/1Rqu0aS6NaVL9HtTlEezvxX6jPfSGe4lkY4uOYcgrsHngAsP1tniIcLi407U/v4e/Nd0b4J7L+A3wU2av6PtX2nnzYtMfX8BTbulM8nTfcy6vwxjN4lWZrzB5Ttu/qs9Rny+f5GnMb7qBa9ZW88vDoQf7cqtPsfVxfxisIO2BrcfA+gpO5YPCr6mYAQuTPTHtLjuNcVvgv/BwnoHjwO05A8eB3nIDiwe84AcWD33ECSkobeKaHh7Ewb7+pLTpsV8wBwCE7e4WKgWrqU5fPU1t9+FOqLRu9l2oFQ6tM+5+Dpw4fG99CtV8V22lPAAjVFVBtxThv7FjebTfcXLPAbhIJAAenqKiUCn5+yKrk2qIvPmvaD2zno7V2zuXNPUv38X3V2cPTdttL7TWOr+qkPl/exI/FI+v4iLLiMb6OxRVHuV/7MtP+dPpS6jOmdnrwY0zr8jO/4wQVD37HCSge/I4TUDz4HSegePA7TkDx4HecgJLSVN+oAodH7FxE/B6eChlvsuuKnvsyrwTMbflzqi1ZyJt03lRvN54EgKrddiXV4o5/pT7P3MXTaPO7N1PtbGKMavW911OtIm+Jad/RySvVlue3Uy19jKebFu/lKcfxhK3pIf6atefxdGR/yW6+rQhvdvqXQ3ZqcXQ5TxOfLG2k2hX7eXPPviK7OS0AHOe7CuXH95j2bhRTn/GQHUcq08/1+ZnfcQKKB7/jBBQPfscJKB78jhNQPPgdJ6Ck9Go/ss8icoM9Zmjwfz9E3XoX2z3r1u5aR31W3Pgzqu08dTPVCr7wNNV2329fgX/3OO/rtqD0A6odVj5a6WAuH4X1tXd5n7bB+AnT/sXb+VX2A8183686yotVjmbZRUQA0FlWZtpj4weoz0gZH9dVGS6i2nAV72lYkmaPwtr2+73Up2iOvXYAGCs7SLX0s1VUu6XXfl0AYP+d9mN+4YX/SH0+UN7TcLr4md9xAooHv+MEFA9+xwkoHvyOE1A8+B0noHjwO05AuWCqT0SqAfwcQBmAcQAbVPVJEfkugMcAnGuG9oSqvjLVY8VGQmg+nGVqVWkx6nd6ySnTvr+KT/1NHF5MtSty7UIKANijPG207NA1pr05na8jNEAaEALoPX0b1a7L4KO86kvtnm8AUL3Y7id4+gVe8HH2Oj6u66lreEXKowcOU21Xz4Bpr+mJUp/hI1dQrSjKx4bNL+Q9FBsy7XFpeen2cQgA6WGeSu1L8GKb7Ayeuq0fXU210B576PVrPfzxwuFFpl3jDdRnMtPJ88cB/LWq7hCRXADbRWRjUvuRqv79tLfmOM5lw3Rm9bUBaEveHhCRBgD8FyiO43wq+Fjf+UVkHoCrAJzrR/0NEdkjIk+JCP986zjOZce0g19EcgD8GsA3VbUfwI8BLASwGhOfDH5A/NaLSL2I1I8N8e8wjuOklmkFv4hEMRH4v1DV5wFAVU+rakJVxwH8BID5I2pV3aCqa1V1bTQrfLHW7TjODLlg8IuIAPgpgAZV/eF59vLz7vYQgH0Xf3mO41wqpnO1/yYAXwGwV0TOlV09AeBLIrIagAJoAvC1Cz1QNBbB3GY7VRLO6KN+S7bZaY3RPjsFCADI4mOhdtfw/nh5+/m4rncX22t86DDvgbevaznVYjW8l2BmC+8Hl172FtUGGu00YPdC/j7fP3qEatdH51JtW1Uu1Sqb7FRaQw2vcszOmEe1TuVpxXAJX0fFyHHT3ljBezXmh/lxlZ/G/bITvALyVCHvUVm+udy0r1zyPvU5mP+Cae/YfB/1mcx0rvZvBmB10Jwyp+84zuWN/8LPcQKKB7/jBBQPfscJKB78jhNQPPgdJ6CkdlxXRgJH6+wKpuzuWuqnV7eZ9kg6b5h4/TbehFG28kq1wVp7NBgAXLPF/pHSyyvmU5+lwreVl86bSA7ybCQSR9dRbU6uPfKqJY1X9VWd5KnKDUW8Smx9hp2iAoCu0/Y+CQ3y8V/pkTNUW3yCb6utg49EW5LbadoPVvLXWZRr8aMLqRaew1O3bfEWqkXn2VWVkTP8IEhbs9G0y047viz8zO84AcWD33ECige/4wQUD37HCSge/I4TUDz4HSegpDTVJ4ggTeyqvppxXhE1cNKuECvI55WAWx7kaaPM4QqqoYtXdDXW2d3LFgw2Up/oIV6dNzDXniMHAGv28eqx6Dh/bvu67Hl3raVvUp832vhhUF3FU1vPF/JGovfX2485lM7PN9lZvDpvD89UYnlmL9Vaam0tZ2EP9ek5MkUaMIOnRUfT66nW18Yb2ZxKs2NikfDU4fKB3aa9O8GbyU7Gz/yOE1A8+B0noHjwO05A8eB3nIDiwe84AcWD33ECSkpTfeFEBHn9dlqjffUI9YtF7DRgQf9K6lO1227cCABSald6AUDaWT5Lrm/+S6Y9sfd66tO2mFf13dTzHtV+t5Sn8zannaBaOGanyxI5JdSntvRmrjXwmYel7/E05mDUfs0ywzy9WdHM02g9A3xIVOMZPmswUmhX/PWH+fFx1RSnxP4beEr60I94A+v2JQuolpFvb/BAfgH1WaSnTfs2TFEOOgk/8ztOQPHgd5yA4sHvOAHFg99xAooHv+MElAte7ReRDACbAKQn7/8rVf2OiMwH8AyAIgA7AHxFVWNTPVbGcATL9ttXnee28p57R++yixVy3uRXQ3fcxYt3wq+tpdqhxfz9sPh73zbt9/XyUUy1o9up9r9u4+OYzqbzQpBYAe93WHBiiWm/sohXxmjnDVQL7+bZj7EEP3y6IvbV7ZJRXnjSOlxHtbozUwx5HeJX4G/eZBeFtb2VQ32O38OzML99oZlqeaihWlnDXVQbKrKzHJEo71s4/4D9ekbOTn8Y7nTO/KMA7lDVKzExjvseEbkewN8C+JGq1gHoAfDVaW/VcZxZ54LBrxOcm3oZTf5TAHcA+FXS/jSABy/JCh3HuSRM6zu/iISTE3o7AGwEcBRAr6rGk3dpAcB/heE4zmXHtIJfVROquhpAFYBrAVhdHMwvISKyXkTqRaR+ODb9RgOO41xaPtbVflXtBfAWgOsBFIjIuSs+VQDMFjiqukFV16rq2sw0/jNMx3FSywWDX0TmiEhB8nYmgDsBNAB4E8AXk3d7FMCLl2qRjuNcfKZT2FMO4GkRCWPizeI5VX1ZRA4AeEZE/gbATgA/vdADjSOEAc02tfRoEfUrG9xm2iXCLzPkt+RR7aEtrVQr3cp73R0ftHsG/nfwQqHTaTz9Ez8zRS/B63iKLRbjfoll1ab9QAkvmrmymRe5VO/l2zp8lhf9ZGTYY6PSwiepTySjkGoS5gUr9RH7mAKA/9z3gWlPxAdNOwCEnudp1qwbeDFZeQEfHzen2x6jBgA3nrJTlQuyeQr5xRVx0z7UyAvJJnPB4FfVPQCuMuzHMPH933GcTyH+Cz/HCSge/I4TUDz4HSegePA7TkDx4HecgCKqU8xButgbE+kEcK4BXQkAPo8odfg6Poyv48N82tZRq6pzpvOAKQ3+D21YpF5VeW2tr8PX4eu4pOvwj/2OE1A8+B0noMxm8G+YxW2fj6/jw/g6Pswf7Dpm7Tu/4zizi3/sd5yAMivBLyL3iMghEWkUkcdnYw3JdTSJyF4R2SUi9Snc7lMi0iEi+86zFYnIRhE5kvzLS9wu7Tq+KyKtyX2yS0TuS8E6qkXkTRFpEJH9IvJXSXtK98kU60jpPhGRDBHZKiK7k+v4n0n7fBHZktwfz4pI2ow2pKop/QcgjIk2YAsApAHYDWB5qteRXEsTgJJZ2O6tANYA2Hee7e8APJ68/TiAv52ldXwXwLdSvD/KAaxJ3s4FcBjA8lTvkynWkdJ9AkAA5CRvRwFswUQDnecAPJK0/18AX5/JdmbjzH8tgEZVPaYTrb6fAfDALKxj1lDVTQC6J5kfwEQjVCBFDVHJOlKOqrap6o7k7QFMNIupRIr3yRTrSCk6wSVvmjtPdN1BAAABvklEQVQbwV8J4PyODrPZ/FMBvCYi20Vk/Syt4RxzVbUNmDgIAdjjZVPDN0RkT/JrwSX/+nE+IjIPE/0jtmAW98mkdQAp3iepaJo7G8Evhm22Ug43qeoaAPcC+AsRuXWW1nE58WMACzExo6ENwA9StWERyQHwawDfVFW7FdDsrCPl+0Rn0DR3usxG8LcAOL/XFG3+ealR1VPJvx0AfoPZ7Ux0WkTKASD5t2M2FqGqp5MH3jiAnyBF+0REopgIuF+o6vNJc8r3ibWO2donyW1/7Ka502U2gn8bgLrklcs0AI8AeCnVixCRbBHJPXcbwGcB7Jva65LyEiYaoQKz2BD1XLAleQgp2CciIpjoAdmgqj88T0rpPmHrSPU+SVnT3FRdwZx0NfM+TFxJPQrg27O0hgWYyDTsBrA/lesA8EtMfHwcw8Qnoa8CKAbwOoAjyb9Fs7SOfwKwF8AeTARfeQrWcTMmPsLuAbAr+e++VO+TKdaR0n0CYBUmmuLuwcQbzf8475jdCqARwL8ASJ/JdvwXfo4TUPwXfo4TUDz4HSegePA7TkDx4HecgOLB7zgBxYPfcQKKB7/jBBQPfscJKP8f5aORkyuW++YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    plt.imshow(x_adv[i].cpu().detach().permute(1, 2, 0).numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## RotNet\n",
    "\n",
    "Train small network on top of pre-trained rotation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {'num_classes': 4, 'num_stages': 4}\n",
    "net = NetworkInNetwork(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('saved_models/model_net_epoch200')['network'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net._feature_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net_wrap = NINWrapper(net, block=2)\n",
    "net_wrap = net_wrap.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_wrap.fc = nn.Sequential(\n",
    "#     nn.Linear(12288, 200),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(200, 200),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(200, 128))\n",
    "net_wrap.fc = nn.Sequential(\n",
    "    nn.Linear(12288, 2000),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(2000, 400),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(400, 128))\n",
    "net_wrap = net_wrap.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_wrap.load_state_dict(torch.load('saved_models/transfer_cifar10_exp11.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PreActResNet(PreActBlock, [2, 2, 2, 2], num_classes=4)\n",
    "net.load_state_dict(torch.load('saved_models/rot_cifar10_exp0.h5'))\n",
    "net_wrap = ResNetWrapper(net, block=3, dim=16384)\n",
    "for param in net_wrap.parameters():\n",
    "    param.requires_grad = False\n",
    "# net_wrap.fc = nn.Sequential(\n",
    "#     nn.Linear(16384, 2000),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(2000, 400),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(400, 128),\n",
    "# )\n",
    "net_wrap.fc = nn.Sequential(\n",
    "    nn.BatchNorm1d(16384),\n",
    "    nn.Linear(16384, 2000),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm1d(2000),\n",
    "    nn.Linear(2000, 400),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm1d(400),\n",
    "    nn.Linear(400, 128),\n",
    ")\n",
    "net_wrap.load_state_dict(torch.load('saved_models/transfer_cifar10_exp18.h5'))\n",
    "net_wrap = net_wrap.to('cuda').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers = ['fc']\n",
    "\n",
    "dknn = DKNNL2(net_wrap, x_train, y_train, x_valid, y_valid, layers, \n",
    "              k=1, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7015\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = dknn.classify(x_test)\n",
    "    print((y_pred.argmax(1) == y_test.numpy()).sum() / y_test.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0011\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    num = 0\n",
    "    for i in range(x_test.size(0) // 100):\n",
    "        begin = i * 100\n",
    "        end = (i + 1) * 100\n",
    "        y_pred = net_wrap(x_test[begin:end].to('cuda'))\n",
    "        num += (y_pred.argmax(1).cpu() == y_test[begin:end]).sum().numpy()\n",
    "    print(num / y_test.size(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
