{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import foolbox\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from lib.dataset_utils import *\n",
    "from lib.mnist_model import *\n",
    "from lib.adv_model import *\n",
    "from lib.dknn_attack import DKNNAttack\n",
    "from lib.cwl2_attack import CWL2Attack\n",
    "from lib.dknn import DKNN, DKNNL2\n",
    "from lib.knn import *\n",
    "from lib.foolbox_model import *\n",
    "from lib.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = 0\n",
    "\n",
    "model_name = 'train_mnist_exp%d.h5' % exp_id\n",
    "net = BasicModel()\n",
    "\n",
    "# model_name = 'train_mnist_snnl_exp%d.h5' % exp_id\n",
    "# net = SNNLModel(train_it=True)\n",
    "\n",
    "# model_name = 'train_mnist_hidden_mixup_exp%d.h5' % exp_id\n",
    "# net = HiddenMixupModel()\n",
    "\n",
    "# model_name = 'train_mnist_vae_exp%d.h5' % exp_id\n",
    "# net = VAE((1, 28, 28), num_classes=10, latent_dim=20)\n",
    "# net = VAE2((1, 28, 28), num_classes=10, latent_dim=1000)\n",
    "\n",
    "# model_name = 'train_mnist_cav_exp%d.h5' % exp_id\n",
    "# net = ClassAuxVAE((1, 28, 28), num_classes=10, latent_dim=20)\n",
    "\n",
    "# model_name = 'adv_mnist_exp%d.h5' % exp_id\n",
    "# basic_net = BasicModel()\n",
    "# # basic_net = BasicModelV2()\n",
    "# config = {'epsilon': 0.3,\n",
    "#               'num_steps': 40,\n",
    "#               'step_size': 0.01,\n",
    "#               'random_start': True,\n",
    "#               'loss_func': 'xent'}\n",
    "# net = PGDModel(basic_net, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicModel(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3))\n",
       "  (relu1): ReLU(inplace)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(6, 6), stride=(2, 2), padding=(3, 3))\n",
       "  (relu2): ReLU(inplace)\n",
       "  (conv3): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu3): ReLU(inplace)\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set all random seeds\n",
    "seed = 2019\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Set up model directory\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "net = net.module\n",
    "# net = net.basic_net\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid), (x_test, y_test) = load_mnist_all(\n",
    "    '/data', val_size=0.1, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = net(x_test.to(device))\n",
    "(y_pred.argmax(1).cpu() == y_test).sum().numpy() / y_test.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers = ['relu1', 'relu2', 'relu3', 'fc']\n",
    "# layers = ['relu1', 'relu2', 'relu3']\n",
    "layers = ['relu3']\n",
    "# layers = ['fc']\n",
    "# layers = ['en_conv3']\n",
    "# layers = ['en_mu']\n",
    "# layers = ['maxpool1', 'maxpool2', 'relu3', 'fc2']\n",
    "# layers = ['maxpool2']\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     dknn = DKNN(net, x_train, y_train, x_valid, y_valid, layers, \n",
    "#                 k=75, num_classes=10)\n",
    "#     y_pred = dknn.classify(x_test)\n",
    "    \n",
    "dknn = DKNNL2(net, x_train, y_train, x_valid, y_valid, layers, \n",
    "              k=75, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = dknn.classify(x_test)\n",
    "    print((y_pred.argmax(1) == y_test.numpy()).sum() / y_test.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 949., 1033.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        8018.]),\n",
       " array([0.016 , 0.1144, 0.2128, 0.3112, 0.4096, 0.508 , 0.6064, 0.7048,\n",
       "        0.8032, 0.9016, 1.    ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cred = dknn.credibility(y_pred)\n",
    "plt.hist(cred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.argmax(y_pred, 1) == y_test.numpy()\n",
    "num_correct_by_cred = np.zeros((10, ))\n",
    "num_cred = np.zeros((10, ))\n",
    "for i in np.arange(10):\n",
    "    ind = (cred > i * 0.1) & (cred <= i* 0.1 + 0.1)\n",
    "    num_cred[i] = np.sum(ind)\n",
    "    num_correct_by_cred[i] = np.sum(correct[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(np.arange(10) * 0.1, num_cred, width=0.05)\n",
    "ax.bar(np.arange(10) * 0.1 + 0.05, num_correct_by_cred, width=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.79532164, 0.98402839,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan, 0.99912696])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct_by_cred / num_cred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dknn_fb = DkNNFoolboxModel(dknn, (0, 1), 1, preprocessing=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from foolbox.criteria import Misclassification\n",
    "from foolbox.distances import MeanSquaredDistance, Linfinity \n",
    "\n",
    "criterion = Misclassification()\n",
    "distance = MeanSquaredDistance\n",
    "# distance = Linfinity\n",
    "\n",
    "attack = foolbox.attacks.BoundaryAttack(\n",
    "    model=dknn_fb, criterion=criterion, distance=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither starting_point nor initialization_attack given. Falling back to BlendedUniformNoiseAttack for initialization.\n",
      "Initial spherical_step = 0.05, source_step = 0.05\n",
      "Using 4 threads to create random numbers\n",
      "Step 0: 8.71503e-02, stepsizes = 5.0e-02/5.0e-02: \n",
      "  Success rate too low, decreasing source step:  0.57 ( 75), 0.00 (30)\n",
      "  Boundary too linear, increasing steps:     0.57 (100), 0.00 (14)\n",
      "  Success rate too low, decreasing source step:  0.54 ( 50), 0.00 (30)\n",
      "  Boundary too linear, increasing steps:     0.60 (100), 0.00 (30)\n",
      "  Success rate too low, decreasing source step:  0.60 (100), 0.00 (30)\n",
      "Step 100: 8.14371e-02, stepsizes = 1.1e-01/3.3e-02:  (took 6.76223 seconds)\n",
      "Initializing generation and prediction time measurements. This can take a few seconds.\n",
      "During initialization, a better adversarial has been found. Continuing from there.\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 554.59922\n",
      "   1.1% for generation (6.25549)\n",
      "   16.3% for spherical prediction (90.54015)\n",
      "   70.2% for prediction (389.50291)\n",
      "   0.0% for hyperparameter update (0.01096)\n",
      "   12.3% for the rest (68.28972)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.45084204e-03 1.91211700e-04 1.20162964e-04 9.33557749e-05\n",
      " 9.86003876e-05 1.02659067e-04 5.88699263e-05 1.44593418e-04\n",
      " 2.70413764e-05 5.16819954e-05 3.56721484e-05 2.62359778e-05\n",
      " 1.00375633e-04 6.04014007e-05 2.20002068e-05 6.00768253e-05\n",
      " 3.29570374e-05 1.39614682e-05 2.09762119e-05 1.81198120e-05\n",
      " 2.72483782e-05 2.22990336e-05 1.99852458e-05 1.87961592e-05\n",
      " 2.11219788e-05]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.15137659 0.111557   0.08790184 0.05471493 0.05113087 0.04182358\n",
      " 0.03310718 0.03373081 0.02765109 0.02613037 0.02541505 0.02388676\n",
      " 0.02474129 0.02415169 0.03075306 0.02746896 0.0279274  0.02608513\n",
      " 0.02521813 0.01452073 0.0173193  0.01419146 0.01431854 0.01169178\n",
      " 0.01355133]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.99 0.   0.   0.   0.   0.   0.01 0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "Using batch size   1, an average step would have taken 3.81646 = 0.06081 + 3.75565 seconds\n",
      "Using batch size   2, an average step would have taken 2.81413 = 0.00698 + 2.80715 seconds\n",
      "Using batch size   3, an average step would have taken 2.24897 = 0.00529 + 2.24368 seconds\n",
      "Using batch size   4, an average step would have taken 1.45892 = 0.00465 + 1.45427 seconds\n",
      "Using batch size   5, an average step would have taken 1.27305 = 0.00245 + 1.27060 seconds\n",
      "Using batch size   6, an average step would have taken 1.15097 = 0.00487 + 1.14610 seconds\n",
      "Using batch size   7, an average step would have taken 0.90888 = 0.00160 + 0.90729 seconds\n",
      "Using batch size   8, an average step would have taken 0.95988 = 0.00587 + 0.95401 seconds\n",
      "Using batch size   9, an average step would have taken 0.72556 = 0.00089 + 0.72466 seconds\n",
      "Using batch size  10, an average step would have taken 0.77461 = 0.00152 + 0.77309 seconds\n",
      "Using batch size  11, an average step would have taken 0.81854 = 0.00114 + 0.81740 seconds\n",
      "Using batch size  12, an average step would have taken 0.72333 = 0.00305 + 0.72028 seconds\n",
      "Using batch size  13, an average step would have taken 0.60703 = 0.00162 + 0.60541 seconds\n",
      "Using batch size  14, an average step would have taken 0.61613 = 0.00123 + 0.61489 seconds\n",
      "Using batch size  15, an average step would have taken 0.72083 = 0.00084 + 0.71999 seconds\n",
      "Using batch size  16, an average step would have taken 0.68708 = 0.00120 + 0.68587 seconds\n",
      "Using batch size  17, an average step would have taken 0.74362 = 0.00171 + 0.74191 seconds\n",
      "Using batch size  18, an average step would have taken 0.69962 = 0.00066 + 0.69897 seconds\n",
      "Using batch size  19, an average step would have taken 0.72858 = 0.00101 + 0.72758 seconds\n",
      "Using batch size  20, an average step would have taken 0.54436 = 0.00085 + 0.54351 seconds\n",
      "Using batch size  21, an average step would have taken 0.58132 = 0.00094 + 0.58038 seconds\n",
      "Using batch size  22, an average step would have taken 0.57413 = 0.00085 + 0.57328 seconds\n",
      "Using batch size  23, an average step would have taken 0.55105 = 0.00084 + 0.55021 seconds\n",
      "Using batch size  24, an average step would have taken 0.43334 = 0.00288 + 0.43047 seconds\n",
      "Using batch size  25, an average step would have taken 0.33931 = 0.00053 + 0.33878 seconds\n",
      "batch size was 1, optimal batch size would have been 25\n",
      "setting batch size to 25: expected step duration: 0.33931\n",
      "improvement compared to old batch size (1): 11.2x\n",
      "improvement compared to worst batch size (1): 11.2x\n",
      "improvement compared to smallest batch size (1): 11.2x\n",
      "improvement compared to largest batch size (25): 1.0x\n",
      "next batch size tuning in 100 steps, after step 200\n",
      "  Success rate too low, decreasing source step:  0.39 (100), 0.00 (30)\n",
      "  Success rate too low, decreasing source step:  0.30 (100), 0.00 (30)\n",
      "Step 200: 4.27449e-02, stepsizes = 1.1e-01/1.5e-02:  (took 0.57975 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 590.42577\n",
      "   1.2% for generation (6.98607)\n",
      "   15.9% for spherical prediction (93.74619)\n",
      "   70.9% for prediction (418.68837)\n",
      "   0.0% for hyperparameter update (0.02450)\n",
      "   12.0% for the rest (70.98064)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.45084204e-03 1.91211700e-04 1.20162964e-04 9.33557749e-05\n",
      " 9.86003876e-05 1.02659067e-04 5.88699263e-05 1.44593418e-04\n",
      " 2.70413764e-05 5.16819954e-05 3.56721484e-05 2.62359778e-05\n",
      " 1.00375633e-04 6.04014007e-05 2.20002068e-05 6.00768253e-05\n",
      " 3.29570374e-05 1.39614682e-05 2.09762119e-05 1.81198120e-05\n",
      " 2.72483782e-05 2.22990336e-05 1.99852458e-05 1.87961592e-05\n",
      " 1.17827047e-05]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.15137659 0.111557   0.08790184 0.05471493 0.05113087 0.04182358\n",
      " 0.03310718 0.03373081 0.02765109 0.02613037 0.02541505 0.02388676\n",
      " 0.02474129 0.02415169 0.03075306 0.02746896 0.0279274  0.02608513\n",
      " 0.02521813 0.01452073 0.0173193  0.01419146 0.01431854 0.01169178\n",
      " 0.012996  ]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.84 0.05 0.   0.01 0.01 0.02 0.01 0.02 0.   0.   0.   0.   0.01 0.\n",
      " 0.   0.   0.01 0.   0.   0.   0.   0.01 0.01 0.   0.   0.  ]\n",
      "Using batch size   1, an average step would have taken 3.40420 = 0.05424 + 3.34996 seconds\n",
      "Using batch size   2, an average step would have taken 2.52063 = 0.00615 + 2.51448 seconds\n",
      "Using batch size   3, an average step would have taken 2.02257 = 0.00464 + 2.01792 seconds\n",
      "Using batch size   4, an average step would have taken 1.31307 = 0.00408 + 1.30900 seconds\n",
      "Using batch size   5, an average step would have taken 1.15779 = 0.00223 + 1.15556 seconds\n",
      "Using batch size   6, an average step would have taken 1.04237 = 0.00429 + 1.03807 seconds\n",
      "Using batch size   7, an average step would have taken 0.82479 = 0.00145 + 0.82334 seconds\n",
      "Using batch size   8, an average step would have taken 0.87176 = 0.00523 + 0.86654 seconds\n",
      "Using batch size   9, an average step would have taken 0.66797 = 0.00081 + 0.66716 seconds\n",
      "Using batch size  10, an average step would have taken 0.71251 = 0.00140 + 0.71111 seconds\n",
      "Using batch size  11, an average step would have taken 0.74814 = 0.00104 + 0.74710 seconds\n",
      "Using batch size  12, an average step would have taken 0.66582 = 0.00265 + 0.66318 seconds\n",
      "Using batch size  13, an average step would have taken 0.57259 = 0.00158 + 0.57101 seconds\n",
      "Using batch size  14, an average step would have taken 0.58253 = 0.00119 + 0.58135 seconds\n",
      "Using batch size  15, an average step would have taken 0.68941 = 0.00078 + 0.68863 seconds\n",
      "Using batch size  16, an average step would have taken 0.65469 = 0.00117 + 0.65352 seconds\n",
      "Using batch size  17, an average step would have taken 0.70839 = 0.00156 + 0.70683 seconds\n",
      "Using batch size  18, an average step would have taken 0.66944 = 0.00061 + 0.66884 seconds\n",
      "Using batch size  19, an average step would have taken 0.69588 = 0.00093 + 0.69495 seconds\n",
      "Using batch size  20, an average step would have taken 0.51106 = 0.00079 + 0.51028 seconds\n",
      "Using batch size  21, an average step would have taken 0.55063 = 0.00089 + 0.54974 seconds\n",
      "Using batch size  22, an average step would have taken 0.53452 = 0.00079 + 0.53372 seconds\n",
      "Using batch size  23, an average step would have taken 0.51752 = 0.00078 + 0.51674 seconds\n",
      "Using batch size  24, an average step would have taken 0.41027 = 0.00251 + 0.40776 seconds\n",
      "Using batch size  25, an average step would have taken 0.32519 = 0.00029 + 0.32490 seconds\n",
      "batch size was 25, optimal batch size would have been 25\n",
      "setting batch size to 25: expected step duration: 0.32519\n",
      "improvement compared to old batch size (25): 1.0x\n",
      "improvement compared to worst batch size (1): 10.5x\n",
      "improvement compared to smallest batch size (1): 10.5x\n",
      "improvement compared to largest batch size (25): 1.0x\n",
      "next batch size tuning in 200 steps, after step 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Boundary too non-linear, decreasing steps: 0.16 (100), 0.15 (27)\n",
      "  Success rate too low, decreasing source step:  0.28 ( 25), 0.07 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.15 (100), 0.00 ( 8)\n",
      "  Success rate too low, decreasing source step:  0.24 (100), 0.07 (30)\n",
      "Step 300: 2.22285e-02, stepsizes = 5.0e-02/2.9e-03:  (took 0.56806 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.14 ( 7)\n",
      "  Success rate too high, increasing source step: 0.50 (100), 0.53 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.17 (100), 0.12 (17)\n",
      "Step 400: 1.60728e-02, stepsizes = 2.2e-02/2.0e-03: d. reduced by 0.39% (6.2898e-05) (took 0.63767 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 665.30181\n",
      "   1.3% for generation (8.47660)\n",
      "   15.1% for spherical prediction (100.38279)\n",
      "   72.1% for prediction (479.77963)\n",
      "   0.0% for hyperparameter update (0.05073)\n",
      "   11.5% for the rest (76.61206)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.45084204e-03 1.91211700e-04 1.20162964e-04 9.33557749e-05\n",
      " 9.86003876e-05 1.02659067e-04 5.88699263e-05 1.44593418e-04\n",
      " 2.70413764e-05 5.16819954e-05 3.56721484e-05 2.62359778e-05\n",
      " 1.00375633e-04 6.04014007e-05 2.20002068e-05 6.00768253e-05\n",
      " 3.29570374e-05 1.39614682e-05 2.09762119e-05 1.81198120e-05\n",
      " 2.72483782e-05 2.22990336e-05 1.99852458e-05 1.87961592e-05\n",
      " 1.18767089e-05]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.15137659 0.111557   0.08790184 0.05471493 0.05113087 0.04182358\n",
      " 0.03310718 0.03373081 0.02765109 0.02613037 0.02541505 0.02388676\n",
      " 0.02474129 0.02415169 0.03075306 0.02746896 0.0279274  0.02608513\n",
      " 0.02521813 0.01452073 0.0173193  0.01419146 0.01431854 0.01169178\n",
      " 0.01337691]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.375 0.065 0.035 0.035 0.04  0.02  0.04  0.04  0.03  0.015 0.045 0.025\n",
      " 0.025 0.035 0.015 0.025 0.035 0.02  0.01  0.02  0.01  0.005 0.01  0.015\n",
      " 0.005 0.005]\n",
      "Using batch size   1, an average step would have taken 2.37048 = 0.03777 + 2.33271 seconds\n",
      "Using batch size   2, an average step would have taken 1.77379 = 0.00387 + 1.76992 seconds\n",
      "Using batch size   3, an average step would have taken 1.44744 = 0.00283 + 1.44461 seconds\n",
      "Using batch size   4, an average step would have taken 0.93429 = 0.00242 + 0.93187 seconds\n",
      "Using batch size   5, an average step would have taken 0.86194 = 0.00166 + 0.86028 seconds\n",
      "Using batch size   6, an average step would have taken 0.76156 = 0.00265 + 0.75890 seconds\n",
      "Using batch size   7, an average step would have taken 0.61457 = 0.00108 + 0.61349 seconds\n",
      "Using batch size   8, an average step would have taken 0.64653 = 0.00344 + 0.64309 seconds\n",
      "Using batch size   9, an average step would have taken 0.52181 = 0.00059 + 0.52121 seconds\n",
      "Using batch size  10, an average step would have taken 0.53438 = 0.00105 + 0.53333 seconds\n",
      "Using batch size  11, an average step would have taken 0.55636 = 0.00078 + 0.55558 seconds\n",
      "Using batch size  12, an average step would have taken 0.51328 = 0.00143 + 0.51185 seconds\n",
      "Using batch size  13, an average step would have taken 0.48077 = 0.00148 + 0.47929 seconds\n",
      "Using batch size  14, an average step would have taken 0.48875 = 0.00106 + 0.48769 seconds\n",
      "Using batch size  15, an average step would have taken 0.59515 = 0.00059 + 0.59456 seconds\n",
      "Using batch size  16, an average step would have taken 0.55879 = 0.00108 + 0.55771 seconds\n",
      "Using batch size  17, an average step would have taken 0.59863 = 0.00109 + 0.59755 seconds\n",
      "Using batch size  18, an average step would have taken 0.57310 = 0.00043 + 0.57266 seconds\n",
      "Using batch size  19, an average step would have taken 0.58645 = 0.00066 + 0.58579 seconds\n",
      "Using batch size  20, an average step would have taken 0.39708 = 0.00057 + 0.39651 seconds\n",
      "Using batch size  21, an average step would have taken 0.45416 = 0.00073 + 0.45344 seconds\n",
      "Using batch size  22, an average step would have taken 0.41833 = 0.00063 + 0.41769 seconds\n",
      "Using batch size  23, an average step would have taken 0.41583 = 0.00061 + 0.41523 seconds\n",
      "Using batch size  24, an average step would have taken 0.33951 = 0.00138 + 0.33813 seconds\n",
      "Using batch size  25, an average step would have taken 0.33472 = 0.00030 + 0.33442 seconds\n",
      "batch size was 25, optimal batch size would have been 25\n",
      "setting batch size to 25: expected step duration: 0.33472\n",
      "improvement compared to old batch size (25): 1.0x\n",
      "improvement compared to worst batch size (1): 7.1x\n",
      "improvement compared to smallest batch size (1): 7.1x\n",
      "improvement compared to largest batch size (25): 1.0x\n",
      "next batch size tuning in 400 steps, after step 800\n",
      "  Success rate too low, decreasing source step:  0.54 ( 50), 0.10 (30)\n",
      "  Success rate too low, decreasing source step:  0.42 (100), 0.13 (30)\n",
      "  Boundary too linear, increasing steps:     0.55 (100), 0.50 (30)\n",
      "Step 500: 1.28827e-02, stepsizes = 3.3e-02/1.3e-03: d. reduced by 0.26% (3.3576e-05) (took 0.47150 seconds)\n",
      "  Success rate too high, increasing source step: 0.25 ( 75), 0.53 (30)\n",
      "  Success rate too low, decreasing source step:  0.24 (100), 0.17 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.29 ( 7)\n",
      "Step 600: 1.07505e-02, stepsizes = 2.2e-02/8.7e-04:  (took 0.58791 seconds)\n",
      "Step 700: 9.72139e-03, stepsizes = 2.2e-02/8.7e-04: d. reduced by 0.17% (1.6880e-05) (took 0.46884 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.18 (100), 0.27 (30)\n",
      "  Success rate too low, decreasing source step:  0.29 (100), 0.17 (30)\n",
      "Step 800: 9.13289e-03, stepsizes = 1.5e-02/3.9e-04: d. reduced by 0.08% (7.0431e-06) (took 0.50726 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 801.84314\n",
      "   1.4% for generation (11.44182)\n",
      "   14.0% for spherical prediction (112.63841)\n",
      "   73.5% for prediction (589.36522)\n",
      "   0.0% for hyperparameter update (0.17784)\n",
      "   11.0% for the rest (88.21985)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.45084204e-03 1.91211700e-04 1.20162964e-04 9.33557749e-05\n",
      " 9.86003876e-05 1.02659067e-04 5.88699263e-05 1.44593418e-04\n",
      " 2.70413764e-05 5.16819954e-05 3.56721484e-05 2.62359778e-05\n",
      " 1.00375633e-04 6.04014007e-05 2.20002068e-05 6.00768253e-05\n",
      " 3.29570374e-05 1.39614682e-05 2.09762119e-05 1.81198120e-05\n",
      " 2.72483782e-05 2.22990336e-05 1.99852458e-05 1.87961592e-05\n",
      " 1.18676772e-05]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.15137659 0.111557   0.08790184 0.05471493 0.05113087 0.04182358\n",
      " 0.03310718 0.03373081 0.02765109 0.02613037 0.02541505 0.02388676\n",
      " 0.02474129 0.02415169 0.03075306 0.02746896 0.0279274  0.02608513\n",
      " 0.02521813 0.01452073 0.0173193  0.01419146 0.01431854 0.01169178\n",
      " 0.01269511]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.325  0.1075 0.0625 0.03   0.04   0.05   0.0375 0.0325 0.0375 0.04\n",
      " 0.035  0.0225 0.0125 0.0225 0.0075 0.0275 0.015  0.0125 0.015  0.015\n",
      " 0.0175 0.0075 0.015  0.005  0.0075 0.    ]\n",
      "Using batch size   1, an average step would have taken 2.10244 = 0.03350 + 2.06894 seconds\n",
      "Using batch size   2, an average step would have taken 1.58262 = 0.00342 + 1.57920 seconds\n",
      "Using batch size   3, an average step would have taken 1.29308 = 0.00249 + 1.29059 seconds\n",
      "Using batch size   4, an average step would have taken 0.84691 = 0.00215 + 0.84475 seconds\n",
      "Using batch size   5, an average step would have taken 0.77677 = 0.00150 + 0.77527 seconds\n",
      "Using batch size   6, an average step would have taken 0.69335 = 0.00237 + 0.69098 seconds\n",
      "Using batch size   7, an average step would have taken 0.56540 = 0.00100 + 0.56440 seconds\n",
      "Using batch size   8, an average step would have taken 0.59810 = 0.00314 + 0.59496 seconds\n",
      "Using batch size   9, an average step would have taken 0.48035 = 0.00054 + 0.47981 seconds\n",
      "Using batch size  10, an average step would have taken 0.49214 = 0.00097 + 0.49118 seconds\n",
      "Using batch size  11, an average step would have taken 0.51046 = 0.00071 + 0.50975 seconds\n",
      "Using batch size  12, an average step would have taken 0.47828 = 0.00127 + 0.47701 seconds\n",
      "Using batch size  13, an average step would have taken 0.45781 = 0.00145 + 0.45636 seconds\n",
      "Using batch size  14, an average step would have taken 0.46845 = 0.00103 + 0.46742 seconds\n",
      "Using batch size  15, an average step would have taken 0.57552 = 0.00055 + 0.57496 seconds\n",
      "Using batch size  16, an average step would have taken 0.54509 = 0.00106 + 0.54402 seconds\n",
      "Using batch size  17, an average step would have taken 0.58576 = 0.00103 + 0.58473 seconds\n",
      "Using batch size  18, an average step would have taken 0.56091 = 0.00041 + 0.56049 seconds\n",
      "Using batch size  19, an average step would have taken 0.57451 = 0.00063 + 0.57387 seconds\n",
      "Using batch size  20, an average step would have taken 0.38299 = 0.00054 + 0.38245 seconds\n",
      "Using batch size  21, an average step would have taken 0.44156 = 0.00070 + 0.44085 seconds\n",
      "Using batch size  22, an average step would have taken 0.40182 = 0.00061 + 0.40121 seconds\n",
      "Using batch size  23, an average step would have taken 0.40410 = 0.00059 + 0.40351 seconds\n",
      "Using batch size  24, an average step would have taken 0.33105 = 0.00125 + 0.32980 seconds\n",
      "Using batch size  25, an average step would have taken 0.31767 = 0.00030 + 0.31738 seconds\n",
      "batch size was 25, optimal batch size would have been 25\n",
      "setting batch size to 25: expected step duration: 0.31767\n",
      "improvement compared to old batch size (25): 1.0x\n",
      "improvement compared to worst batch size (1): 6.6x\n",
      "improvement compared to smallest batch size (1): 6.6x\n",
      "improvement compared to largest batch size (25): 1.0x\n",
      "next batch size tuning in 800 steps, after step 1600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 900: 8.58667e-03, stepsizes = 1.5e-02/3.9e-04: d. reduced by 0.08% (6.6217e-06) (took 0.44916 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.10 (100), 0.57 (30)\n",
      "  Success rate too high, increasing source step: 0.10 (100), 0.57 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.15 (100), 0.05 (22)\n",
      "Step 1000: 8.20488e-03, stepsizes = 6.6e-03/2.6e-04:  (took 0.46306 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.14 (100), 0.17 (30)\n",
      "  Success rate too low, decreasing source step:  0.14 (100), 0.17 (30)\n",
      "Step 1100: 8.00269e-03, stepsizes = 4.4e-03/1.1e-04: d. reduced by 0.02% (1.8279e-06) (took 0.64393 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.17 (100), 0.33 (30)\n",
      "Step 1200: 7.85601e-03, stepsizes = 2.9e-03/7.6e-05: d. reduced by 0.02% (1.1963e-06) (took 0.58013 seconds)\n",
      "  Boundary too linear, increasing steps:     0.65 (100), 0.73 (30)\n",
      "  Success rate too high, increasing source step: 0.65 (100), 0.73 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.05 (19)\n",
      "  Success rate too low, decreasing source step:  0.23 ( 75), 0.03 (30)\n",
      "Step 1300: 7.77716e-03, stepsizes = 2.9e-03/7.6e-05:  (took 0.55007 seconds)\n",
      "Step 1400: 7.69003e-03, stepsizes = 2.9e-03/7.6e-05: d. reduced by 0.02% (1.1709e-06) (took 0.46434 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.17 (100), 0.30 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.17 (100), 0.20 (30)\n",
      "  Success rate too high, increasing source step: 0.88 ( 25), 0.67 (30)\n",
      "Step 1500: 7.64671e-03, stepsizes = 1.3e-03/5.1e-05:  (took 0.49196 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.11 (100), 0.00 (11)\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.10 (30)\n",
      "  Success rate too low, decreasing source step:  0.19 (100), 0.10 (30)\n",
      "Step 1600: 7.63338e-03, stepsizes = 5.8e-04/1.5e-05: d. reduced by 0.00% (2.2948e-07) (took 0.59119 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 1073.41773\n",
      "   1.6% for generation (17.10293)\n",
      "   12.8% for spherical prediction (137.23131)\n",
      "   75.4% for prediction (809.68219)\n",
      "   0.0% for hyperparameter update (0.29219)\n",
      "   10.2% for the rest (109.10911)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.45084204e-03 1.91211700e-04 1.20162964e-04 9.33557749e-05\n",
      " 9.86003876e-05 1.02659067e-04 5.88699263e-05 1.44593418e-04\n",
      " 2.70413764e-05 5.16819954e-05 3.56721484e-05 2.62359778e-05\n",
      " 1.00375633e-04 6.04014007e-05 2.20002068e-05 6.00768253e-05\n",
      " 3.29570374e-05 1.39614682e-05 2.09762119e-05 1.81198120e-05\n",
      " 2.72483782e-05 2.22990336e-05 1.99852458e-05 1.87961592e-05\n",
      " 1.15769589e-05]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.15137659 0.111557   0.08790184 0.05471493 0.05113087 0.04182358\n",
      " 0.03310718 0.03373081 0.02765109 0.02613037 0.02541505 0.02388676\n",
      " 0.02474129 0.02415169 0.03075306 0.02746896 0.0279274  0.02608513\n",
      " 0.02521813 0.01452073 0.0173193  0.01419146 0.01431854 0.01169178\n",
      " 0.01245301]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.375   0.09625 0.055   0.04    0.05125 0.04625 0.04    0.03    0.0275\n",
      " 0.0175  0.01875 0.02125 0.0175  0.01375 0.0175  0.00875 0.01625 0.01875\n",
      " 0.015   0.015   0.01875 0.01375 0.0075  0.00125 0.00875 0.00875]\n",
      "Using batch size   1, an average step would have taken 2.24146 = 0.03571 + 2.20575 seconds\n",
      "Using batch size   2, an average step would have taken 1.68050 = 0.00371 + 1.67678 seconds\n",
      "Using batch size   3, an average step would have taken 1.36979 = 0.00273 + 1.36706 seconds\n",
      "Using batch size   4, an average step would have taken 0.89376 = 0.00236 + 0.89140 seconds\n",
      "Using batch size   5, an average step would have taken 0.82031 = 0.00158 + 0.81873 seconds\n",
      "Using batch size   6, an average step would have taken 0.72786 = 0.00258 + 0.72528 seconds\n",
      "Using batch size   7, an average step would have taken 0.58683 = 0.00104 + 0.58579 seconds\n",
      "Using batch size   8, an average step would have taken 0.62712 = 0.00337 + 0.62376 seconds\n",
      "Using batch size   9, an average step would have taken 0.50181 = 0.00057 + 0.50124 seconds\n",
      "Using batch size  10, an average step would have taken 0.51932 = 0.00102 + 0.51830 seconds\n",
      "Using batch size  11, an average step would have taken 0.53966 = 0.00075 + 0.53891 seconds\n",
      "Using batch size  12, an average step would have taken 0.50058 = 0.00142 + 0.49916 seconds\n",
      "Using batch size  13, an average step would have taken 0.47359 = 0.00147 + 0.47212 seconds\n",
      "Using batch size  14, an average step would have taken 0.48105 = 0.00104 + 0.48000 seconds\n",
      "Using batch size  15, an average step would have taken 0.59221 = 0.00059 + 0.59162 seconds\n",
      "Using batch size  16, an average step would have taken 0.56066 = 0.00108 + 0.55958 seconds\n",
      "Using batch size  17, an average step would have taken 0.60100 = 0.00110 + 0.59991 seconds\n",
      "Using batch size  18, an average step would have taken 0.57397 = 0.00044 + 0.57353 seconds\n",
      "Using batch size  19, an average step would have taken 0.58866 = 0.00067 + 0.58799 seconds\n",
      "Using batch size  20, an average step would have taken 0.39708 = 0.00057 + 0.39651 seconds\n",
      "Using batch size  21, an average step would have taken 0.45224 = 0.00072 + 0.45152 seconds\n",
      "Using batch size  22, an average step would have taken 0.41668 = 0.00063 + 0.41605 seconds\n",
      "Using batch size  23, an average step would have taken 0.41751 = 0.00061 + 0.41690 seconds\n",
      "Using batch size  24, an average step would have taken 0.34009 = 0.00139 + 0.33869 seconds\n",
      "Using batch size  25, an average step would have taken 0.31161 = 0.00029 + 0.31133 seconds\n",
      "batch size was 25, optimal batch size would have been 25\n",
      "setting batch size to 25: expected step duration: 0.31161\n",
      "improvement compared to old batch size (25): 1.0x\n",
      "improvement compared to worst batch size (1): 7.2x\n",
      "improvement compared to smallest batch size (1): 7.2x\n",
      "improvement compared to largest batch size (25): 1.0x\n",
      "next batch size tuning in 1600 steps, after step 3200\n",
      "  Boundary too non-linear, decreasing steps: 0.16 (100), 0.20 (30)\n",
      "  Success rate too low, decreasing source step:  0.16 ( 25), 0.13 (30)\n",
      "Step 1700: 7.62161e-03, stepsizes = 3.9e-04/6.7e-06: d. reduced by 0.00% (1.0190e-07) (took 0.60677 seconds)\n",
      "  Success rate too high, increasing source step: 0.37 (100), 0.77 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.11 (100), 0.18 (11)\n",
      "Step 1800: 7.61265e-03, stepsizes = 2.6e-04/6.7e-06:  (took 0.72589 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.02 (100), 0.15 (13)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.15 (13)\n",
      "Step 1900: 7.61220e-03, stepsizes = 1.1e-04/3.0e-06:  (took 0.46295 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.15 (13)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.14 (14)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.14 (14)\n",
      "Step 2000: 7.61220e-03, stepsizes = 3.4e-05/8.8e-07:  (took 0.36714 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.14 (14)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.14 (14)\n",
      "Step 2100: 7.61216e-03, stepsizes = 1.5e-05/3.9e-07:  (took 0.34722 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.13 (15)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.13 (15)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.12 (16)\n",
      "Step 2200: 7.61213e-03, stepsizes = 4.5e-06/1.2e-07:  (took 0.32535 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.12 (17)\n",
      "Step 2240: 7.61212e-03, stepsizes = 3.0e-06/7.7e-08: \n",
      "Looks like attack has converged after 2241 steps for the first time. Resetting steps to be sure.\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.12 (17)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.12 (17)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.11 (18)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.11 (18)\n",
      "  Boundary too non-linear, decreasing steps: 0.02 (100), 0.10 (20)\n",
      "  Boundary too non-linear, decreasing steps: 0.02 (100), 0.09 (22)\n",
      "  Boundary too non-linear, decreasing steps: 0.02 (100), 0.08 (24)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.08 (25)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.08 (25)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.08 (25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.08 (25)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.08 (25)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.08 (25)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.08 (25)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.08 (25)\n",
      "Step 2300: 7.61212e-03, stepsizes = 2.3e-05/2.3e-05:  (took 0.24838 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.08 (25)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.08 (25)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.08 (26)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.08 (26)\n",
      "  Boundary too non-linear, decreasing steps: 0.02 (100), 0.07 (28)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.07 (28)\n",
      "  Success rate too low, decreasing source step:  0.03 ( 75), 0.07 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.03 (100), 0.00 ( 1)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.00 ( 2)\n",
      "  Boundary too non-linear, decreasing steps: 0.02 (100), 0.00 ( 4)\n",
      "  Boundary too non-linear, decreasing steps: 0.02 (100), 0.00 ( 6)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.00 ( 7)\n",
      "  Boundary too non-linear, decreasing steps: 0.05 (100), 0.00 (12)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.00 (12)\n",
      "Step 2352: 7.61212e-03, stepsizes = 1.2e-07/7.8e-08: \n",
      "Looks like attack has converged after 2353 steps, 100 remaining\n",
      "Step 2353: 7.61212e-03, stepsizes = 1.2e-07/7.8e-08: \n",
      "Looks like attack has converged after 2354 steps, 99 remaining\n",
      "Step 2354: 7.61212e-03, stepsizes = 1.2e-07/7.8e-08: \n",
      "Looks like attack has converged after 2355 steps, 98 remaining\n",
      "Step 2355: 7.61212e-03, stepsizes = 1.2e-07/7.8e-08: \n",
      "Looks like attack has converged after 2356 steps, 97 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.02 (100), 0.00 (14)\n",
      "Step 2356: 7.61212e-03, stepsizes = 7.8e-08/5.2e-08: \n",
      "Looks like attack has converged after 2357 steps, 96 remaining\n",
      "Step 2357: 7.61212e-03, stepsizes = 7.8e-08/5.2e-08: \n",
      "Looks like attack has converged after 2358 steps, 95 remaining\n",
      "Step 2358: 7.61212e-03, stepsizes = 7.8e-08/5.2e-08: \n",
      "Looks like attack has converged after 2359 steps, 94 remaining\n",
      "Step 2359: 7.61212e-03, stepsizes = 7.8e-08/5.2e-08: \n",
      "Looks like attack has converged after 2360 steps, 93 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.07 (100), 0.00 (21)\n",
      "Step 2360: 7.61212e-03, stepsizes = 5.2e-08/3.5e-08: \n",
      "Looks like attack has converged after 2361 steps, 92 remaining\n",
      "Step 2361: 7.61212e-03, stepsizes = 5.2e-08/3.5e-08: \n",
      "Looks like attack has converged after 2362 steps, 91 remaining\n",
      "Step 2362: 7.61212e-03, stepsizes = 5.2e-08/3.5e-08: \n",
      "Looks like attack has converged after 2363 steps, 90 remaining\n",
      "Step 2363: 7.61212e-03, stepsizes = 5.2e-08/3.5e-08: \n",
      "Looks like attack has converged after 2364 steps, 89 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.03 (100), 0.00 (24)\n",
      "Step 2364: 7.61212e-03, stepsizes = 3.5e-08/2.3e-08: \n",
      "Looks like attack has converged after 2365 steps, 88 remaining\n",
      "Step 2365: 7.61212e-03, stepsizes = 3.5e-08/2.3e-08: \n",
      "Looks like attack has converged after 2366 steps, 87 remaining\n",
      "Step 2366: 7.61212e-03, stepsizes = 3.5e-08/2.3e-08: \n",
      "Looks like attack has converged after 2367 steps, 86 remaining\n",
      "Step 2367: 7.61212e-03, stepsizes = 3.5e-08/2.3e-08: \n",
      "Looks like attack has converged after 2368 steps, 85 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.04 (100), 0.00 (28)\n",
      "Step 2368: 7.61212e-03, stepsizes = 2.3e-08/1.5e-08: \n",
      "Looks like attack has converged after 2369 steps, 84 remaining\n",
      "  Success rate too low, decreasing source step:  0.20 ( 25), 0.00 (30)\n",
      "Step 2369: 7.61212e-03, stepsizes = 2.3e-08/1.0e-08: \n",
      "Looks like attack has converged after 2370 steps, 83 remaining\n",
      "Step 2370: 7.61212e-03, stepsizes = 2.3e-08/1.0e-08: \n",
      "Looks like attack has converged after 2371 steps, 82 remaining\n",
      "Step 2371: 7.61212e-03, stepsizes = 2.3e-08/1.0e-08: \n",
      "Looks like attack has converged after 2372 steps, 81 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.13 (100), 0.12 ( 8)\n",
      "Step 2372: 7.61212e-03, stepsizes = 1.5e-08/6.9e-09: \n",
      "Looks like attack has converged after 2373 steps, 80 remaining\n",
      "Step 2373: 7.61212e-03, stepsizes = 1.5e-08/6.9e-09: \n",
      "Looks like attack has converged after 2374 steps, 79 remaining\n",
      "Step 2374: 7.61212e-03, stepsizes = 1.5e-08/6.9e-09: \n",
      "Looks like attack has converged after 2375 steps, 78 remaining\n",
      "Step 2375: 7.61212e-03, stepsizes = 1.5e-08/6.9e-09: \n",
      "Looks like attack has converged after 2376 steps, 77 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.18 (100), 0.19 (26)\n",
      "Step 2376: 7.61212e-03, stepsizes = 1.0e-08/4.6e-09: \n",
      "Looks like attack has converged after 2377 steps, 76 remaining\n",
      "Step 2377: 7.61212e-03, stepsizes = 1.0e-08/4.6e-09: \n",
      "Looks like attack has converged after 2378 steps, 75 remaining\n",
      "Step 2378: 7.61212e-03, stepsizes = 1.0e-08/4.6e-09: \n",
      "Looks like attack has converged after 2379 steps, 74 remaining\n",
      "Step 2379: 7.61212e-03, stepsizes = 1.0e-08/4.6e-09: \n",
      "Looks like attack has converged after 2380 steps, 73 remaining\n",
      "Step 2380: 7.61212e-03, stepsizes = 1.0e-08/4.6e-09: \n",
      "Looks like attack has converged after 2381 steps, 72 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.23 (30)\n",
      "Step 2381: 7.61212e-03, stepsizes = 6.9e-09/3.1e-09: \n",
      "Looks like attack has converged after 2382 steps, 71 remaining\n",
      "Step 2382: 7.61212e-03, stepsizes = 6.9e-09/3.1e-09: \n",
      "Looks like attack has converged after 2383 steps, 70 remaining\n",
      "Step 2383: 7.61212e-03, stepsizes = 6.9e-09/3.1e-09: \n",
      "Looks like attack has converged after 2384 steps, 69 remaining\n",
      "  Success rate too low, decreasing source step:  0.36 ( 75), 0.17 (30)\n",
      "Step 2384: 7.61212e-03, stepsizes = 6.9e-09/2.0e-09: \n",
      "Looks like attack has converged after 2385 steps, 68 remaining\n",
      "Step 2385: 7.61212e-03, stepsizes = 6.9e-09/2.0e-09: \n",
      "Looks like attack has converged after 2386 steps, 67 remaining\n",
      "Step 2386: 7.61212e-03, stepsizes = 6.9e-09/2.0e-09: \n",
      "Looks like attack has converged after 2387 steps, 66 remaining\n",
      "Step 2387: 7.61212e-03, stepsizes = 6.9e-09/2.0e-09: \n",
      "Looks like attack has converged after 2388 steps, 65 remaining\n",
      "Step 2388: 7.61212e-03, stepsizes = 6.9e-09/2.0e-09: \n",
      "Looks like attack has converged after 2389 steps, 64 remaining\n",
      "Step 2389: 7.61212e-03, stepsizes = 6.9e-09/2.0e-09: \n",
      "Looks like attack has converged after 2390 steps, 63 remaining\n",
      "Step 2390: 7.61212e-03, stepsizes = 6.9e-09/2.0e-09: \n",
      "Looks like attack has converged after 2391 steps, 62 remaining\n",
      "Step 2391: 7.61212e-03, stepsizes = 6.9e-09/2.0e-09: \n",
      "Looks like attack has converged after 2392 steps, 61 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.17 (100), 0.40 (30)\n",
      "Step 2392: 7.61212e-03, stepsizes = 4.6e-09/1.4e-09: \n",
      "Looks like attack has converged after 2393 steps, 60 remaining\n",
      "Step 2393: 7.61212e-03, stepsizes = 4.6e-09/1.4e-09: \n",
      "Looks like attack has converged after 2394 steps, 59 remaining\n",
      "Step 2394: 7.61212e-03, stepsizes = 4.6e-09/1.4e-09: \n",
      "Looks like attack has converged after 2395 steps, 58 remaining\n",
      "Step 2395: 7.61212e-03, stepsizes = 4.6e-09/1.4e-09: \n",
      "Looks like attack has converged after 2396 steps, 57 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.14 (100), 0.17 (30)\n",
      "  Success rate too low, decreasing source step:  0.14 (100), 0.17 (30)\n",
      "Step 2396: 7.61212e-03, stepsizes = 3.1e-09/6.0e-10: \n",
      "Looks like attack has converged after 2397 steps, 56 remaining\n",
      "Step 2397: 7.61212e-03, stepsizes = 3.1e-09/6.0e-10: \n",
      "Looks like attack has converged after 2398 steps, 55 remaining\n",
      "Step 2398: 7.61212e-03, stepsizes = 3.1e-09/6.0e-10: \n",
      "Looks like attack has converged after 2399 steps, 54 remaining\n",
      "Step 2399: 7.61212e-03, stepsizes = 3.1e-09/6.0e-10: \n",
      "Looks like attack has converged after 2400 steps, 53 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.15 (100), 0.00 (15)\n",
      "Step 2400: 7.61212e-03, stepsizes = 2.0e-09/4.0e-10:  (took 0.61583 seconds)\n",
      "Step 2400: 7.61212e-03, stepsizes = 2.0e-09/4.0e-10: \n",
      "Looks like attack has converged after 2401 steps, 52 remaining\n",
      "Step 2401: 7.61212e-03, stepsizes = 2.0e-09/4.0e-10: \n",
      "Looks like attack has converged after 2402 steps, 51 remaining\n",
      "Step 2402: 7.61212e-03, stepsizes = 2.0e-09/4.0e-10: \n",
      "Looks like attack has converged after 2403 steps, 50 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2403: 7.61212e-03, stepsizes = 2.0e-09/4.0e-10: \n",
      "Looks like attack has converged after 2404 steps, 49 remaining\n",
      "Step 2404: 7.61212e-03, stepsizes = 2.0e-09/4.0e-10: \n",
      "Looks like attack has converged after 2405 steps, 48 remaining\n",
      "  Success rate too high, increasing source step: 0.20 (100), 0.53 (30)\n",
      "Step 2405: 7.61212e-03, stepsizes = 2.0e-09/6.0e-10: \n",
      "Looks like attack has converged after 2406 steps, 47 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.15 (100), -1.00 ( 0)\n",
      "Step 2406: 7.61212e-03, stepsizes = 1.4e-09/4.0e-10: \n",
      "Looks like attack has converged after 2407 steps, 46 remaining\n",
      "Step 2407: 7.61212e-03, stepsizes = 1.4e-09/4.0e-10: \n",
      "Looks like attack has converged after 2408 steps, 45 remaining\n",
      "Step 2408: 7.61212e-03, stepsizes = 1.4e-09/4.0e-10: \n",
      "Looks like attack has converged after 2409 steps, 44 remaining\n",
      "Step 2409: 7.61212e-03, stepsizes = 1.4e-09/4.0e-10: \n",
      "Looks like attack has converged after 2410 steps, 43 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.17 (100), 0.59 (17)\n",
      "Step 2410: 7.61212e-03, stepsizes = 9.0e-10/2.7e-10: \n",
      "Looks like attack has converged after 2411 steps, 42 remaining\n",
      "Step 2411: 7.61212e-03, stepsizes = 9.0e-10/2.7e-10: \n",
      "Looks like attack has converged after 2412 steps, 41 remaining\n",
      "Step 2412: 7.61212e-03, stepsizes = 9.0e-10/2.7e-10: \n",
      "Looks like attack has converged after 2413 steps, 40 remaining\n",
      "  Success rate too high, increasing source step: 0.17 ( 75), 0.63 (30)\n",
      "Step 2413: 7.61212e-03, stepsizes = 9.0e-10/4.0e-10: \n",
      "Looks like attack has converged after 2414 steps, 39 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.16 (100), 0.33 ( 3)\n",
      "Step 2414: 7.61212e-03, stepsizes = 6.0e-10/2.7e-10: \n",
      "Looks like attack has converged after 2415 steps, 38 remaining\n",
      "Step 2415: 7.61212e-03, stepsizes = 6.0e-10/2.7e-10: \n",
      "Looks like attack has converged after 2416 steps, 37 remaining\n",
      "Step 2416: 7.61212e-03, stepsizes = 6.0e-10/2.7e-10: \n",
      "Looks like attack has converged after 2417 steps, 36 remaining\n",
      "Step 2417: 7.61212e-03, stepsizes = 6.0e-10/2.7e-10: \n",
      "Looks like attack has converged after 2418 steps, 35 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.11 (100), 0.43 (14)\n",
      "Step 2418: 7.61212e-03, stepsizes = 4.0e-10/1.8e-10: \n",
      "Looks like attack has converged after 2419 steps, 34 remaining\n",
      "Step 2419: 7.61212e-03, stepsizes = 4.0e-10/1.8e-10: \n",
      "Looks like attack has converged after 2420 steps, 33 remaining\n",
      "Step 2420: 7.61212e-03, stepsizes = 4.0e-10/1.8e-10: \n",
      "Looks like attack has converged after 2421 steps, 32 remaining\n",
      "Step 2421: 7.61212e-03, stepsizes = 4.0e-10/1.8e-10: \n",
      "Looks like attack has converged after 2422 steps, 31 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.12 (100), 0.35 (26)\n",
      "Step 2422: 7.61212e-03, stepsizes = 2.7e-10/1.2e-10: \n",
      "Looks like attack has converged after 2423 steps, 30 remaining\n",
      "Step 2423: 7.61212e-03, stepsizes = 2.7e-10/1.2e-10: \n",
      "Looks like attack has converged after 2424 steps, 29 remaining\n",
      "Step 2424: 7.61212e-03, stepsizes = 2.7e-10/1.2e-10: \n",
      "Looks like attack has converged after 2425 steps, 28 remaining\n",
      "  Success rate too low, decreasing source step:  0.19 ( 75), 0.13 (30)\n",
      "Step 2425: 7.61212e-03, stepsizes = 2.7e-10/7.9e-11: \n",
      "Looks like attack has converged after 2426 steps, 27 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.16 (100), 0.00 ( 2)\n",
      "Step 2426: 7.61212e-03, stepsizes = 1.8e-10/5.3e-11: \n",
      "Looks like attack has converged after 2427 steps, 26 remaining\n",
      "Step 2427: 7.61212e-03, stepsizes = 1.8e-10/5.3e-11: \n",
      "Looks like attack has converged after 2428 steps, 25 remaining\n",
      "Step 2428: 7.61212e-03, stepsizes = 1.8e-10/5.3e-11: \n",
      "Looks like attack has converged after 2429 steps, 24 remaining\n",
      "Step 2429: 7.61212e-03, stepsizes = 1.8e-10/5.3e-11: \n",
      "Looks like attack has converged after 2430 steps, 23 remaining\n",
      "Step 2430: 7.61212e-03, stepsizes = 1.8e-10/5.3e-11: \n",
      "Looks like attack has converged after 2431 steps, 22 remaining\n",
      "Step 2431: 7.61212e-03, stepsizes = 1.8e-10/5.3e-11: \n",
      "Looks like attack has converged after 2432 steps, 21 remaining\n",
      "Step 2432: 7.61212e-03, stepsizes = 1.8e-10/5.3e-11: \n",
      "Looks like attack has converged after 2433 steps, 20 remaining\n",
      "Step 2433: 7.61212e-03, stepsizes = 1.8e-10/5.3e-11: \n",
      "Looks like attack has converged after 2434 steps, 19 remaining\n",
      "  Success rate too low, decreasing source step:  0.29 (100), 0.17 (30)\n",
      "Step 2434: 7.61212e-03, stepsizes = 1.8e-10/3.5e-11: \n",
      "Looks like attack has converged after 2435 steps, 18 remaining\n",
      "Step 2435: 7.61212e-03, stepsizes = 1.8e-10/3.5e-11: \n",
      "Looks like attack has converged after 2436 steps, 17 remaining\n",
      "Step 2436: 7.61212e-03, stepsizes = 1.8e-10/3.5e-11: \n",
      "Looks like attack has converged after 2437 steps, 16 remaining\n",
      "Step 2437: 7.61212e-03, stepsizes = 1.8e-10/3.5e-11: \n",
      "Looks like attack has converged after 2438 steps, 15 remaining\n",
      "Step 2438: 7.61212e-03, stepsizes = 1.8e-10/3.5e-11: \n",
      "Looks like attack has converged after 2439 steps, 14 remaining\n",
      "Step 2439: 7.61212e-03, stepsizes = 1.8e-10/3.5e-11: \n",
      "Looks like attack has converged after 2440 steps, 13 remaining\n",
      "Step 2440: 7.61212e-03, stepsizes = 1.8e-10/3.5e-11: \n",
      "Looks like attack has converged after 2441 steps, 12 remaining\n",
      "Step 2441: 7.61212e-03, stepsizes = 1.8e-10/3.5e-11: \n",
      "Looks like attack has converged after 2442 steps, 11 remaining\n",
      "Step 2442: 7.61212e-03, stepsizes = 1.8e-10/3.5e-11: \n",
      "Looks like attack has converged after 2443 steps, 10 remaining\n",
      "Step 2443: 7.61212e-03, stepsizes = 1.8e-10/3.5e-11: \n",
      "Looks like attack has converged after 2444 steps, 9 remaining\n",
      "  Success rate too high, increasing source step: 0.28 (100), 0.57 (30)\n",
      "Step 2444: 7.61212e-03, stepsizes = 1.8e-10/5.3e-11: \n",
      "Looks like attack has converged after 2445 steps, 8 remaining\n",
      "Step 2445: 7.61212e-03, stepsizes = 1.8e-10/5.3e-11: \n",
      "Looks like attack has converged after 2446 steps, 7 remaining\n",
      "Step 2446: 7.61212e-03, stepsizes = 1.8e-10/5.3e-11: \n",
      "Looks like attack has converged after 2447 steps, 6 remaining\n",
      "Step 2447: 7.61212e-03, stepsizes = 1.8e-10/5.3e-11: \n",
      "Looks like attack has converged after 2448 steps, 5 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.17 (100), 0.24 (17)\n",
      "Step 2448: 7.61212e-03, stepsizes = 1.2e-10/3.5e-11: \n",
      "Looks like attack has converged after 2449 steps, 4 remaining\n",
      "Step 2449: 7.61212e-03, stepsizes = 1.2e-10/3.5e-11: \n",
      "Looks like attack has converged after 2450 steps, 3 remaining\n",
      "Step 2450: 7.61212e-03, stepsizes = 1.2e-10/3.5e-11: \n",
      "Looks like attack has converged after 2451 steps, 2 remaining\n",
      "Step 2451: 7.61212e-03, stepsizes = 1.2e-10/3.5e-11: \n",
      "Looks like attack has converged after 2452 steps, 1 remaining\n",
      "Time since beginning: 1386.99355\n",
      "   1.7% for generation (23.32915)\n",
      "   16.1% for spherical prediction (223.10696)\n",
      "   72.0% for prediction (998.81819)\n",
      "   0.0% for hyperparameter update (0.52050)\n",
      "   10.2% for the rest (141.21874)\n"
     ]
    }
   ],
   "source": [
    "attack_params = {\n",
    "    'iterations': 10000,\n",
    "    'max_directions': 25,\n",
    "    'starting_point': None,\n",
    "    'initialization_attack': None,\n",
    "    'log_every_n_steps': 100,\n",
    "    'spherical_step': 0.05,\n",
    "    'source_step': 0.05,\n",
    "    'step_adaptation': 1.5,\n",
    "    'batch_size': 1,\n",
    "    'tune_batch_size': True, \n",
    "    'threaded_rnd': True, \n",
    "    'threaded_gen': True, \n",
    "    'alternative_generator': False\n",
    "}\n",
    "\n",
    "num = 1\n",
    "x_adv = np.zeros_like(x_test[:num].numpy())\n",
    "for i in range(num):\n",
    "    x_adv[i] = attack(x_test[i].numpy(), label=y_test[i].numpy(), \n",
    "                      unpack=True, verbose=True, **attack_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = dknn.classify(torch.tensor(x_adv))\n",
    "print((y_pred.argmax(1) == y_test[:num].numpy()).sum() / num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4429293\n"
     ]
    }
   ],
   "source": [
    "dist = np.sqrt(np.sum((x_adv - x_test[:num].numpy())**2, (1, 2, 3)))\n",
    "print(dist.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38494432]\n"
     ]
    }
   ],
   "source": [
    "dist = np.max(np.abs(x_adv - x_test[:num].numpy()), (1, 2, 3))\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f269e7b5358>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_adv[0].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f269e788f98>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0].numpy().reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNNL2(x_train, y_train, x_valid, y_valid, k=75, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_fb = DkNNFoolboxModel(knn, (0, 1), 1, preprocessing=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from foolbox.criteria import Misclassification\n",
    "from foolbox.distances import MeanSquaredDistance, Linfinity \n",
    "\n",
    "criterion = Misclassification()\n",
    "distance = MeanSquaredDistance\n",
    "# distance = Linfinity\n",
    "\n",
    "attack = foolbox.attacks.BoundaryAttack(\n",
    "    model=knn_fb, criterion=criterion, distance=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither starting_point nor initialization_attack given. Falling back to BlendedUniformNoiseAttack for initialization.\n",
      "Initial spherical_step = 1.00, source_step = 0.10\n",
      "Using 4 threads to create random numbers\n",
      "Step 0: 2.51014e-01, stepsizes = 1.0e+00/1.0e-01: \n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "Step 100: 1.38781e-01, stepsizes = 4.4e-01/4.4e-02:  (took 0.80455 seconds)\n",
      "Initializing generation and prediction time measurements. This can take a few seconds.\n",
      "During initialization, a better adversarial has been found. Continuing from there.\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 192.98212\n",
      "   4.1% for generation (7.81726)\n",
      "   17.0% for spherical prediction (32.83595)\n",
      "   64.7% for prediction (124.82559)\n",
      "   0.0% for hyperparameter update (0.00618)\n",
      "   14.2% for the rest (27.49714)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[3.11849263e-03 1.29878521e-04 1.36057536e-04 1.03428960e-04\n",
      " 5.33008575e-05 5.96112675e-05 7.05427053e-05 5.46984375e-05\n",
      " 3.90005700e-05 4.76789474e-05 3.05688086e-05 6.86347485e-05\n",
      " 4.12308958e-05 4.78150893e-05 5.67139520e-05 1.85882673e-05\n",
      " 2.37131614e-05 4.29490466e-04 2.75957948e-05 1.03420019e-05\n",
      " 2.93714389e-05 1.88803870e-05 1.51794664e-05 9.36165452e-06\n",
      " 1.90753937e-05]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.04729938 0.02579688 0.02804977 0.02489193 0.02273439 0.01912259\n",
      " 0.01682576 0.01259852 0.01403215 0.01174186 0.01009572 0.01038138\n",
      " 0.01049701 0.01243431 0.01051983 0.01126348 0.00948429 0.01065676\n",
      " 0.00856411 0.01532085 0.00944899 0.01137929 0.00886216 0.00711982\n",
      " 0.00703244]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.94 0.   0.   0.   0.01 0.   0.01 0.   0.   0.   0.01 0.   0.01 0.01\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.01 0.   0.   0.  ]\n",
      "Using batch size   1, an average step would have taken 1.21860 = 0.07537 + 1.14323 seconds\n",
      "Using batch size   2, an average step would have taken 0.64993 = 0.00595 + 0.64398 seconds\n",
      "Using batch size   3, an average step would have taken 0.70440 = 0.00610 + 0.69830 seconds\n",
      "Using batch size   4, an average step would have taken 0.63028 = 0.00534 + 0.62494 seconds\n",
      "Using batch size   5, an average step would have taken 0.55374 = 0.00130 + 0.55245 seconds\n",
      "Using batch size   6, an average step would have taken 0.49511 = 0.00432 + 0.49078 seconds\n",
      "Using batch size   7, an average step would have taken 0.44153 = 0.00184 + 0.43969 seconds\n",
      "Using batch size   8, an average step would have taken 0.34398 = 0.00421 + 0.33977 seconds\n",
      "Using batch size   9, an average step would have taken 0.36311 = 0.00116 + 0.36194 seconds\n",
      "Using batch size  10, an average step would have taken 0.34050 = 0.00119 + 0.33930 seconds\n",
      "Using batch size  11, an average step would have taken 0.29892 = 0.00105 + 0.29787 seconds\n",
      "Using batch size  12, an average step would have taken 0.29318 = 0.00455 + 0.28863 seconds\n",
      "Using batch size  13, an average step would have taken 0.25613 = 0.00132 + 0.25481 seconds\n",
      "Using batch size  14, an average step would have taken 0.28057 = 0.00099 + 0.27958 seconds\n",
      "Using batch size  15, an average step would have taken 0.27065 = 0.00130 + 0.26935 seconds\n",
      "Using batch size  16, an average step would have taken 0.30082 = 0.00063 + 0.30019 seconds\n",
      "Using batch size  17, an average step would have taken 0.25780 = 0.00082 + 0.25698 seconds\n",
      "Using batch size  18, an average step would have taken 0.31191 = 0.00820 + 0.30371 seconds\n",
      "Using batch size  19, an average step would have taken 0.27258 = 0.00086 + 0.27172 seconds\n",
      "Using batch size  20, an average step would have taken 0.41487 = 0.00046 + 0.41441 seconds\n",
      "Using batch size  21, an average step would have taken 0.29403 = 0.00101 + 0.29302 seconds\n",
      "Using batch size  22, an average step would have taken 0.33024 = 0.00080 + 0.32944 seconds\n",
      "Using batch size  23, an average step would have taken 0.25292 = 0.00059 + 0.25233 seconds\n",
      "Using batch size  24, an average step would have taken 0.21849 = 0.00316 + 0.21534 seconds\n",
      "Using batch size  25, an average step would have taken 0.17629 = 0.00048 + 0.17581 seconds\n",
      "batch size was 1, optimal batch size would have been 25\n",
      "setting batch size to 25: expected step duration: 0.17629\n",
      "improvement compared to old batch size (1): 6.9x\n",
      "improvement compared to worst batch size (1): 6.9x\n",
      "improvement compared to smallest batch size (1): 6.9x\n",
      "improvement compared to largest batch size (25): 1.0x\n",
      "next batch size tuning in 100 steps, after step 200\n",
      "  Boundary too non-linear, decreasing steps: 0.03 (100), 0.00 ( 3)\n",
      "  Boundary too non-linear, decreasing steps: 0.10 (100), 0.15 (13)\n",
      "  Boundary too non-linear, decreasing steps: 0.11 (100), 0.08 (24)\n",
      "Step 200: 5.91938e-02, stepsizes = 1.3e-01/1.3e-02:  (took 0.22576 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 213.80539\n",
      "   4.0% for generation (8.55623)\n",
      "   16.3% for spherical prediction (34.86582)\n",
      "   66.4% for prediction (141.97577)\n",
      "   0.0% for hyperparameter update (0.08450)\n",
      "   13.2% for the rest (28.32308)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[3.11849263e-03 1.29878521e-04 1.36057536e-04 1.03428960e-04\n",
      " 5.33008575e-05 5.96112675e-05 7.05427053e-05 5.46984375e-05\n",
      " 3.90005700e-05 4.76789474e-05 3.05688086e-05 6.86347485e-05\n",
      " 4.12308958e-05 4.78150893e-05 5.67139520e-05 1.85882673e-05\n",
      " 2.37131614e-05 4.29490466e-04 2.75957948e-05 1.03420019e-05\n",
      " 2.93714389e-05 1.88803870e-05 1.51794664e-05 9.36165452e-06\n",
      " 1.18953101e-05]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.04729938 0.02579688 0.02804977 0.02489193 0.02273439 0.01912259\n",
      " 0.01682576 0.01259852 0.01403215 0.01174186 0.01009572 0.01038138\n",
      " 0.01049701 0.01243431 0.01051983 0.01126348 0.00948429 0.01065676\n",
      " 0.00856411 0.01532085 0.00944899 0.01137929 0.00886216 0.00711982\n",
      " 0.00759721]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.86 0.   0.01 0.   0.01 0.   0.   0.   0.   0.   0.01 0.   0.02 0.01\n",
      " 0.   0.01 0.   0.01 0.01 0.03 0.   0.01 0.01 0.   0.   0.  ]\n",
      "Using batch size   1, an average step would have taken 1.18633 = 0.07338 + 1.11295 seconds\n",
      "Using batch size   2, an average step would have taken 0.63293 = 0.00564 + 0.62730 seconds\n",
      "Using batch size   3, an average step would have taken 0.68684 = 0.00579 + 0.68105 seconds\n",
      "Using batch size   4, an average step would have taken 0.61525 = 0.00505 + 0.61020 seconds\n",
      "Using batch size   5, an average step would have taken 0.54235 = 0.00127 + 0.54108 seconds\n",
      "Using batch size   6, an average step would have taken 0.48532 = 0.00406 + 0.48126 seconds\n",
      "Using batch size   7, an average step would have taken 0.43234 = 0.00180 + 0.43054 seconds\n",
      "Using batch size   8, an average step would have taken 0.33793 = 0.00396 + 0.33397 seconds\n",
      "Using batch size   9, an average step would have taken 0.35838 = 0.00114 + 0.35723 seconds\n",
      "Using batch size  10, an average step would have taken 0.33252 = 0.00117 + 0.33135 seconds\n",
      "Using batch size  11, an average step would have taken 0.29216 = 0.00101 + 0.29114 seconds\n",
      "Using batch size  12, an average step would have taken 0.28789 = 0.00429 + 0.28360 seconds\n",
      "Using batch size  13, an average step would have taken 0.25487 = 0.00131 + 0.25356 seconds\n",
      "Using batch size  14, an average step would have taken 0.27946 = 0.00099 + 0.27847 seconds\n",
      "Using batch size  15, an average step would have taken 0.26829 = 0.00129 + 0.26700 seconds\n",
      "Using batch size  16, an average step would have taken 0.29829 = 0.00062 + 0.29766 seconds\n",
      "Using batch size  17, an average step would have taken 0.25476 = 0.00081 + 0.25396 seconds\n",
      "Using batch size  18, an average step would have taken 0.30718 = 0.00818 + 0.29900 seconds\n",
      "Using batch size  19, an average step would have taken 0.26452 = 0.00084 + 0.26369 seconds\n",
      "Using batch size  20, an average step would have taken 0.40689 = 0.00044 + 0.40645 seconds\n",
      "Using batch size  21, an average step would have taken 0.28603 = 0.00098 + 0.28505 seconds\n",
      "Using batch size  22, an average step would have taken 0.32348 = 0.00077 + 0.32271 seconds\n",
      "Using batch size  23, an average step would have taken 0.24877 = 0.00057 + 0.24820 seconds\n",
      "Using batch size  24, an average step would have taken 0.21446 = 0.00291 + 0.21155 seconds\n",
      "Using batch size  25, an average step would have taken 0.19023 = 0.00030 + 0.18993 seconds\n",
      "batch size was 25, optimal batch size would have been 25\n",
      "setting batch size to 25: expected step duration: 0.19023\n",
      "improvement compared to old batch size (25): 1.0x\n",
      "improvement compared to worst batch size (1): 6.2x\n",
      "improvement compared to smallest batch size (1): 6.2x\n",
      "improvement compared to largest batch size (25): 1.0x\n",
      "next batch size tuning in 200 steps, after step 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Success rate too low, decreasing source step:  0.12 ( 50), 0.07 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.15 (100), 0.11 ( 9)\n",
      "  Boundary too non-linear, decreasing steps: 0.15 (100), 0.21 (24)\n",
      "Step 300: 3.32159e-02, stepsizes = 5.9e-02/3.9e-03: d. reduced by 0.78% (2.6073e-04) (took 0.56737 seconds)\n",
      "  Success rate too low, decreasing source step:  0.20 ( 75), 0.17 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.16 (100), 1.00 ( 1)\n",
      "  Boundary too non-linear, decreasing steps: 0.14 (100), 0.22 (23)\n",
      "Step 400: 2.75217e-02, stepsizes = 2.6e-02/1.2e-03: d. reduced by 0.23% (6.3746e-05) (took 0.25705 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 276.01621\n",
      "   3.6% for generation (10.06696)\n",
      "   14.6% for spherical prediction (40.37381)\n",
      "   70.6% for prediction (194.93326)\n",
      "   0.0% for hyperparameter update (0.12338)\n",
      "   11.1% for the rest (30.51880)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[3.11849263e-03 1.29878521e-04 1.36057536e-04 1.03428960e-04\n",
      " 5.33008575e-05 5.96112675e-05 7.05427053e-05 5.46984375e-05\n",
      " 3.90005700e-05 4.76789474e-05 3.05688086e-05 6.86347485e-05\n",
      " 4.12308958e-05 4.78150893e-05 5.67139520e-05 1.85882673e-05\n",
      " 2.37131614e-05 4.29490466e-04 2.75957948e-05 1.03420019e-05\n",
      " 2.93714389e-05 1.88803870e-05 1.51794664e-05 9.36165452e-06\n",
      " 1.20219234e-05]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.04729938 0.02579688 0.02804977 0.02489193 0.02273439 0.01912259\n",
      " 0.01682576 0.01259852 0.01403215 0.01174186 0.01009572 0.01038138\n",
      " 0.01049701 0.01243431 0.01051983 0.01126348 0.00948429 0.01065676\n",
      " 0.00856411 0.01532085 0.00944899 0.01137929 0.00886216 0.00711982\n",
      " 0.01033736]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.51  0.07  0.04  0.035 0.035 0.035 0.02  0.015 0.015 0.01  0.01  0.005\n",
      " 0.02  0.01  0.02  0.02  0.005 0.02  0.03  0.015 0.015 0.005 0.    0.005\n",
      " 0.015 0.02 ]\n",
      "Using batch size   1, an average step would have taken 0.88156 = 0.05453 + 0.82703 seconds\n",
      "Using batch size   2, an average step would have taken 0.47266 = 0.00389 + 0.46878 seconds\n",
      "Using batch size   3, an average step would have taken 0.51800 = 0.00402 + 0.51398 seconds\n",
      "Using batch size   4, an average step would have taken 0.47014 = 0.00349 + 0.46665 seconds\n",
      "Using batch size   5, an average step would have taken 0.42100 = 0.00098 + 0.42002 seconds\n",
      "Using batch size   6, an average step would have taken 0.37660 = 0.00274 + 0.37386 seconds\n",
      "Using batch size   7, an average step would have taken 0.34003 = 0.00142 + 0.33861 seconds\n",
      "Using batch size   8, an average step would have taken 0.26663 = 0.00269 + 0.26394 seconds\n",
      "Using batch size   9, an average step would have taken 0.28764 = 0.00089 + 0.28675 seconds\n",
      "Using batch size  10, an average step would have taken 0.26543 = 0.00097 + 0.26446 seconds\n",
      "Using batch size  11, an average step would have taken 0.23698 = 0.00080 + 0.23618 seconds\n",
      "Using batch size  12, an average step would have taken 0.23865 = 0.00304 + 0.23560 seconds\n",
      "Using batch size  13, an average step would have taken 0.22227 = 0.00110 + 0.22117 seconds\n",
      "Using batch size  14, an average step would have taken 0.24827 = 0.00089 + 0.24738 seconds\n",
      "Using batch size  15, an average step would have taken 0.23410 = 0.00116 + 0.23295 seconds\n",
      "Using batch size  16, an average step would have taken 0.26093 = 0.00052 + 0.26041 seconds\n",
      "Using batch size  17, an average step would have taken 0.22389 = 0.00067 + 0.22322 seconds\n",
      "Using batch size  18, an average step would have taken 0.26874 = 0.00802 + 0.26072 seconds\n",
      "Using batch size  19, an average step would have taken 0.22885 = 0.00073 + 0.22812 seconds\n",
      "Using batch size  20, an average step would have taken 0.36986 = 0.00035 + 0.36950 seconds\n",
      "Using batch size  21, an average step would have taken 0.25404 = 0.00084 + 0.25319 seconds\n",
      "Using batch size  22, an average step would have taken 0.29727 = 0.00064 + 0.29663 seconds\n",
      "Using batch size  23, an average step would have taken 0.23244 = 0.00049 + 0.23195 seconds\n",
      "Using batch size  24, an average step would have taken 0.19782 = 0.00188 + 0.19594 seconds\n",
      "Using batch size  25, an average step would have taken 0.25873 = 0.00030 + 0.25843 seconds\n",
      "batch size was 25, optimal batch size would have been 24\n",
      "setting batch size to 24: expected step duration: 0.19782\n",
      "improvement compared to old batch size (25): 1.3x\n",
      "improvement compared to worst batch size (1): 4.5x\n",
      "improvement compared to smallest batch size (1): 4.5x\n",
      "improvement compared to largest batch size (25): 1.3x\n",
      "next batch size tuning in 200 steps, after step 600\n",
      "  Boundary too non-linear, decreasing steps: 0.17 (100), 0.27 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.18 (100), 0.30 (30)\n",
      "Step 500: 2.53944e-02, stepsizes = 1.2e-02/5.1e-04: d. reduced by 0.10% (2.6117e-05) (took 0.28973 seconds)\n",
      "  Success rate too high, increasing source step: 0.30 ( 96), 0.53 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.11 (100), 0.18 (11)\n",
      "  Boundary too non-linear, decreasing steps: 0.11 (100), 0.12 (25)\n",
      "Step 600: 2.48393e-02, stepsizes = 5.1e-03/3.4e-04:  (took 0.26621 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 323.12220\n",
      "   3.6% for generation (11.59532)\n",
      "   13.6% for spherical prediction (43.99251)\n",
      "   72.4% for prediction (233.85105)\n",
      "   0.1% for hyperparameter update (0.19168)\n",
      "   10.4% for the rest (33.49164)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.98494243e-03 1.29878521e-04 1.36057536e-04 1.03428960e-04\n",
      " 5.33008575e-05 5.96112675e-05 7.05427053e-05 5.46984375e-05\n",
      " 3.90005700e-05 4.76789474e-05 3.05688086e-05 6.86347485e-05\n",
      " 4.12308958e-05 4.78150893e-05 5.67139520e-05 1.85882673e-05\n",
      " 2.37131614e-05 4.29490466e-04 2.75957948e-05 1.03420019e-05\n",
      " 2.93714389e-05 1.88803870e-05 1.51794664e-05 1.27624615e-05\n",
      " 1.20219234e-05]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.04729938 0.02579688 0.02804977 0.02489193 0.02273439 0.01912259\n",
      " 0.01682576 0.01259852 0.01403215 0.01174186 0.01009572 0.01038138\n",
      " 0.01049701 0.01243431 0.01051983 0.01126348 0.00948429 0.01065676\n",
      " 0.00856411 0.01532085 0.00944899 0.01137929 0.00886216 0.00548191\n",
      " 0.01033736]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.625 0.035 0.02  0.04  0.03  0.035 0.035 0.01  0.015 0.02  0.015 0.03\n",
      " 0.005 0.    0.01  0.015 0.005 0.    0.    0.005 0.005 0.005 0.01  0.005\n",
      " 0.015 0.01 ]\n",
      "Using batch size   1, an average step would have taken 0.95163 = 0.05649 + 0.89514 seconds\n",
      "Using batch size   2, an average step would have taken 0.51132 = 0.00430 + 0.50702 seconds\n",
      "Using batch size   3, an average step would have taken 0.55703 = 0.00443 + 0.55260 seconds\n",
      "Using batch size   4, an average step would have taken 0.50334 = 0.00385 + 0.49950 seconds\n",
      "Using batch size   5, an average step would have taken 0.44892 = 0.00105 + 0.44787 seconds\n",
      "Using batch size   6, an average step would have taken 0.39965 = 0.00304 + 0.39662 seconds\n",
      "Using batch size   7, an average step would have taken 0.36158 = 0.00151 + 0.36007 seconds\n",
      "Using batch size   8, an average step would have taken 0.28095 = 0.00297 + 0.27797 seconds\n",
      "Using batch size   9, an average step would have taken 0.30331 = 0.00095 + 0.30236 seconds\n",
      "Using batch size  10, an average step would have taken 0.28207 = 0.00101 + 0.28106 seconds\n",
      "Using batch size  11, an average step would have taken 0.24642 = 0.00084 + 0.24557 seconds\n",
      "Using batch size  12, an average step would have taken 0.24636 = 0.00330 + 0.24306 seconds\n",
      "Using batch size  13, an average step would have taken 0.22603 = 0.00112 + 0.22491 seconds\n",
      "Using batch size  14, an average step would have taken 0.25272 = 0.00090 + 0.25182 seconds\n",
      "Using batch size  15, an average step would have taken 0.23941 = 0.00118 + 0.23823 seconds\n",
      "Using batch size  16, an average step would have taken 0.26663 = 0.00054 + 0.26609 seconds\n",
      "Using batch size  17, an average step would have taken 0.23047 = 0.00070 + 0.22977 seconds\n",
      "Using batch size  18, an average step would have taken 0.27998 = 0.00807 + 0.27191 seconds\n",
      "Using batch size  19, an average step would have taken 0.24093 = 0.00077 + 0.24016 seconds\n",
      "Using batch size  20, an average step would have taken 0.38296 = 0.00039 + 0.38258 seconds\n",
      "Using batch size  21, an average step would have taken 0.26553 = 0.00089 + 0.26464 seconds\n",
      "Using batch size  22, an average step would have taken 0.30614 = 0.00068 + 0.30546 seconds\n",
      "Using batch size  23, an average step would have taken 0.23788 = 0.00052 + 0.23737 seconds\n",
      "Using batch size  24, an average step would have taken 0.16380 = 0.00220 + 0.16160 seconds\n",
      "Using batch size  25, an average step would have taken 0.25873 = 0.00030 + 0.25843 seconds\n",
      "batch size was 24, optimal batch size would have been 24\n",
      "setting batch size to 24: expected step duration: 0.16380\n",
      "improvement compared to old batch size (24): 1.0x\n",
      "improvement compared to worst batch size (1): 5.8x\n",
      "improvement compared to smallest batch size (1): 5.8x\n",
      "improvement compared to largest batch size (25): 1.6x\n",
      "next batch size tuning in 400 steps, after step 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Success rate too low, decreasing source step:  0.21 ( 24), 0.13 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.16 (100), 0.16 (25)\n",
      "  Success rate too low, decreasing source step:  0.20 ( 25), 0.17 (30)\n",
      "Step 700: 2.42028e-02, stepsizes = 3.4e-03/1.0e-04: d. reduced by 0.02% (4.9136e-06) (took 0.33337 seconds)\n",
      "  Success rate too high, increasing source step: 0.46 (100), 0.53 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.14 (100), 0.15 (13)\n",
      "Step 800: 2.37960e-02, stepsizes = 2.3e-03/1.0e-04: d. reduced by 0.02% (4.8312e-06) (took 0.41077 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.27 (30)\n",
      "Step 900: 2.35334e-02, stepsizes = 1.5e-03/6.8e-05:  (took 0.38240 seconds)\n",
      "  Success rate too low, decreasing source step:  0.25 ( 97), 0.13 (30)\n",
      "Step 1000: 2.33546e-02, stepsizes = 1.5e-03/4.5e-05: d. reduced by 0.01% (2.1073e-06) (took 0.28056 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 430.80211\n",
      "   3.4% for generation (14.71553)\n",
      "   12.5% for spherical prediction (53.98532)\n",
      "   74.9% for prediction (322.46440)\n",
      "   0.1% for hyperparameter update (0.26651)\n",
      "   9.1% for the rest (39.37035)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.93579196e-03 1.29878521e-04 1.36057536e-04 1.03428960e-04\n",
      " 5.33008575e-05 5.96112675e-05 7.05427053e-05 5.46984375e-05\n",
      " 3.90005700e-05 4.76789474e-05 3.05688086e-05 6.86347485e-05\n",
      " 4.12308958e-05 4.78150893e-05 5.67139520e-05 1.85882673e-05\n",
      " 2.37131614e-05 4.29490466e-04 2.75957948e-05 1.03420019e-05\n",
      " 2.93714389e-05 1.88803870e-05 1.51794664e-05 1.25914082e-05\n",
      " 1.20219234e-05]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.04729938 0.02579688 0.02804977 0.02489193 0.02273439 0.01912259\n",
      " 0.01682576 0.01259852 0.01403215 0.01174186 0.01009572 0.01038138\n",
      " 0.01049701 0.01243431 0.01051983 0.01126348 0.00948429 0.01065676\n",
      " 0.00856411 0.01532085 0.00944899 0.01137929 0.00886216 0.0069111\n",
      " 0.01033736]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.3025 0.1325 0.06   0.0525 0.0375 0.0325 0.035  0.04   0.03   0.03\n",
      " 0.025  0.035  0.015  0.02   0.0225 0.025  0.0125 0.01   0.025  0.0175\n",
      " 0.005  0.015  0.0025 0.     0.01   0.0075]\n",
      "Using batch size   1, an average step would have taken 0.65808 = 0.03846 + 0.61962 seconds\n",
      "Using batch size   2, an average step would have taken 0.35781 = 0.00262 + 0.35518 seconds\n",
      "Using batch size   3, an average step would have taken 0.39777 = 0.00276 + 0.39502 seconds\n",
      "Using batch size   4, an average step would have taken 0.36601 = 0.00236 + 0.36365 seconds\n",
      "Using batch size   5, an average step would have taken 0.33669 = 0.00079 + 0.33590 seconds\n",
      "Using batch size   6, an average step would have taken 0.30158 = 0.00180 + 0.29978 seconds\n",
      "Using batch size   7, an average step would have taken 0.27382 = 0.00114 + 0.27268 seconds\n",
      "Using batch size   8, an average step would have taken 0.21549 = 0.00177 + 0.21372 seconds\n",
      "Using batch size   9, an average step would have taken 0.23887 = 0.00072 + 0.23815 seconds\n",
      "Using batch size  10, an average step would have taken 0.21824 = 0.00082 + 0.21743 seconds\n",
      "Using batch size  11, an average step would have taken 0.19303 = 0.00063 + 0.19240 seconds\n",
      "Using batch size  12, an average step would have taken 0.20054 = 0.00212 + 0.19841 seconds\n",
      "Using batch size  13, an average step would have taken 0.19405 = 0.00091 + 0.19314 seconds\n",
      "Using batch size  14, an average step would have taken 0.22293 = 0.00081 + 0.22211 seconds\n",
      "Using batch size  15, an average step would have taken 0.20669 = 0.00105 + 0.20565 seconds\n",
      "Using batch size  16, an average step would have taken 0.23054 = 0.00044 + 0.23010 seconds\n",
      "Using batch size  17, an average step would have taken 0.20061 = 0.00057 + 0.20004 seconds\n",
      "Using batch size  18, an average step would have taken 0.24213 = 0.00791 + 0.23422 seconds\n",
      "Using batch size  19, an average step would have taken 0.20266 = 0.00065 + 0.20202 seconds\n",
      "Using batch size  20, an average step would have taken 0.34508 = 0.00030 + 0.34478 seconds\n",
      "Using batch size  21, an average step would have taken 0.23129 = 0.00075 + 0.23054 seconds\n",
      "Using batch size  22, an average step would have taken 0.27782 = 0.00055 + 0.27727 seconds\n",
      "Using batch size  23, an average step would have taken 0.22077 = 0.00043 + 0.22034 seconds\n",
      "Using batch size  24, an average step would have taken 0.18174 = 0.00121 + 0.18053 seconds\n",
      "Using batch size  25, an average step would have taken 0.25873 = 0.00030 + 0.25843 seconds\n",
      "batch size was 24, optimal batch size would have been 24\n",
      "setting batch size to 24: expected step duration: 0.18174\n",
      "improvement compared to old batch size (24): 1.0x\n",
      "improvement compared to worst batch size (1): 3.6x\n",
      "improvement compared to smallest batch size (1): 3.6x\n",
      "improvement compared to largest batch size (25): 1.4x\n",
      "next batch size tuning in 800 steps, after step 1800\n",
      "  Success rate too high, increasing source step: 0.34 (100), 0.60 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.15 (100), 0.21 (14)\n",
      "Step 1100: 2.31825e-02, stepsizes = 1.0e-03/4.5e-05: d. reduced by 0.01% (2.0918e-06) (took 0.35229 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.18 (100), 0.37 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.18 (100), 0.30 (30)\n",
      "Step 1200: 2.31062e-02, stepsizes = 4.5e-04/2.0e-05:  (took 0.43812 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.09 (100), 0.13 (30)\n",
      "  Success rate too low, decreasing source step:  0.09 (100), 0.13 (30)\n",
      "Step 1300: 2.30580e-02, stepsizes = 3.0e-04/8.9e-06: d. reduced by 0.00% (4.1093e-07) (took 0.36111 seconds)\n",
      "  Success rate too high, increasing source step: 0.48 (100), 0.60 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.16 (100), 0.20 (20)\n",
      "Step 1400: 2.30166e-02, stepsizes = 2.0e-04/8.9e-06: d. reduced by 0.00% (4.1017e-07) (took 0.33863 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.18 (100), 0.23 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.15 (100), 0.23 (30)\n",
      "Step 1500: 2.29982e-02, stepsizes = 8.9e-05/4.0e-06: d. reduced by 0.00% (1.8206e-07) (took 0.29973 seconds)\n",
      "  Success rate too low, decreasing source step:  0.33 ( 49), 0.13 (30)\n",
      "  Success rate too high, increasing source step: 0.40 (100), 0.73 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.18 (100), 0.26 (27)\n",
      "Step 1600: 2.29855e-02, stepsizes = 5.9e-05/2.6e-06: d. reduced by 0.00% (1.2145e-07) (took 0.26701 seconds)\n",
      "  Success rate too low, decreasing source step:  0.27 ( 49), 0.17 (30)\n",
      "  Success rate too high, increasing source step: 0.35 (100), 0.67 (30)\n",
      "Step 1700: 2.29765e-02, stepsizes = 5.9e-05/2.6e-06: d. reduced by 0.00% (1.2155e-07) (took 0.29808 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.16 (100), 0.30 (30)\n",
      "  Success rate too low, decreasing source step:  0.46 ( 24), 0.13 (30)\n",
      "  Success rate too high, increasing source step: 0.38 (100), 0.67 (30)\n",
      "Step 1800: 2.29712e-02, stepsizes = 4.0e-05/1.8e-06: d. reduced by 0.00% (8.0880e-08) (took 0.30047 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 622.85436\n",
      "   3.3% for generation (20.81251)\n",
      "   11.5% for spherical prediction (71.52963)\n",
      "   76.8% for prediction (478.55165)\n",
      "   0.1% for hyperparameter update (0.48001)\n",
      "   8.3% for the rest (51.48055)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.86216541e-03 1.29878521e-04 1.36057536e-04 1.03428960e-04\n",
      " 5.33008575e-05 5.96112675e-05 7.05427053e-05 5.46984375e-05\n",
      " 3.90005700e-05 4.76789474e-05 3.05688086e-05 6.86347485e-05\n",
      " 4.12308958e-05 4.78150893e-05 5.67139520e-05 1.85882673e-05\n",
      " 2.37131614e-05 4.29490466e-04 2.75957948e-05 1.03420019e-05\n",
      " 2.93714389e-05 1.88803870e-05 1.51794664e-05 1.24448527e-05\n",
      " 1.20219234e-05]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.04729938 0.02579688 0.02804977 0.02489193 0.02273439 0.01912259\n",
      " 0.01682576 0.01259852 0.01403215 0.01174186 0.01009572 0.01038138\n",
      " 0.01049701 0.01243431 0.01051983 0.01126348 0.00948429 0.01065676\n",
      " 0.00856411 0.01532085 0.00944899 0.01137929 0.00886216 0.00703857\n",
      " 0.01033736]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.255   0.12625 0.0775  0.06875 0.05875 0.05875 0.03875 0.035   0.03375\n",
      " 0.03    0.02625 0.02625 0.0225  0.0175  0.02125 0.00625 0.01625 0.0125\n",
      " 0.00875 0.0125  0.00625 0.015   0.00625 0.00625 0.0025  0.01125]\n",
      "Using batch size   1, an average step would have taken 0.59084 = 0.03371 + 0.55713 seconds\n",
      "Using batch size   2, an average step would have taken 0.32260 = 0.00231 + 0.32029 seconds\n",
      "Using batch size   3, an average step would have taken 0.36152 = 0.00244 + 0.35908 seconds\n",
      "Using batch size   4, an average step would have taken 0.33342 = 0.00209 + 0.33133 seconds\n",
      "Using batch size   5, an average step would have taken 0.30820 = 0.00072 + 0.30748 seconds\n",
      "Using batch size   6, an average step would have taken 0.27620 = 0.00158 + 0.27462 seconds\n",
      "Using batch size   7, an average step would have taken 0.25225 = 0.00105 + 0.25120 seconds\n",
      "Using batch size   8, an average step would have taken 0.19948 = 0.00157 + 0.19792 seconds\n",
      "Using batch size   9, an average step would have taken 0.22373 = 0.00067 + 0.22306 seconds\n",
      "Using batch size  10, an average step would have taken 0.20426 = 0.00077 + 0.20349 seconds\n",
      "Using batch size  11, an average step would have taken 0.18143 = 0.00059 + 0.18084 seconds\n",
      "Using batch size  12, an average step would have taken 0.18860 = 0.00191 + 0.18669 seconds\n",
      "Using batch size  13, an average step would have taken 0.18465 = 0.00085 + 0.18380 seconds\n",
      "Using batch size  14, an average step would have taken 0.21471 = 0.00079 + 0.21392 seconds\n",
      "Using batch size  15, an average step would have taken 0.20021 = 0.00102 + 0.19919 seconds\n",
      "Using batch size  16, an average step would have taken 0.22310 = 0.00042 + 0.22268 seconds\n",
      "Using batch size  17, an average step would have taken 0.19441 = 0.00054 + 0.19386 seconds\n",
      "Using batch size  18, an average step would have taken 0.23681 = 0.00789 + 0.22892 seconds\n",
      "Using batch size  19, an average step would have taken 0.19806 = 0.00063 + 0.19743 seconds\n",
      "Using batch size  20, an average step would have taken 0.34038 = 0.00029 + 0.34009 seconds\n",
      "Using batch size  21, an average step would have taken 0.22717 = 0.00073 + 0.22643 seconds\n",
      "Using batch size  22, an average step would have taken 0.27401 = 0.00053 + 0.27349 seconds\n",
      "Using batch size  23, an average step would have taken 0.21811 = 0.00042 + 0.21770 seconds\n",
      "Using batch size  24, an average step would have taken 0.18258 = 0.00106 + 0.18152 seconds\n",
      "Using batch size  25, an average step would have taken 0.25873 = 0.00030 + 0.25843 seconds\n",
      "batch size was 24, optimal batch size would have been 11\n",
      "setting batch size to 11: expected step duration: 0.18143\n",
      "improvement compared to old batch size (24): 1.0x\n",
      "improvement compared to worst batch size (1): 3.3x\n",
      "improvement compared to smallest batch size (1): 3.3x\n",
      "improvement compared to largest batch size (25): 1.4x\n",
      "next batch size tuning in 400 steps, after step 2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Boundary too non-linear, decreasing steps: 0.18 (100), 0.17 (30)\n",
      "  Success rate too low, decreasing source step:  0.18 (100), 0.17 (30)\n",
      "Step 1900: 2.29668e-02, stepsizes = 2.6e-05/7.8e-07: d. reduced by 0.00% (3.6003e-08) (took 0.22091 seconds)\n",
      "  Success rate too high, increasing source step: 0.58 ( 55), 0.77 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.16 (100), 0.31 (13)\n",
      "Step 2000: 2.29647e-02, stepsizes = 1.8e-05/7.8e-07:  (took 0.39241 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.06 (100), 0.21 (19)\n",
      "  Boundary too non-linear, decreasing steps: 0.10 (100), 0.23 (30)\n",
      "Step 2100: 2.29639e-02, stepsizes = 7.8e-06/3.5e-07:  (took 0.47583 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.30 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.08 (100), 0.23 (30)\n",
      "Step 2200: 2.29633e-02, stepsizes = 3.5e-06/1.5e-07: d. reduced by 0.00% (7.1607e-09) (took 0.38019 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 721.17518\n",
      "   3.2% for generation (23.23654)\n",
      "   11.1% for spherical prediction (80.24999)\n",
      "   77.7% for prediction (560.36937)\n",
      "   0.1% for hyperparameter update (0.52399)\n",
      "   7.9% for the rest (56.79529)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.86216541e-03 1.29878521e-04 2.18274705e-04 1.03428960e-04\n",
      " 5.33008575e-05 5.96112675e-05 7.05427053e-05 5.46984375e-05\n",
      " 3.90005700e-05 4.76789474e-05 2.54000382e-05 6.86347485e-05\n",
      " 4.12308958e-05 4.78150893e-05 5.67139520e-05 1.85882673e-05\n",
      " 2.37131614e-05 4.29490466e-04 2.75957948e-05 1.03420019e-05\n",
      " 2.93714389e-05 1.88803870e-05 1.51794664e-05 1.24448527e-05\n",
      " 1.20219234e-05]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.04729938 0.02579688 0.02804977 0.02489193 0.02273439 0.01912259\n",
      " 0.01682576 0.01259852 0.01403215 0.01174186 0.00955229 0.01038138\n",
      " 0.01049701 0.01243431 0.01051983 0.01126348 0.00948429 0.01065676\n",
      " 0.00856411 0.01532085 0.00944899 0.01137929 0.00886216 0.00703857\n",
      " 0.01033736]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.4825 0.0975 0.0475 0.0525 0.0425 0.0275 0.03   0.025  0.01   0.0025\n",
      " 0.0125 0.01   0.025  0.0125 0.0075 0.01   0.02   0.0175 0.0075 0.01\n",
      " 0.01   0.0025 0.005  0.0125 0.0125 0.0075]\n",
      "Using batch size   1, an average step would have taken 0.81312 = 0.04640 + 0.76672 seconds\n",
      "Using batch size   2, an average step would have taken 0.43941 = 0.00348 + 0.43593 seconds\n",
      "Using batch size   3, an average step would have taken 0.48570 = 0.00496 + 0.48074 seconds\n",
      "Using batch size   4, an average step would have taken 0.43800 = 0.00311 + 0.43489 seconds\n",
      "Using batch size   5, an average step would have taken 0.39821 = 0.00093 + 0.39728 seconds\n",
      "Using batch size   6, an average step would have taken 0.35403 = 0.00243 + 0.35161 seconds\n",
      "Using batch size   7, an average step would have taken 0.32106 = 0.00134 + 0.31973 seconds\n",
      "Using batch size   8, an average step would have taken 0.25082 = 0.00238 + 0.24844 seconds\n",
      "Using batch size   9, an average step would have taken 0.27502 = 0.00085 + 0.27417 seconds\n",
      "Using batch size  10, an average step would have taken 0.25435 = 0.00093 + 0.25343 seconds\n",
      "Using batch size  11, an average step would have taken 0.21672 = 0.00080 + 0.21592 seconds\n",
      "Using batch size  12, an average step would have taken 0.22741 = 0.00273 + 0.22468 seconds\n",
      "Using batch size  13, an average step would have taken 0.21286 = 0.00103 + 0.21183 seconds\n",
      "Using batch size  14, an average step would have taken 0.23770 = 0.00084 + 0.23686 seconds\n",
      "Using batch size  15, an average step would have taken 0.22791 = 0.00113 + 0.22678 seconds\n",
      "Using batch size  16, an average step would have taken 0.25238 = 0.00050 + 0.25188 seconds\n",
      "Using batch size  17, an average step would have taken 0.21731 = 0.00064 + 0.21667 seconds\n",
      "Using batch size  18, an average step would have taken 0.26372 = 0.00800 + 0.25572 seconds\n",
      "Using batch size  19, an average step would have taken 0.22453 = 0.00071 + 0.22381 seconds\n",
      "Using batch size  20, an average step would have taken 0.36616 = 0.00035 + 0.36581 seconds\n",
      "Using batch size  21, an average step would have taken 0.25104 = 0.00083 + 0.25020 seconds\n",
      "Using batch size  22, an average step would have taken 0.29443 = 0.00075 + 0.29368 seconds\n",
      "Using batch size  23, an average step would have taken 0.23024 = 0.00048 + 0.22976 seconds\n",
      "Using batch size  24, an average step would have taken 0.19380 = 0.00170 + 0.19210 seconds\n",
      "Using batch size  25, an average step would have taken 0.25873 = 0.00030 + 0.25843 seconds\n",
      "batch size was 11, optimal batch size would have been 24\n",
      "setting batch size to 24: expected step duration: 0.19380\n",
      "improvement compared to old batch size (11): 1.1x\n",
      "improvement compared to worst batch size (1): 4.2x\n",
      "improvement compared to smallest batch size (1): 4.2x\n",
      "improvement compared to largest batch size (25): 1.3x\n",
      "next batch size tuning in 200 steps, after step 2400\n",
      "  Boundary too non-linear, decreasing steps: 0.10 (100), 0.17 (30)\n",
      "  Success rate too low, decreasing source step:  0.10 (100), 0.17 (30)\n",
      "Step 2230: 2.29633e-02, stepsizes = 2.3e-06/6.9e-08: \n",
      "Looks like attack has converged after 2231 steps for the first time. Resetting steps to be sure.\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), -1.00 ( 0)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.00 ( 1)\n",
      "Step 2300: 2.29633e-02, stepsizes = 1.0e-05/1.0e-05:  (took 0.33389 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.03 (100), 0.00 ( 4)\n",
      "  Boundary too non-linear, decreasing steps: 0.05 (100), 0.00 ( 9)\n",
      "  Boundary too non-linear, decreasing steps: 0.04 (100), 0.00 (13)\n",
      "  Boundary too non-linear, decreasing steps: 0.04 (100), 0.00 (17)\n",
      "  Boundary too non-linear, decreasing steps: 0.06 (100), 0.00 (23)\n",
      "  Success rate too low, decreasing source step:  0.11 ( 75), 0.00 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.10 (100), 0.00 ( 2)\n",
      "  Boundary too non-linear, decreasing steps: 0.16 (100), 0.00 (18)\n",
      "  Success rate too low, decreasing source step:  0.17 ( 75), 0.00 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.00 ( 6)\n",
      "  Success rate too low, decreasing source step:  0.28 (100), 0.00 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.10 (10)\n",
      "Step 2337: 2.29633e-02, stepsizes = 2.6e-07/7.8e-08: \n",
      "Looks like attack has converged after 2338 steps, 100 remaining\n",
      "Step 2338: 2.29633e-02, stepsizes = 2.6e-07/7.8e-08: \n",
      "Looks like attack has converged after 2339 steps, 99 remaining\n",
      "Step 2339: 2.29633e-02, stepsizes = 2.6e-07/7.8e-08: \n",
      "Looks like attack has converged after 2340 steps, 98 remaining\n",
      "Step 2340: 2.29633e-02, stepsizes = 2.6e-07/7.8e-08: \n",
      "Looks like attack has converged after 2341 steps, 97 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.03 (100), 0.08 (13)\n",
      "Step 2341: 2.29633e-02, stepsizes = 1.8e-07/5.2e-08: \n",
      "Looks like attack has converged after 2342 steps, 96 remaining\n",
      "Step 2342: 2.29633e-02, stepsizes = 1.8e-07/5.2e-08: \n",
      "Looks like attack has converged after 2343 steps, 95 remaining\n",
      "Step 2343: 2.29633e-02, stepsizes = 1.8e-07/5.2e-08: \n",
      "Looks like attack has converged after 2344 steps, 94 remaining\n",
      "Step 2344: 2.29633e-02, stepsizes = 1.8e-07/5.2e-08: \n",
      "Looks like attack has converged after 2345 steps, 93 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2345: 2.29633e-02, stepsizes = 1.8e-07/5.2e-08: \n",
      "Looks like attack has converged after 2346 steps, 92 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.04 (100), 0.11 (19)\n",
      "Step 2346: 2.29633e-02, stepsizes = 1.2e-07/3.5e-08: \n",
      "Looks like attack has converged after 2347 steps, 91 remaining\n",
      "Step 2347: 2.29633e-02, stepsizes = 1.2e-07/3.5e-08: \n",
      "Looks like attack has converged after 2348 steps, 90 remaining\n",
      "Step 2348: 2.29633e-02, stepsizes = 1.2e-07/3.5e-08: \n",
      "Looks like attack has converged after 2349 steps, 89 remaining\n",
      "Step 2349: 2.29633e-02, stepsizes = 1.2e-07/3.5e-08: \n",
      "Looks like attack has converged after 2350 steps, 88 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.04 (100), 0.09 (23)\n",
      "Step 2350: 2.29633e-02, stepsizes = 7.8e-08/2.3e-08: \n",
      "Looks like attack has converged after 2351 steps, 87 remaining\n",
      "Step 2351: 2.29633e-02, stepsizes = 7.8e-08/2.3e-08: \n",
      "Looks like attack has converged after 2352 steps, 86 remaining\n",
      "Step 2352: 2.29633e-02, stepsizes = 7.8e-08/2.3e-08: \n",
      "Looks like attack has converged after 2353 steps, 85 remaining\n",
      "Step 2353: 2.29633e-02, stepsizes = 7.8e-08/2.3e-08: \n",
      "Looks like attack has converged after 2354 steps, 84 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.08 (24)\n",
      "Step 2354: 2.29633e-02, stepsizes = 5.2e-08/1.5e-08: \n",
      "Looks like attack has converged after 2355 steps, 83 remaining\n",
      "Step 2355: 2.29633e-02, stepsizes = 5.2e-08/1.5e-08: \n",
      "Looks like attack has converged after 2356 steps, 82 remaining\n",
      "Step 2356: 2.29633e-02, stepsizes = 5.2e-08/1.5e-08: \n",
      "Looks like attack has converged after 2357 steps, 81 remaining\n",
      "Step 2357: 2.29633e-02, stepsizes = 5.2e-08/1.5e-08: \n",
      "Looks like attack has converged after 2358 steps, 80 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.08 (24)\n",
      "Step 2358: 2.29633e-02, stepsizes = 3.5e-08/1.0e-08: \n",
      "Looks like attack has converged after 2359 steps, 79 remaining\n",
      "Step 2359: 2.29633e-02, stepsizes = 3.5e-08/1.0e-08: \n",
      "Looks like attack has converged after 2360 steps, 78 remaining\n",
      "Step 2360: 2.29633e-02, stepsizes = 3.5e-08/1.0e-08: \n",
      "Looks like attack has converged after 2361 steps, 77 remaining\n",
      "Step 2361: 2.29633e-02, stepsizes = 3.5e-08/1.0e-08: \n",
      "Looks like attack has converged after 2362 steps, 76 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.02 (100), 0.12 (26)\n",
      "Step 2362: 2.29633e-02, stepsizes = 2.3e-08/6.9e-09: \n",
      "Looks like attack has converged after 2363 steps, 75 remaining\n",
      "Step 2363: 2.29633e-02, stepsizes = 2.3e-08/6.9e-09: \n",
      "Looks like attack has converged after 2364 steps, 74 remaining\n",
      "Step 2364: 2.29633e-02, stepsizes = 2.3e-08/6.9e-09: \n",
      "Looks like attack has converged after 2365 steps, 73 remaining\n",
      "Step 2365: 2.29633e-02, stepsizes = 2.3e-08/6.9e-09: \n",
      "Looks like attack has converged after 2366 steps, 72 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.12 (26)\n",
      "Step 2366: 2.29633e-02, stepsizes = 1.5e-08/4.6e-09: \n",
      "Looks like attack has converged after 2367 steps, 71 remaining\n",
      "Step 2367: 2.29633e-02, stepsizes = 1.5e-08/4.6e-09: \n",
      "Looks like attack has converged after 2368 steps, 70 remaining\n",
      "Step 2368: 2.29633e-02, stepsizes = 1.5e-08/4.6e-09: \n",
      "Looks like attack has converged after 2369 steps, 69 remaining\n",
      "Step 2369: 2.29633e-02, stepsizes = 1.5e-08/4.6e-09: \n",
      "Looks like attack has converged after 2370 steps, 68 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.03 (100), 0.14 (29)\n",
      "Step 2370: 2.29633e-02, stepsizes = 1.0e-08/3.1e-09: \n",
      "Looks like attack has converged after 2371 steps, 67 remaining\n",
      "Step 2371: 2.29633e-02, stepsizes = 1.0e-08/3.1e-09: \n",
      "Looks like attack has converged after 2372 steps, 66 remaining\n",
      "Step 2372: 2.29633e-02, stepsizes = 1.0e-08/3.1e-09: \n",
      "Looks like attack has converged after 2373 steps, 65 remaining\n",
      "Step 2373: 2.29633e-02, stepsizes = 1.0e-08/3.1e-09: \n",
      "Looks like attack has converged after 2374 steps, 64 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.14 (29)\n",
      "Step 2374: 2.29633e-02, stepsizes = 6.9e-09/2.0e-09: \n",
      "Looks like attack has converged after 2375 steps, 63 remaining\n",
      "Step 2375: 2.29633e-02, stepsizes = 6.9e-09/2.0e-09: \n",
      "Looks like attack has converged after 2376 steps, 62 remaining\n",
      "Step 2376: 2.29633e-02, stepsizes = 6.9e-09/2.0e-09: \n",
      "Looks like attack has converged after 2377 steps, 61 remaining\n",
      "  Success rate too low, decreasing source step:  0.01 ( 75), 0.17 (30)\n",
      "Step 2377: 2.29633e-02, stepsizes = 6.9e-09/1.4e-09: \n",
      "Looks like attack has converged after 2378 steps, 60 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.02 (100), 1.00 ( 1)\n",
      "Step 2378: 2.29633e-02, stepsizes = 4.6e-09/9.0e-10: \n",
      "Looks like attack has converged after 2379 steps, 59 remaining\n",
      "Step 2379: 2.29633e-02, stepsizes = 4.6e-09/9.0e-10: \n",
      "Looks like attack has converged after 2380 steps, 58 remaining\n",
      "Step 2380: 2.29633e-02, stepsizes = 4.6e-09/9.0e-10: \n",
      "Looks like attack has converged after 2381 steps, 57 remaining\n",
      "Step 2381: 2.29633e-02, stepsizes = 4.6e-09/9.0e-10: \n",
      "Looks like attack has converged after 2382 steps, 56 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.04 (100), 1.00 ( 5)\n",
      "Step 2382: 2.29633e-02, stepsizes = 3.1e-09/6.0e-10: \n",
      "Looks like attack has converged after 2383 steps, 55 remaining\n",
      "Step 2383: 2.29633e-02, stepsizes = 3.1e-09/6.0e-10: \n",
      "Looks like attack has converged after 2384 steps, 54 remaining\n",
      "Step 2384: 2.29633e-02, stepsizes = 3.1e-09/6.0e-10: \n",
      "Looks like attack has converged after 2385 steps, 53 remaining\n",
      "Step 2385: 2.29633e-02, stepsizes = 3.1e-09/6.0e-10: \n",
      "Looks like attack has converged after 2386 steps, 52 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.03 (100), 1.00 ( 8)\n",
      "Step 2386: 2.29633e-02, stepsizes = 2.0e-09/4.0e-10: \n",
      "Looks like attack has converged after 2387 steps, 51 remaining\n",
      "Step 2387: 2.29633e-02, stepsizes = 2.0e-09/4.0e-10: \n",
      "Looks like attack has converged after 2388 steps, 50 remaining\n",
      "Step 2388: 2.29633e-02, stepsizes = 2.0e-09/4.0e-10: \n",
      "Looks like attack has converged after 2389 steps, 49 remaining\n",
      "Step 2389: 2.29633e-02, stepsizes = 2.0e-09/4.0e-10: \n",
      "Looks like attack has converged after 2390 steps, 48 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.03 (100), 1.00 (11)\n",
      "Step 2390: 2.29633e-02, stepsizes = 1.4e-09/2.7e-10: \n",
      "Looks like attack has converged after 2391 steps, 47 remaining\n",
      "Step 2391: 2.29633e-02, stepsizes = 1.4e-09/2.7e-10: \n",
      "Looks like attack has converged after 2392 steps, 46 remaining\n",
      "Step 2392: 2.29633e-02, stepsizes = 1.4e-09/2.7e-10: \n",
      "Looks like attack has converged after 2393 steps, 45 remaining\n",
      "Step 2393: 2.29633e-02, stepsizes = 1.4e-09/2.7e-10: \n",
      "Looks like attack has converged after 2394 steps, 44 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 1.00 (12)\n",
      "Step 2394: 2.29633e-02, stepsizes = 9.0e-10/1.8e-10: \n",
      "Looks like attack has converged after 2395 steps, 43 remaining\n",
      "Step 2395: 2.29633e-02, stepsizes = 9.0e-10/1.8e-10: \n",
      "Looks like attack has converged after 2396 steps, 42 remaining\n",
      "Step 2396: 2.29633e-02, stepsizes = 9.0e-10/1.8e-10: \n",
      "Looks like attack has converged after 2397 steps, 41 remaining\n",
      "Step 2397: 2.29633e-02, stepsizes = 9.0e-10/1.8e-10: \n",
      "Looks like attack has converged after 2398 steps, 40 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.03 (100), 0.93 (15)\n",
      "Step 2398: 2.29633e-02, stepsizes = 6.0e-10/1.2e-10: \n",
      "Looks like attack has converged after 2399 steps, 39 remaining\n",
      "Step 2399: 2.29633e-02, stepsizes = 6.0e-10/1.2e-10: \n",
      "Looks like attack has converged after 2400 steps, 38 remaining\n",
      "Step 2400: 2.29633e-02, stepsizes = 6.0e-10/1.2e-10:  (took 0.33663 seconds)\n",
      "Step 2400: 2.29633e-02, stepsizes = 6.0e-10/1.2e-10: \n",
      "Looks like attack has converged after 2401 steps, 37 remaining\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 778.44289\n",
      "   3.2% for generation (24.84509)\n",
      "   15.5% for spherical prediction (120.68313)\n",
      "   72.9% for prediction (567.55184)\n",
      "   0.1% for hyperparameter update (0.76665)\n",
      "   8.3% for the rest (64.59618)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.71331939e-03 1.29878521e-04 2.18274705e-04 1.03428960e-04\n",
      " 5.33008575e-05 5.96112675e-05 7.05427053e-05 5.46984375e-05\n",
      " 3.90005700e-05 4.76789474e-05 2.54000382e-05 6.86347485e-05\n",
      " 4.12308958e-05 4.78150893e-05 5.67139520e-05 1.85882673e-05\n",
      " 2.37131614e-05 4.29490466e-04 2.75957948e-05 1.03420019e-05\n",
      " 2.93714389e-05 1.88803870e-05 1.51794664e-05 1.25171220e-05\n",
      " 1.20219234e-05]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.04729938 0.02579688 0.02804977 0.02489193 0.02273439 0.01912259\n",
      " 0.01682576 0.01259852 0.01403215 0.01174186 0.00955229 0.01038138\n",
      " 0.01049701 0.01243431 0.01051983 0.01126348 0.00948429 0.01065676\n",
      " 0.00856411 0.01532085 0.00944899 0.01137929 0.00886216 0.00699204\n",
      " 0.01033736]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.89  0.    0.    0.    0.    0.    0.    0.    0.    0.005 0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.005 0.    0.    0.    0.\n",
      " 0.    0.1  ]\n",
      "Using batch size   1, an average step would have taken 1.24482 = 0.06753 + 1.17728 seconds\n",
      "Using batch size   2, an average step would have taken 0.66942 = 0.00579 + 0.66363 seconds\n",
      "Using batch size   3, an average step would have taken 0.72540 = 0.00791 + 0.71750 seconds\n",
      "Using batch size   4, an average step would have taken 0.64740 = 0.00516 + 0.64224 seconds\n",
      "Using batch size   5, an average step would have taken 0.56741 = 0.00133 + 0.56609 seconds\n",
      "Using batch size   6, an average step would have taken 0.50873 = 0.00411 + 0.50462 seconds\n",
      "Using batch size   7, an average step would have taken 0.45321 = 0.00189 + 0.45132 seconds\n",
      "Using batch size   8, an average step would have taken 0.35268 = 0.00400 + 0.34869 seconds\n",
      "Using batch size   9, an average step would have taken 0.37033 = 0.00119 + 0.36914 seconds\n",
      "Using batch size  10, an average step would have taken 0.34800 = 0.00122 + 0.34679 seconds\n",
      "Using batch size  11, an average step would have taken 0.29414 = 0.00121 + 0.29293 seconds\n",
      "Using batch size  12, an average step would have taken 0.29969 = 0.00433 + 0.29536 seconds\n",
      "Using batch size  13, an average step would have taken 0.26177 = 0.00136 + 0.26041 seconds\n",
      "Using batch size  14, an average step would have taken 0.27958 = 0.00095 + 0.27863 seconds\n",
      "Using batch size  15, an average step would have taken 0.27595 = 0.00133 + 0.27463 seconds\n",
      "Using batch size  16, an average step would have taken 0.30652 = 0.00065 + 0.30587 seconds\n",
      "Using batch size  17, an average step would have taken 0.26236 = 0.00084 + 0.26152 seconds\n",
      "Using batch size  18, an average step would have taken 0.31724 = 0.00822 + 0.30901 seconds\n",
      "Using batch size  19, an average step would have taken 0.27718 = 0.00088 + 0.27631 seconds\n",
      "Using batch size  20, an average step would have taken 0.41942 = 0.00047 + 0.41895 seconds\n",
      "Using batch size  21, an average step would have taken 0.29803 = 0.00103 + 0.29700 seconds\n",
      "Using batch size  22, an average step would have taken 0.33472 = 0.00106 + 0.33365 seconds\n",
      "Using batch size  23, an average step would have taken 0.25551 = 0.00061 + 0.25491 seconds\n",
      "Using batch size  24, an average step would have taken 0.21762 = 0.00299 + 0.21464 seconds\n",
      "Using batch size  25, an average step would have taken 0.25873 = 0.00030 + 0.25843 seconds\n",
      "batch size was 24, optimal batch size would have been 24\n",
      "setting batch size to 24: expected step duration: 0.21762\n",
      "improvement compared to old batch size (24): 1.0x\n",
      "improvement compared to worst batch size (1): 5.7x\n",
      "improvement compared to smallest batch size (1): 5.7x\n",
      "improvement compared to largest batch size (25): 1.2x\n",
      "next batch size tuning in 400 steps, after step 2800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2401: 2.29633e-02, stepsizes = 6.0e-10/1.2e-10: \n",
      "Looks like attack has converged after 2402 steps, 36 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.03 (100), 0.89 (18)\n",
      "Step 2402: 2.29633e-02, stepsizes = 4.0e-10/7.9e-11: \n",
      "Looks like attack has converged after 2403 steps, 35 remaining\n",
      "Step 2403: 2.29633e-02, stepsizes = 4.0e-10/7.9e-11: \n",
      "Looks like attack has converged after 2404 steps, 34 remaining\n",
      "Step 2404: 2.29633e-02, stepsizes = 4.0e-10/7.9e-11: \n",
      "Looks like attack has converged after 2405 steps, 33 remaining\n",
      "Step 2405: 2.29633e-02, stepsizes = 4.0e-10/7.9e-11: \n",
      "Looks like attack has converged after 2406 steps, 32 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.03 (100), 0.81 (21)\n",
      "Step 2406: 2.29633e-02, stepsizes = 2.7e-10/5.3e-11: \n",
      "Looks like attack has converged after 2407 steps, 31 remaining\n",
      "Step 2407: 2.29633e-02, stepsizes = 2.7e-10/5.3e-11: \n",
      "Looks like attack has converged after 2408 steps, 30 remaining\n",
      "Step 2408: 2.29633e-02, stepsizes = 2.7e-10/5.3e-11: \n",
      "Looks like attack has converged after 2409 steps, 29 remaining\n",
      "Step 2409: 2.29633e-02, stepsizes = 2.7e-10/5.3e-11: \n",
      "Looks like attack has converged after 2410 steps, 28 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.02 (100), 0.78 (23)\n",
      "Step 2410: 2.29633e-02, stepsizes = 1.8e-10/3.5e-11: \n",
      "Looks like attack has converged after 2411 steps, 27 remaining\n",
      "Step 2411: 2.29633e-02, stepsizes = 1.8e-10/3.5e-11: \n",
      "Looks like attack has converged after 2412 steps, 26 remaining\n",
      "Step 2412: 2.29633e-02, stepsizes = 1.8e-10/3.5e-11: \n",
      "Looks like attack has converged after 2413 steps, 25 remaining\n",
      "Step 2413: 2.29633e-02, stepsizes = 1.8e-10/3.5e-11: \n",
      "Looks like attack has converged after 2414 steps, 24 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.03 (100), 0.81 (26)\n",
      "Step 2414: 2.29633e-02, stepsizes = 1.2e-10/2.4e-11: \n",
      "Looks like attack has converged after 2415 steps, 23 remaining\n",
      "Step 2415: 2.29633e-02, stepsizes = 1.2e-10/2.4e-11: \n",
      "Looks like attack has converged after 2416 steps, 22 remaining\n",
      "Step 2416: 2.29633e-02, stepsizes = 1.2e-10/2.4e-11: \n",
      "Looks like attack has converged after 2417 steps, 21 remaining\n",
      "Step 2417: 2.29633e-02, stepsizes = 1.2e-10/2.4e-11: \n",
      "Looks like attack has converged after 2418 steps, 20 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.04 (100), 0.80 (30)\n",
      "  Success rate too high, increasing source step: 0.04 (100), 0.80 (30)\n",
      "Step 2418: 2.29633e-02, stepsizes = 7.9e-11/2.4e-11: \n",
      "Looks like attack has converged after 2419 steps, 19 remaining\n",
      "Step 2419: 2.29633e-02, stepsizes = 7.9e-11/2.4e-11: \n",
      "Looks like attack has converged after 2420 steps, 18 remaining\n",
      "Step 2420: 2.29633e-02, stepsizes = 7.9e-11/2.4e-11: \n",
      "Looks like attack has converged after 2421 steps, 17 remaining\n",
      "Step 2421: 2.29633e-02, stepsizes = 7.9e-11/2.4e-11: \n",
      "Looks like attack has converged after 2422 steps, 16 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.00 ( 1)\n",
      "Step 2422: 2.29633e-02, stepsizes = 5.3e-11/1.6e-11: \n",
      "Looks like attack has converged after 2423 steps, 15 remaining\n",
      "Step 2423: 2.29633e-02, stepsizes = 5.3e-11/1.6e-11: \n",
      "Looks like attack has converged after 2424 steps, 14 remaining\n",
      "Step 2424: 2.29633e-02, stepsizes = 5.3e-11/1.6e-11: \n",
      "Looks like attack has converged after 2425 steps, 13 remaining\n",
      "Step 2425: 2.29633e-02, stepsizes = 5.3e-11/1.6e-11: \n",
      "Looks like attack has converged after 2426 steps, 12 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.03 (100), 0.00 ( 4)\n",
      "Step 2426: 2.29633e-02, stepsizes = 3.5e-11/1.0e-11: \n",
      "Looks like attack has converged after 2427 steps, 11 remaining\n",
      "Step 2427: 2.29633e-02, stepsizes = 3.5e-11/1.0e-11: \n",
      "Looks like attack has converged after 2428 steps, 10 remaining\n",
      "Step 2428: 2.29633e-02, stepsizes = 3.5e-11/1.0e-11: \n",
      "Looks like attack has converged after 2429 steps, 9 remaining\n",
      "Step 2429: 2.29633e-02, stepsizes = 3.5e-11/1.0e-11: \n",
      "Looks like attack has converged after 2430 steps, 8 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.02 (100), 0.00 ( 6)\n",
      "Step 2430: 2.29633e-02, stepsizes = 2.4e-11/7.0e-12: \n",
      "Looks like attack has converged after 2431 steps, 7 remaining\n",
      "Step 2431: 2.29633e-02, stepsizes = 2.4e-11/7.0e-12: \n",
      "Looks like attack has converged after 2432 steps, 6 remaining\n",
      "Step 2432: 2.29633e-02, stepsizes = 2.4e-11/7.0e-12: \n",
      "Looks like attack has converged after 2433 steps, 5 remaining\n",
      "Step 2433: 2.29633e-02, stepsizes = 2.4e-11/7.0e-12: \n",
      "Looks like attack has converged after 2434 steps, 4 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.04 (100), 0.20 (10)\n",
      "Step 2434: 2.29633e-02, stepsizes = 1.6e-11/4.6e-12: \n",
      "Looks like attack has converged after 2435 steps, 3 remaining\n",
      "Step 2435: 2.29633e-02, stepsizes = 1.6e-11/4.6e-12: \n",
      "Looks like attack has converged after 2436 steps, 2 remaining\n",
      "Step 2436: 2.29633e-02, stepsizes = 1.6e-11/4.6e-12: \n",
      "Looks like attack has converged after 2437 steps, 1 remaining\n",
      "Time since beginning: 789.26418\n",
      "   3.2% for generation (25.12043)\n",
      "   16.4% for spherical prediction (129.65783)\n",
      "   71.9% for prediction (567.55184)\n",
      "   0.1% for hyperparameter update (0.81483)\n",
      "   8.4% for the rest (66.11925)\n"
     ]
    }
   ],
   "source": [
    "attack_params = {\n",
    "    'iterations': 10000,\n",
    "    'max_directions': 25,\n",
    "    'starting_point': None,\n",
    "    'initialization_attack': None,\n",
    "    'log_every_n_steps': 100,\n",
    "    'spherical_step': 1.0,\n",
    "    'source_step': 0.1,\n",
    "    'step_adaptation': 1.5,\n",
    "    'batch_size': 1,\n",
    "    'tune_batch_size': True, \n",
    "    'threaded_rnd': True, \n",
    "    'threaded_gen': True, \n",
    "    'alternative_generator': False\n",
    "}\n",
    "\n",
    "num = 1\n",
    "x_adv = np.zeros_like(x_test[:num].numpy())\n",
    "for i in range(num):\n",
    "    x_adv[i] = attack(x_test[i].numpy(), label=y_test[i].numpy(), \n",
    "                      unpack=True, verbose=True, **attack_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.classify(torch.tensor(x_adv))\n",
    "print((y_pred.argmax(1) == y_test[:num].numpy()).sum() / num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2430224\n"
     ]
    }
   ],
   "source": [
    "dist = np.sqrt(np.sum((x_adv - x_test[:num].numpy())**2, (1, 2, 3)))\n",
    "print(dist.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f269e0a7128>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_adv[0].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmodel = foolbox.models.PyTorchModel(\n",
    "    net, bounds=(0, 1), num_classes=10, preprocessing=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from foolbox.criteria import Misclassification\n",
    "from foolbox.distances import MeanSquaredDistance, Linfinity \n",
    "\n",
    "criterion = Misclassification()\n",
    "distance = MeanSquaredDistance\n",
    "# distance = Linfinity\n",
    "\n",
    "attack = foolbox.attacks.BoundaryAttack(\n",
    "    model=fmodel, criterion=criterion, distance=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run with verbose=True to see details\n",
      "Step 0: 1.70851e-01, stepsizes = 1.0e+00/1.0e-01: \n",
      "Step 100: 5.18938e-02, stepsizes = 4.4e-01/4.4e-02:  (took 0.10067 seconds)\n",
      "Step 200: 2.04484e-02, stepsizes = 2.0e-01/2.0e-02:  (took 0.00762 seconds)\n",
      "Step 300: 1.32653e-02, stepsizes = 5.9e-02/3.9e-03:  (took 0.00827 seconds)\n",
      "Step 400: 8.66029e-03, stepsizes = 3.9e-02/1.7e-03: d. reduced by 0.35% (3.0115e-05) (took 0.01879 seconds)\n",
      "Step 500: 6.75292e-03, stepsizes = 2.6e-02/1.2e-03: d. reduced by 0.23% (1.5641e-05) (took 0.01096 seconds)\n",
      "Step 600: 5.75658e-03, stepsizes = 2.6e-02/7.7e-04: d. reduced by 0.15% (8.8838e-06) (took 0.00927 seconds)\n",
      "Step 700: 5.09897e-03, stepsizes = 1.7e-02/5.1e-04: d. reduced by 0.10% (5.2439e-06) (took 0.01148 seconds)\n",
      "Step 800: 4.72065e-03, stepsizes = 1.2e-02/3.4e-04:  (took 0.01006 seconds)\n",
      "Step 900: 4.54329e-03, stepsizes = 1.2e-02/3.4e-04: d. reduced by 0.07% (3.1142e-06) (took 0.00837 seconds)\n",
      "Step 1000: 4.32558e-03, stepsizes = 7.7e-03/2.3e-04: d. reduced by 0.05% (1.9763e-06) (took 0.01291 seconds)\n",
      "Step 1100: 4.21569e-03, stepsizes = 5.1e-03/1.0e-04:  (took 0.00902 seconds)\n",
      "Step 1200: 4.13182e-03, stepsizes = 5.1e-03/1.5e-04: d. reduced by 0.03% (1.2584e-06) (took 0.01217 seconds)\n",
      "Step 1300: 4.07072e-03, stepsizes = 3.4e-03/4.5e-05: d. reduced by 0.01% (3.6725e-07) (took 0.00956 seconds)\n",
      "Step 1400: 4.01899e-03, stepsizes = 3.4e-03/1.0e-04:  (took 0.00899 seconds)\n",
      "Step 1500: 3.97508e-03, stepsizes = 2.3e-03/4.5e-05: d. reduced by 0.01% (3.5860e-07) (took 0.01129 seconds)\n",
      "Step 1600: 3.94685e-03, stepsizes = 1.5e-03/4.5e-05:  (took 0.00817 seconds)\n",
      "Step 1700: 3.93393e-03, stepsizes = 1.0e-03/3.0e-05:  (took 0.01206 seconds)\n",
      "Step 1800: 3.92884e-03, stepsizes = 3.0e-04/8.9e-06:  (took 0.00735 seconds)\n",
      "Step 1900: 3.92788e-03, stepsizes = 1.3e-04/2.6e-06:  (took 0.01028 seconds)\n",
      "Step 2000: 3.92788e-03, stepsizes = 4.0e-05/7.8e-07:  (took 0.00795 seconds)\n"
     ]
    }
   ],
   "source": [
    "attack_params = {\n",
    "    'iterations': 2000,\n",
    "    'max_directions': 25,\n",
    "    'starting_point': None,\n",
    "    'initialization_attack': None,\n",
    "    'log_every_n_steps': 100,\n",
    "    'spherical_step': 1.0,\n",
    "    'source_step': 0.1,\n",
    "    'step_adaptation': 1.5,\n",
    "    'batch_size': 1,\n",
    "    'tune_batch_size': True, \n",
    "    'threaded_rnd': True, \n",
    "    'threaded_gen': True, \n",
    "    'alternative_generator': False\n",
    "}\n",
    "\n",
    "num = 1\n",
    "x_adv = np.zeros_like(x_test[:num].numpy())\n",
    "for i in range(num):\n",
    "    x_adv[i] = attack(x_test[i].numpy(), label=y_test[i].numpy(), \n",
    "                      unpack=True, verbose=False, **attack_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "y_pred = net(torch.tensor(x_adv).cuda())\n",
    "print((y_pred.argmax(1).cpu().detach() == y_test[:num]).sum() / num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7548374\n"
     ]
    }
   ],
   "source": [
    "dist = np.sqrt(np.sum((x_adv - x_test[:num].numpy())**2, (1, 2, 3)))\n",
    "print(dist.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f269e09d2b0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_adv[0].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Misclassification()\n",
    "distance = MeanSquaredDistance\n",
    "# distance = Linfinity\n",
    "\n",
    "attack = foolbox.attacks.LBFGSAttack(approximate_gradient=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num = 1\n",
    "x_adv = np.zeros_like(x_test[:num].numpy())\n",
    "for i in range(num):\n",
    "#     adv = foolbox.adversarial.Adversarial(\n",
    "#         fmodel, criterion, x_test[i].numpy(), y_test[i].numpy(), \n",
    "#         distance=distance, verbose=True)\n",
    "    adv = foolbox.adversarial.Adversarial(\n",
    "        dknn_fb, criterion, x_test[i].numpy(), y_test[i].numpy(), \n",
    "        distance=distance, verbose=True)\n",
    "    x_adv[i] = attack(adv, unpack=True, epsilon=1e-05, num_random_targets=0, maxiter=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "y_pred = net(torch.tensor(x_adv).cuda())\n",
    "print((y_pred.argmax(1).cpu().detach() == y_test[:num]).sum() / num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "dist = np.sqrt(np.sum((x_adv - x_test[:num].numpy())**2, (1, 2, 3)))\n",
    "print(dist.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2694020d68>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/image.py:395: UserWarning: Warning: converting a masked element to nan.\n",
      "  dv = (np.float64(self.norm.vmax) -\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/image.py:396: UserWarning: Warning: converting a masked element to nan.\n",
      "  np.float64(self.norm.vmin))\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/image.py:403: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_min = np.float64(newmin)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/image.py:408: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_max = np.float64(newmax)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/colors.py:918: UserWarning: Warning: converting a masked element to nan.\n",
      "  dtype = np.min_scalar_type(value)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/numpy/ma/core.py:713: UserWarning: Warning: converting a masked element to nan.\n",
      "  data = np.array(a, copy=False, subok=subok)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/colors.py:918: UserWarning: Warning: converting a masked element to nan.\n",
      "  dtype = np.min_scalar_type(value)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/numpy/ma/core.py:713: UserWarning: Warning: converting a masked element to nan.\n",
      "  data = np.array(a, copy=False, subok=subok)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/image.py:395: UserWarning: Warning: converting a masked element to nan.\n",
      "  dv = (np.float64(self.norm.vmax) -\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/image.py:396: UserWarning: Warning: converting a masked element to nan.\n",
      "  np.float64(self.norm.vmin))\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/image.py:403: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_min = np.float64(newmin)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/image.py:408: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_max = np.float64(newmax)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/colors.py:918: UserWarning: Warning: converting a masked element to nan.\n",
      "  dtype = np.min_scalar_type(value)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/numpy/ma/core.py:713: UserWarning: Warning: converting a masked element to nan.\n",
      "  data = np.array(a, copy=False, subok=subok)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/colors.py:918: UserWarning: Warning: converting a masked element to nan.\n",
      "  dtype = np.min_scalar_type(value)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/numpy/ma/core.py:713: UserWarning: Warning: converting a masked element to nan.\n",
      "  data = np.array(a, copy=False, subok=subok)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/image.py:395: UserWarning: Warning: converting a masked element to nan.\n",
      "  dv = (np.float64(self.norm.vmax) -\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/image.py:396: UserWarning: Warning: converting a masked element to nan.\n",
      "  np.float64(self.norm.vmin))\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/image.py:403: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_min = np.float64(newmin)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/image.py:408: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_max = np.float64(newmax)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/colors.py:918: UserWarning: Warning: converting a masked element to nan.\n",
      "  dtype = np.min_scalar_type(value)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/numpy/ma/core.py:713: UserWarning: Warning: converting a masked element to nan.\n",
      "  data = np.array(a, copy=False, subok=subok)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/colors.py:918: UserWarning: Warning: converting a masked element to nan.\n",
      "  dtype = np.min_scalar_type(value)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/numpy/ma/core.py:713: UserWarning: Warning: converting a masked element to nan.\n",
      "  data = np.array(a, copy=False, subok=subok)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_adv[0].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
