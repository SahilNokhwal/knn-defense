{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import foolbox\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from lib.dataset_utils import *\n",
    "from lib.mnist_model import *\n",
    "from lib.adv_model import *\n",
    "from lib.dknn_attack import DKNNAttack\n",
    "from lib.cwl2_attack import CWL2Attack\n",
    "from lib.dknn import DKNN, DKNNL2\n",
    "from lib.foolbox_model import *\n",
    "from lib.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = 0\n",
    "\n",
    "# model_name = 'train_mnist_exp%d.h5' % exp_id\n",
    "# net = BasicModel()\n",
    "\n",
    "# model_name = 'train_mnist_snnl_exp%d.h5' % exp_id\n",
    "# net = SNNLModel(train_it=True)\n",
    "\n",
    "# model_name = 'train_mnist_hidden_mixup_exp%d.h5' % exp_id\n",
    "# net = HiddenMixupModel()\n",
    "\n",
    "# model_name = 'train_mnist_vae_exp%d.h5' % exp_id\n",
    "# net = VAE((1, 28, 28), num_classes=10, latent_dim=20)\n",
    "# net = VAE2((1, 28, 28), num_classes=10, latent_dim=1000)\n",
    "\n",
    "# model_name = 'train_mnist_cav_exp%d.h5' % exp_id\n",
    "# net = ClassAuxVAE((1, 28, 28), num_classes=10, latent_dim=20)\n",
    "\n",
    "model_name = 'adv_mnist_exp%d.h5' % exp_id\n",
    "basic_net = BasicModel()\n",
    "# basic_net = BasicModelV2()\n",
    "config = {'epsilon': 0.3,\n",
    "              'num_steps': 40,\n",
    "              'step_size': 0.01,\n",
    "              'random_start': True,\n",
    "              'loss_func': 'xent'}\n",
    "net = PGDModel(basic_net, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicModel(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3))\n",
       "  (relu1): ReLU(inplace)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(6, 6), stride=(2, 2), padding=(3, 3))\n",
       "  (relu2): ReLU(inplace)\n",
       "  (conv3): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu3): ReLU(inplace)\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set all random seeds\n",
    "seed = 2019\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Set up model directory\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "net = net.to(device)\n",
    "# if device == 'cuda':\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "#     cudnn.benchmark = True\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "# net = net.module\n",
    "net = net.basic_net\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid), (x_test, y_test) = load_mnist_all(\n",
    "    '/data', val_size=0.1, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = net(x_test.to(device))\n",
    "(y_pred.argmax(1).cpu() == y_test).sum().numpy() / y_test.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers = ['relu1', 'relu2', 'relu3', 'fc']\n",
    "# layers = ['relu1', 'relu2', 'relu3']\n",
    "layers = ['relu3']\n",
    "# layers = ['fc2']\n",
    "# layers = ['en_conv3']\n",
    "# layers = ['en_mu']\n",
    "# layers = ['maxpool1', 'maxpool2', 'relu3', 'fc2']\n",
    "# layers = ['maxpool2']\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     dknn = DKNN(net, x_train, y_train, x_valid, y_valid, layers, \n",
    "#                 k=75, num_classes=10)\n",
    "#     y_pred = dknn.classify(x_test)\n",
    "    \n",
    "dknn = DKNNL2(net, x_train, y_train, x_valid, y_valid, layers, \n",
    "              k=75, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9653\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = dknn.classify(x_test)\n",
    "    print((y_pred.argmax(1) == y_test.numpy()).sum() / y_test.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 994.,  813.,  695.,  959.,    0.,    0.,    0.,    0.,    0.,\n",
       "        6539.]),\n",
       " array([0.01666667, 0.115     , 0.21333333, 0.31166667, 0.41      ,\n",
       "        0.50833333, 0.60666667, 0.705     , 0.80333333, 0.90166667,\n",
       "        1.        ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cred = dknn.credibility(y_pred)\n",
    "plt.hist(cred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.argmax(y_pred, 1) == y_test.numpy()\n",
    "num_correct_by_cred = np.zeros((10, ))\n",
    "num_cred = np.zeros((10, ))\n",
    "for i in np.arange(10):\n",
    "    ind = (cred > i * 0.1) & (cred <= i* 0.1 + 0.1)\n",
    "    num_cred[i] = np.sum(ind)\n",
    "    num_correct_by_cred[i] = np.sum(correct[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(np.arange(10) * 0.1, num_cred, width=0.05)\n",
    "ax.bar(np.arange(10) * 0.1 + 0.05, num_correct_by_cred, width=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.6875    , 0.94731065, 0.99136691, 0.99687174,        nan,\n",
       "              nan,        nan,        nan,        nan, 0.99847071])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct_by_cred / num_cred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dknn_fb = DkNNFoolboxModel(dknn, (0, 1), 1, preprocessing=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from foolbox.criteria import Misclassification\n",
    "from foolbox.distances import MeanSquaredDistance\n",
    "\n",
    "criterion = Misclassification()\n",
    "distance = MeanSquaredDistance\n",
    "\n",
    "attack = foolbox.attacks.BoundaryAttack(\n",
    "    model=dknn_fb, criterion=criterion, distance=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither starting_point nor initialization_attack given. Falling back to BlendedUniformNoiseAttack for initialization.\n",
      "Initial spherical_step = 0.01, source_step = 0.01\n",
      "Using 4 threads to create random numbers\n",
      "Step 0: 8.25497e-02, stepsizes = 1.0e-02/1.0e-02: \n",
      "Step 10: 8.25497e-02, stepsizes = 1.0e-02/1.0e-02:  (took 2.09354 seconds)\n",
      "Step 20: 8.25497e-02, stepsizes = 1.0e-02/1.0e-02:  (took 2.02172 seconds)\n",
      "  Success rate too low, decreasing source step:  0.63 ( 75), 0.00 (30)\n",
      "Step 30: 8.25497e-02, stepsizes = 1.0e-02/6.7e-03:  (took 2.43455 seconds)\n",
      "  Boundary too linear, increasing steps:     0.60 (100), 0.00 (13)\n",
      "Step 40: 8.25497e-02, stepsizes = 1.5e-02/1.0e-02:  (took 1.95784 seconds)\n",
      "Step 50: 8.25497e-02, stepsizes = 1.5e-02/1.0e-02:  (took 2.12790 seconds)\n",
      "  Success rate too low, decreasing source step:  0.44 ( 50), 0.00 (30)\n",
      "Step 60: 8.25497e-02, stepsizes = 1.5e-02/6.7e-03:  (took 2.08625 seconds)\n",
      "Step 70: 8.03703e-02, stepsizes = 1.5e-02/6.7e-03:  (took 1.95560 seconds)\n",
      "Step 80: 7.61826e-02, stepsizes = 1.5e-02/6.7e-03:  (took 1.55220 seconds)\n",
      "Step 90: 7.61826e-02, stepsizes = 1.5e-02/6.7e-03:  (took 1.49384 seconds)\n",
      "  Success rate too low, decreasing source step:  0.31 (100), 0.00 (30)\n",
      "Step 100: 7.61826e-02, stepsizes = 1.5e-02/4.4e-03:  (took 1.45272 seconds)\n",
      "Initializing generation and prediction time measurements. This can take a few seconds.\n",
      "During initialization, a better adversarial has been found. Continuing from there.\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 187.63632\n",
      "   0.3% for generation (0.59381)\n",
      "   14.7% for spherical prediction (27.57216)\n",
      "   67.6% for prediction (126.88255)\n",
      "   0.0% for hyperparameter update (0.00514)\n",
      "   17.4% for the rest (32.58266)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.11207543e-04 1.24871731e-04 9.02016958e-05 7.24345446e-05\n",
      " 6.65092468e-05 4.94519869e-05 3.77236580e-05 3.90149653e-05\n",
      " 3.83206356e-05 1.23999119e-04 2.43718959e-05 2.69313653e-05\n",
      " 2.34482556e-05 1.75249820e-05 1.44396888e-05 1.20447949e-05\n",
      " 1.10703769e-05 1.04094729e-05 1.06509042e-05 1.30814314e-05\n",
      " 1.19398511e-05 1.08958276e-05 7.77091331e-06 8.13934538e-06\n",
      " 9.64927673e-06]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.05250178 0.02781962 0.01936165 0.01519677 0.01170658 0.01024334\n",
      " 0.00884617 0.00788441 0.00710096 0.007426   0.00706609 0.00605582\n",
      " 0.00934424 0.00883261 0.00769593 0.00787009 0.00857013 0.00740995\n",
      " 0.00691973 0.00427057 0.0045204  0.00470802 0.00511053 0.00440684\n",
      " 0.00410424]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.94 0.   0.   0.02 0.   0.   0.02 0.   0.   0.   0.   0.   0.01 0.\n",
      " 0.   0.   0.   0.01 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "Using batch size   1, an average step would have taken 1.26353 = 0.00506 + 1.25847 seconds\n",
      "Using batch size   2, an average step would have taken 0.69395 = 0.00308 + 0.69087 seconds\n",
      "Using batch size   3, an average step would have taken 0.49772 = 0.00228 + 0.49544 seconds\n",
      "Using batch size   4, an average step would have taken 0.40257 = 0.00187 + 0.40070 seconds\n",
      "Using batch size   5, an average step would have taken 0.28432 = 0.00161 + 0.28271 seconds\n",
      "Using batch size   6, an average step would have taken 0.28731 = 0.00134 + 0.28597 seconds\n",
      "Using batch size   7, an average step would have taken 0.23838 = 0.00104 + 0.23734 seconds\n",
      "Using batch size   8, an average step would have taken 0.23401 = 0.00111 + 0.23290 seconds\n",
      "Using batch size   9, an average step would have taken 0.18439 = 0.00092 + 0.18347 seconds\n",
      "Using batch size  10, an average step would have taken 0.20331 = 0.00274 + 0.20057 seconds\n",
      "Using batch size  11, an average step would have taken 0.20772 = 0.00078 + 0.20694 seconds\n",
      "Using batch size  12, an average step would have taken 0.19189 = 0.00083 + 0.19106 seconds\n",
      "Using batch size  13, an average step would have taken 0.19112 = 0.00061 + 0.19051 seconds\n",
      "Using batch size  14, an average step would have taken 0.19800 = 0.00050 + 0.19750 seconds\n",
      "Using batch size  15, an average step would have taken 0.18738 = 0.00139 + 0.18599 seconds\n",
      "Using batch size  16, an average step would have taken 0.18716 = 0.00052 + 0.18663 seconds\n",
      "Using batch size  17, an average step would have taken 0.20546 = 0.00048 + 0.20498 seconds\n",
      "Using batch size  18, an average step would have taken 0.19202 = 0.00044 + 0.19159 seconds\n",
      "Using batch size  19, an average step would have taken 0.18973 = 0.00048 + 0.18925 seconds\n",
      "Using batch size  20, an average step would have taken 0.14101 = 0.00057 + 0.14043 seconds\n",
      "Using batch size  21, an average step would have taken 0.15259 = 0.00052 + 0.15207 seconds\n",
      "Using batch size  22, an average step would have taken 0.15867 = 0.00049 + 0.15818 seconds\n",
      "Using batch size  23, an average step would have taken 0.17026 = 0.00041 + 0.16984 seconds\n",
      "Using batch size  24, an average step would have taken 0.15551 = 0.00039 + 0.15512 seconds\n",
      "Using batch size  25, an average step would have taken 0.10285 = 0.00024 + 0.10261 seconds\n",
      "batch size was 1, optimal batch size would have been 25\n",
      "setting batch size to 25: expected step duration: 0.10285\n",
      "improvement compared to old batch size (1): 12.3x\n",
      "improvement compared to worst batch size (1): 12.3x\n",
      "improvement compared to smallest batch size (1): 12.3x\n",
      "improvement compared to largest batch size (25): 1.0x\n",
      "next batch size tuning in 100 steps, after step 200\n",
      "Step 110: 7.48370e-02, stepsizes = 1.5e-02/4.4e-03:  (took 0.19078 seconds)\n",
      "Step 120: 7.41732e-02, stepsizes = 1.5e-02/4.4e-03:  (took 0.25285 seconds)\n",
      "  Boundary too linear, increasing steps:     0.52 (100), 0.07 (30)\n",
      "  Success rate too low, decreasing source step:  0.52 (100), 0.07 (30)\n",
      "Step 130: 7.09418e-02, stepsizes = 2.2e-02/4.4e-03: d. reduced by 0.89% (6.3482e-04) (took 0.28720 seconds)\n",
      "Step 140: 6.54759e-02, stepsizes = 2.2e-02/4.4e-03: d. reduced by 0.89% (5.8591e-04) (took 0.19353 seconds)\n",
      "Step 150: 6.09718e-02, stepsizes = 2.2e-02/4.4e-03: d. reduced by 0.89% (5.4561e-04) (took 0.18989 seconds)\n",
      "  Success rate too low, decreasing source step:  0.40 ( 75), 0.10 (30)\n",
      "Step 160: 5.67776e-02, stepsizes = 2.2e-02/3.0e-03:  (took 0.23522 seconds)\n",
      "Step 170: 5.35061e-02, stepsizes = 2.2e-02/3.0e-03: d. reduced by 0.59% (3.1849e-04) (took 0.22024 seconds)\n",
      "  Boundary too linear, increasing steps:     0.52 (100), 0.30 (30)\n",
      "Step 180: 5.07232e-02, stepsizes = 3.4e-02/4.4e-03: d. reduced by 0.59% (3.0192e-04) (took 0.27987 seconds)\n",
      "Step 190: 4.68150e-02, stepsizes = 3.4e-02/4.4e-03: d. reduced by 0.89% (4.1892e-04) (took 0.20553 seconds)\n",
      "Step 200: 4.28248e-02, stepsizes = 3.4e-02/4.4e-03: d. reduced by 0.89% (3.8322e-04) (took 0.18982 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 200.77548\n",
      "   0.6% for generation (1.13605)\n",
      "   14.3% for spherical prediction (28.75803)\n",
      "   68.3% for prediction (137.19630)\n",
      "   0.0% for hyperparameter update (0.01343)\n",
      "   16.8% for the rest (33.67167)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.11207543e-04 1.24871731e-04 9.02016958e-05 7.24345446e-05\n",
      " 6.65092468e-05 4.94519869e-05 3.77236580e-05 3.90149653e-05\n",
      " 3.83206356e-05 1.23999119e-04 2.43718959e-05 2.69313653e-05\n",
      " 2.34482556e-05 1.75249820e-05 1.44396888e-05 1.20447949e-05\n",
      " 1.10703769e-05 1.04094729e-05 1.06509042e-05 1.30814314e-05\n",
      " 1.19398511e-05 1.08958276e-05 7.77091331e-06 8.13934538e-06\n",
      " 8.68537072e-06]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.05250178 0.02781962 0.01936165 0.01519677 0.01170658 0.01024334\n",
      " 0.00884617 0.00788441 0.00710096 0.007426   0.00706609 0.00605582\n",
      " 0.00934424 0.00883261 0.00769593 0.00787009 0.00857013 0.00740995\n",
      " 0.00691973 0.00427057 0.0045204  0.00470802 0.00511053 0.00440684\n",
      " 0.00456348]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.29 0.16 0.02 0.08 0.02 0.04 0.03 0.03 0.04 0.02 0.02 0.01 0.06 0.02\n",
      " 0.03 0.   0.01 0.   0.04 0.   0.01 0.01 0.01 0.01 0.02 0.02]\n",
      "Using batch size   1, an average step would have taken 0.70056 = 0.00281 + 0.69775 seconds\n",
      "Using batch size   2, an average step would have taken 0.38968 = 0.00173 + 0.38795 seconds\n",
      "Using batch size   3, an average step would have taken 0.28244 = 0.00130 + 0.28114 seconds\n",
      "Using batch size   4, an average step would have taken 0.23255 = 0.00109 + 0.23146 seconds\n",
      "Using batch size   5, an average step would have taken 0.17660 = 0.00100 + 0.17560 seconds\n",
      "Using batch size   6, an average step would have taken 0.17012 = 0.00080 + 0.16931 seconds\n",
      "Using batch size   7, an average step would have taken 0.14824 = 0.00064 + 0.14760 seconds\n",
      "Using batch size   8, an average step would have taken 0.14248 = 0.00069 + 0.14180 seconds\n",
      "Using batch size   9, an average step would have taken 0.12324 = 0.00064 + 0.12261 seconds\n",
      "Using batch size  10, an average step would have taken 0.13746 = 0.00203 + 0.13543 seconds\n",
      "Using batch size  11, an average step would have taken 0.13917 = 0.00050 + 0.13867 seconds\n",
      "Using batch size  12, an average step would have taken 0.12364 = 0.00054 + 0.12310 seconds\n",
      "Using batch size  13, an average step would have taken 0.15463 = 0.00045 + 0.15418 seconds\n",
      "Using batch size  14, an average step would have taken 0.15666 = 0.00036 + 0.15630 seconds\n",
      "Using batch size  15, an average step would have taken 0.14737 = 0.00074 + 0.14663 seconds\n",
      "Using batch size  16, an average step would have taken 0.15246 = 0.00033 + 0.15212 seconds\n",
      "Using batch size  17, an average step would have taken 0.17187 = 0.00032 + 0.17155 seconds\n",
      "Using batch size  18, an average step would have taken 0.15658 = 0.00029 + 0.15629 seconds\n",
      "Using batch size  19, an average step would have taken 0.15453 = 0.00031 + 0.15422 seconds\n",
      "Using batch size  20, an average step would have taken 0.10686 = 0.00038 + 0.10648 seconds\n",
      "Using batch size  21, an average step would have taken 0.11656 = 0.00035 + 0.11620 seconds\n",
      "Using batch size  22, an average step would have taken 0.12366 = 0.00033 + 0.12333 seconds\n",
      "Using batch size  23, an average step would have taken 0.13616 = 0.00026 + 0.13590 seconds\n",
      "Using batch size  24, an average step would have taken 0.12230 = 0.00026 + 0.12204 seconds\n",
      "Using batch size  25, an average step would have taken 0.11430 = 0.00022 + 0.11409 seconds\n",
      "batch size was 25, optimal batch size would have been 20\n",
      "setting batch size to 20: expected step duration: 0.10686\n",
      "improvement compared to old batch size (25): 1.1x\n",
      "improvement compared to worst batch size (1): 6.6x\n",
      "improvement compared to smallest batch size (1): 6.6x\n",
      "improvement compared to largest batch size (25): 1.1x\n",
      "next batch size tuning in 100 steps, after step 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Success rate too low, decreasing source step:  0.41 ( 75), 0.13 (30)\n",
      "Step 210: 3.98789e-02, stepsizes = 3.4e-02/3.0e-03:  (took 0.34768 seconds)\n",
      "Step 220: 3.87130e-02, stepsizes = 3.4e-02/3.0e-03: d. reduced by 0.59% (2.3043e-04) (took 0.16391 seconds)\n",
      "Step 230: 3.64823e-02, stepsizes = 3.4e-02/3.0e-03: d. reduced by 0.59% (2.1716e-04) (took 0.15531 seconds)\n",
      "Step 240: 3.43802e-02, stepsizes = 3.4e-02/3.0e-03: d. reduced by 0.59% (2.0464e-04) (took 0.20843 seconds)\n",
      "  Boundary too linear, increasing steps:     0.51 (100), 0.43 (30)\n",
      "Step 250: 3.23992e-02, stepsizes = 5.1e-02/4.4e-03: d. reduced by 0.59% (1.9285e-04) (took 0.20941 seconds)\n",
      "  Success rate too high, increasing source step: 0.85 ( 20), 0.60 (30)\n",
      "Step 260: 2.96377e-02, stepsizes = 5.1e-02/6.7e-03: d. reduced by 0.89% (2.6521e-04) (took 0.27081 seconds)\n",
      "Step 270: 2.62757e-02, stepsizes = 5.1e-02/6.7e-03: d. reduced by 1.33% (3.5388e-04) (took 0.23032 seconds)\n",
      "Step 280: 2.32951e-02, stepsizes = 5.1e-02/6.7e-03: d. reduced by 1.33% (3.1373e-04) (took 0.19641 seconds)\n",
      "Step 290: 2.09307e-02, stepsizes = 5.1e-02/6.7e-03: d. reduced by 1.33% (2.8189e-04) (took 0.31853 seconds)\n",
      "  Boundary too linear, increasing steps:     0.54 (100), 0.13 (30)\n",
      "  Success rate too low, decreasing source step:  0.54 (100), 0.13 (30)\n",
      "Step 300: 1.93163e-02, stepsizes = 7.6e-02/6.7e-03: d. reduced by 1.33% (2.6015e-04) (took 0.18950 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 214.10953\n",
      "   0.7% for generation (1.60558)\n",
      "   14.0% for spherical prediction (29.95079)\n",
      "   69.0% for prediction (147.71552)\n",
      "   0.0% for hyperparameter update (0.02174)\n",
      "   16.3% for the rest (34.81590)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.11207543e-04 1.24871731e-04 9.02016958e-05 7.24345446e-05\n",
      " 3.53580051e-05 4.94519869e-05 3.77236580e-05 3.90149653e-05\n",
      " 3.83206356e-05 1.23999119e-04 2.43718959e-05 2.69313653e-05\n",
      " 2.34482556e-05 1.75249820e-05 1.44396888e-05 1.20447949e-05\n",
      " 1.10703769e-05 1.04094729e-05 1.06509042e-05 1.13989929e-05\n",
      " 1.19398511e-05 1.08958276e-05 7.77091331e-06 8.13934538e-06\n",
      " 8.68537072e-06]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.05250178 0.02781962 0.01936165 0.01519677 0.01170658 0.01024334\n",
      " 0.00884617 0.00788441 0.00710096 0.007426   0.00706609 0.00605582\n",
      " 0.00934424 0.00883261 0.00769593 0.00787009 0.00857013 0.00740995\n",
      " 0.00691973 0.00498205 0.0045204  0.00470802 0.00511053 0.00440684\n",
      " 0.00456348]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.15 0.15 0.12 0.05 0.06 0.06 0.05 0.08 0.02 0.01 0.03 0.03 0.01 0.02\n",
      " 0.02 0.03 0.01 0.03 0.01 0.01 0.03 0.01 0.01 0.   0.   0.  ]\n",
      "Using batch size   1, an average step would have taken 0.51395 = 0.00206 + 0.51189 seconds\n",
      "Using batch size   2, an average step would have taken 0.28959 = 0.00129 + 0.28830 seconds\n",
      "Using batch size   3, an average step would have taken 0.21507 = 0.00099 + 0.21408 seconds\n",
      "Using batch size   4, an average step would have taken 0.17770 = 0.00084 + 0.17686 seconds\n",
      "Using batch size   5, an average step would have taken 0.13855 = 0.00042 + 0.13814 seconds\n",
      "Using batch size   6, an average step would have taken 0.13451 = 0.00064 + 0.13387 seconds\n",
      "Using batch size   7, an average step would have taken 0.11673 = 0.00050 + 0.11623 seconds\n",
      "Using batch size   8, an average step would have taken 0.11313 = 0.00055 + 0.11258 seconds\n",
      "Using batch size   9, an average step would have taken 0.10301 = 0.00054 + 0.10248 seconds\n",
      "Using batch size  10, an average step would have taken 0.11342 = 0.00173 + 0.11169 seconds\n",
      "Using batch size  11, an average step would have taken 0.11327 = 0.00040 + 0.11287 seconds\n",
      "Using batch size  12, an average step would have taken 0.10499 = 0.00046 + 0.10453 seconds\n",
      "Using batch size  13, an average step would have taken 0.14441 = 0.00041 + 0.14400 seconds\n",
      "Using batch size  14, an average step would have taken 0.14652 = 0.00032 + 0.14620 seconds\n",
      "Using batch size  15, an average step would have taken 0.13529 = 0.00054 + 0.13475 seconds\n",
      "Using batch size  16, an average step would have taken 0.14218 = 0.00028 + 0.14190 seconds\n",
      "Using batch size  17, an average step would have taken 0.15983 = 0.00026 + 0.15957 seconds\n",
      "Using batch size  18, an average step would have taken 0.14663 = 0.00024 + 0.14638 seconds\n",
      "Using batch size  19, an average step would have taken 0.14403 = 0.00026 + 0.14377 seconds\n",
      "Using batch size  20, an average step would have taken 0.10985 = 0.00026 + 0.10959 seconds\n",
      "Using batch size  21, an average step would have taken 0.10495 = 0.00030 + 0.10465 seconds\n",
      "Using batch size  22, an average step would have taken 0.11257 = 0.00028 + 0.11229 seconds\n",
      "Using batch size  23, an average step would have taken 0.12610 = 0.00022 + 0.12589 seconds\n",
      "Using batch size  24, an average step would have taken 0.11387 = 0.00023 + 0.11364 seconds\n",
      "Using batch size  25, an average step would have taken 0.11430 = 0.00022 + 0.11409 seconds\n",
      "batch size was 20, optimal batch size would have been 9\n",
      "setting batch size to 9: expected step duration: 0.10301\n",
      "improvement compared to old batch size (20): 1.1x\n",
      "improvement compared to worst batch size (1): 5.0x\n",
      "improvement compared to smallest batch size (1): 5.0x\n",
      "improvement compared to largest batch size (25): 1.1x\n",
      "next batch size tuning in 100 steps, after step 400\n",
      "Step 310: 1.73558e-02, stepsizes = 7.6e-02/6.7e-03: d. reduced by 1.33% (2.3375e-04) (took 0.26987 seconds)\n",
      "Step 320: 1.58043e-02, stepsizes = 7.6e-02/6.7e-03: d. reduced by 1.33% (2.1285e-04) (took 0.12590 seconds)\n",
      "Step 330: 1.40115e-02, stepsizes = 7.6e-02/6.7e-03: d. reduced by 1.33% (1.8871e-04) (took 0.15140 seconds)\n",
      "Step 340: 1.22570e-02, stepsizes = 7.6e-02/6.7e-03: d. reduced by 1.33% (1.6508e-04) (took 0.28274 seconds)\n",
      "Step 350: 1.11613e-02, stepsizes = 7.6e-02/6.7e-03: d. reduced by 1.33% (1.5032e-04) (took 0.36691 seconds)\n",
      "Step 360: 1.07222e-02, stepsizes = 7.6e-02/6.7e-03:  (took 0.44270 seconds)\n",
      "  Success rate too low, decreasing source step:  0.35 (100), 0.10 (30)\n",
      "Step 370: 9.76372e-03, stepsizes = 7.6e-02/4.4e-03: d. reduced by 1.33% (1.3150e-04) (took 0.30178 seconds)\n",
      "Step 380: 8.93152e-03, stepsizes = 7.6e-02/4.4e-03: d. reduced by 0.89% (7.9924e-05) (took 0.37034 seconds)\n",
      "Step 390: 8.17025e-03, stepsizes = 7.6e-02/4.4e-03: d. reduced by 0.89% (7.3111e-05) (took 0.13030 seconds)\n",
      "Step 400: 7.67631e-03, stepsizes = 7.6e-02/4.4e-03: d. reduced by 0.89% (6.8691e-05) (took 0.11328 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 228.24984\n",
      "   0.8% for generation (1.86865)\n",
      "   13.7% for spherical prediction (31.24812)\n",
      "   69.6% for prediction (158.97476)\n",
      "   0.0% for hyperparameter update (0.02746)\n",
      "   15.8% for the rest (36.13085)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.11207543e-04 1.24871731e-04 9.02016958e-05 7.24345446e-05\n",
      " 3.53580051e-05 4.94519869e-05 8.93371210e-06 3.90149653e-05\n",
      " 2.15161982e-05 1.23999119e-04 2.43718959e-05 2.69313653e-05\n",
      " 2.34482556e-05 1.75249820e-05 1.44396888e-05 1.20447949e-05\n",
      " 1.10703769e-05 1.04094729e-05 1.06509042e-05 1.13989929e-05\n",
      " 1.19398511e-05 1.08958276e-05 7.77091331e-06 8.13934538e-06\n",
      " 8.68537072e-06]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.05250178 0.02781962 0.01936165 0.01519677 0.01170658 0.01024334\n",
      " 0.00884617 0.00788441 0.00797996 0.007426   0.00706609 0.00605582\n",
      " 0.00934424 0.00883261 0.00769593 0.00787009 0.00857013 0.00740995\n",
      " 0.00691973 0.00498205 0.0045204  0.00470802 0.00511053 0.00440684\n",
      " 0.00456348]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.22 0.13 0.1  0.08 0.02 0.11 0.03 0.05 0.02 0.01 0.01 0.03 0.01 0.05\n",
      " 0.01 0.01 0.01 0.   0.02 0.02 0.02 0.   0.02 0.   0.01 0.01]\n",
      "Using batch size   1, an average step would have taken 0.59039 = 0.00237 + 0.58802 seconds\n",
      "Using batch size   2, an average step would have taken 0.33237 = 0.00148 + 0.33089 seconds\n",
      "Using batch size   3, an average step would have taken 0.24321 = 0.00112 + 0.24209 seconds\n",
      "Using batch size   4, an average step would have taken 0.20207 = 0.00095 + 0.20112 seconds\n",
      "Using batch size   5, an average step would have taken 0.15206 = 0.00046 + 0.15160 seconds\n",
      "Using batch size   6, an average step would have taken 0.14984 = 0.00071 + 0.14913 seconds\n",
      "Using batch size   7, an average step would have taken 0.12869 = 0.00019 + 0.12850 seconds\n",
      "Using batch size   8, an average step would have taken 0.12495 = 0.00060 + 0.12435 seconds\n",
      "Using batch size   9, an average step would have taken 0.12301 = 0.00030 + 0.12272 seconds\n",
      "Using batch size  10, an average step would have taken 0.12398 = 0.00183 + 0.12215 seconds\n",
      "Using batch size  11, an average step would have taken 0.12398 = 0.00044 + 0.12354 seconds\n",
      "Using batch size  12, an average step would have taken 0.11431 = 0.00050 + 0.11381 seconds\n",
      "Using batch size  13, an average step would have taken 0.14733 = 0.00042 + 0.14691 seconds\n",
      "Using batch size  14, an average step would have taken 0.15042 = 0.00034 + 0.15008 seconds\n",
      "Using batch size  15, an average step would have taken 0.14057 = 0.00063 + 0.13994 seconds\n",
      "Using batch size  16, an average step would have taken 0.14916 = 0.00025 + 0.14890 seconds\n",
      "Using batch size  17, an average step would have taken 0.16616 = 0.00029 + 0.16588 seconds\n",
      "Using batch size  18, an average step would have taken 0.15216 = 0.00021 + 0.15196 seconds\n",
      "Using batch size  19, an average step would have taken 0.14897 = 0.00029 + 0.14868 seconds\n",
      "Using batch size  20, an average step would have taken 0.11513 = 0.00027 + 0.11486 seconds\n",
      "Using batch size  21, an average step would have taken 0.11106 = 0.00033 + 0.11073 seconds\n",
      "Using batch size  22, an average step would have taken 0.11782 = 0.00030 + 0.11752 seconds\n",
      "Using batch size  23, an average step would have taken 0.13113 = 0.00024 + 0.13090 seconds\n",
      "Using batch size  24, an average step would have taken 0.11808 = 0.00024 + 0.11784 seconds\n",
      "Using batch size  25, an average step would have taken 0.11430 = 0.00022 + 0.11409 seconds\n",
      "batch size was 9, optimal batch size would have been 21\n",
      "setting batch size to 21: expected step duration: 0.11106\n",
      "improvement compared to old batch size (9): 1.1x\n",
      "improvement compared to worst batch size (1): 5.3x\n",
      "improvement compared to smallest batch size (1): 5.3x\n",
      "improvement compared to largest batch size (25): 1.0x\n",
      "next batch size tuning in 100 steps, after step 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 410: 7.27676e-03, stepsizes = 7.6e-02/4.4e-03: d. reduced by 0.89% (6.5116e-05) (took 0.19676 seconds)\n",
      "Step 420: 6.71610e-03, stepsizes = 7.6e-02/4.4e-03:  (took 0.35834 seconds)\n",
      "Step 430: 6.31007e-03, stepsizes = 7.6e-02/4.4e-03:  (took 0.26538 seconds)\n",
      "Step 440: 5.92859e-03, stepsizes = 7.6e-02/4.4e-03: d. reduced by 0.89% (5.3052e-05) (took 0.19764 seconds)\n",
      "  Success rate too low, decreasing source step:  0.26 (100), 0.07 (30)\n",
      "Step 450: 5.57017e-03, stepsizes = 7.6e-02/3.0e-03: d. reduced by 0.89% (4.9845e-05) (took 0.20441 seconds)\n",
      "Step 460: 5.31189e-03, stepsizes = 7.6e-02/3.0e-03: d. reduced by 0.59% (3.1618e-05) (took 0.19487 seconds)\n",
      "Step 470: 5.06559e-03, stepsizes = 7.6e-02/3.0e-03: d. reduced by 0.59% (3.0152e-05) (took 0.23648 seconds)\n",
      "Step 480: 4.85946e-03, stepsizes = 7.6e-02/3.0e-03:  (took 0.24977 seconds)\n",
      "Step 490: 4.71738e-03, stepsizes = 7.6e-02/3.0e-03:  (took 0.23816 seconds)\n",
      "Step 500: 4.66172e-03, stepsizes = 7.6e-02/3.0e-03:  (took 0.21587 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 242.65921\n",
      "   1.0% for generation (2.34630)\n",
      "   13.5% for spherical prediction (32.77304)\n",
      "   70.3% for prediction (170.48983)\n",
      "   0.0% for hyperparameter update (0.04279)\n",
      "   15.3% for the rest (37.00726)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.11207543e-04 1.24871731e-04 9.02016958e-05 2.45115587e-05\n",
      " 3.53580051e-05 4.94519869e-05 8.93371210e-06 3.90149653e-05\n",
      " 2.15161982e-05 1.23999119e-04 2.43718959e-05 2.69313653e-05\n",
      " 2.34482556e-05 1.75249820e-05 1.44396888e-05 1.20447949e-05\n",
      " 1.10703769e-05 1.04094729e-05 1.06509042e-05 1.13989929e-05\n",
      " 1.05599074e-05 1.08958276e-05 7.77091331e-06 8.13934538e-06\n",
      " 8.68537072e-06]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.05250178 0.02781962 0.01936165 0.01519677 0.01170658 0.01024334\n",
      " 0.00884617 0.00788441 0.00797996 0.007426   0.00706609 0.00605582\n",
      " 0.00934424 0.00883261 0.00769593 0.00787009 0.00857013 0.00740995\n",
      " 0.00691973 0.00498205 0.00460502 0.00470802 0.00511053 0.00440684\n",
      " 0.00456348]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.34 0.07 0.03 0.04 0.   0.07 0.01 0.03 0.06 0.04 0.06 0.03 0.01 0.01\n",
      " 0.02 0.05 0.01 0.04 0.03 0.02 0.02 0.01 0.   0.   0.   0.  ]\n",
      "Using batch size   1, an average step would have taken 0.77963 = 0.00312 + 0.77650 seconds\n",
      "Using batch size   2, an average step would have taken 0.43318 = 0.00193 + 0.43125 seconds\n",
      "Using batch size   3, an average step would have taken 0.31203 = 0.00144 + 0.31060 seconds\n",
      "Using batch size   4, an average step would have taken 0.25598 = 0.00046 + 0.25553 seconds\n",
      "Using batch size   5, an average step would have taken 0.18787 = 0.00057 + 0.18731 seconds\n",
      "Using batch size   6, an average step would have taken 0.18590 = 0.00088 + 0.18502 seconds\n",
      "Using batch size   7, an average step would have taken 0.16141 = 0.00018 + 0.16123 seconds\n",
      "Using batch size   8, an average step would have taken 0.15421 = 0.00074 + 0.15346 seconds\n",
      "Using batch size   9, an average step would have taken 0.14300 = 0.00034 + 0.14265 seconds\n",
      "Using batch size  10, an average step would have taken 0.14059 = 0.00203 + 0.13856 seconds\n",
      "Using batch size  11, an average step would have taken 0.14151 = 0.00051 + 0.14100 seconds\n",
      "Using batch size  12, an average step would have taken 0.13106 = 0.00057 + 0.13049 seconds\n",
      "Using batch size  13, an average step would have taken 0.16120 = 0.00048 + 0.16072 seconds\n",
      "Using batch size  14, an average step would have taken 0.16446 = 0.00038 + 0.16407 seconds\n",
      "Using batch size  15, an average step would have taken 0.15114 = 0.00080 + 0.15034 seconds\n",
      "Using batch size  16, an average step would have taken 0.15924 = 0.00028 + 0.15896 seconds\n",
      "Using batch size  17, an average step would have taken 0.17250 = 0.00032 + 0.17218 seconds\n",
      "Using batch size  18, an average step would have taken 0.15774 = 0.00021 + 0.15753 seconds\n",
      "Using batch size  19, an average step would have taken 0.15453 = 0.00031 + 0.15422 seconds\n",
      "Using batch size  20, an average step would have taken 0.12042 = 0.00029 + 0.12013 seconds\n",
      "Using batch size  21, an average step would have taken 0.11763 = 0.00026 + 0.11737 seconds\n",
      "Using batch size  22, an average step would have taken 0.12366 = 0.00033 + 0.12333 seconds\n",
      "Using batch size  23, an average step would have taken 0.13672 = 0.00026 + 0.13646 seconds\n",
      "Using batch size  24, an average step would have taken 0.12388 = 0.00027 + 0.12361 seconds\n",
      "Using batch size  25, an average step would have taken 0.11430 = 0.00022 + 0.11409 seconds\n",
      "batch size was 21, optimal batch size would have been 25\n",
      "setting batch size to 25: expected step duration: 0.11430\n",
      "improvement compared to old batch size (21): 1.0x\n",
      "improvement compared to worst batch size (1): 6.8x\n",
      "improvement compared to smallest batch size (1): 6.8x\n",
      "improvement compared to largest batch size (25): 1.0x\n",
      "next batch size tuning in 100 steps, after step 600\n",
      "  Boundary too non-linear, decreasing steps: 0.10 (100), 0.20 (30)\n",
      "Step 510: 4.55236e-03, stepsizes = 5.1e-02/2.0e-03: d. reduced by 0.59% (2.7097e-05) (took 0.17570 seconds)\n",
      "Step 520: 4.41059e-03, stepsizes = 5.1e-02/2.0e-03:  (took 0.19425 seconds)\n",
      "Step 530: 4.32424e-03, stepsizes = 5.1e-02/2.0e-03:  (took 0.17161 seconds)\n",
      "Step 540: 4.25638e-03, stepsizes = 5.1e-02/2.0e-03: d. reduced by 0.39% (1.6865e-05) (took 0.22478 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.16 (100), 0.23 (30)\n",
      "Step 550: 4.14017e-03, stepsizes = 3.4e-02/1.3e-03: d. reduced by 0.39% (1.6405e-05) (took 0.19676 seconds)\n",
      "Step 560: 4.06449e-03, stepsizes = 3.4e-02/1.3e-03: d. reduced by 0.26% (1.0726e-05) (took 0.16540 seconds)\n",
      "  Success rate too low, decreasing source step:  0.28 ( 50), 0.17 (30)\n",
      "Step 570: 3.97969e-03, stepsizes = 3.4e-02/8.8e-04:  (took 0.15457 seconds)\n",
      "Step 580: 3.91039e-03, stepsizes = 3.4e-02/8.8e-04: d. reduced by 0.18% (6.8751e-06) (took 0.15864 seconds)\n",
      "Step 590: 3.85583e-03, stepsizes = 3.4e-02/8.8e-04:  (took 0.16162 seconds)\n",
      "Step 600: 3.78869e-03, stepsizes = 3.4e-02/8.8e-04: d. reduced by 0.18% (6.6611e-06) (took 0.26355 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 255.00091\n",
      "   1.1% for generation (2.83718)\n",
      "   13.3% for spherical prediction (33.90218)\n",
      "   70.8% for prediction (180.44000)\n",
      "   0.0% for hyperparameter update (0.05329)\n",
      "   14.8% for the rest (37.76826)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.11207543e-04 1.24871731e-04 9.02016958e-05 2.45115587e-05\n",
      " 3.53580051e-05 4.94519869e-05 8.93371210e-06 3.90149653e-05\n",
      " 2.15161982e-05 1.23999119e-04 2.43718959e-05 2.69313653e-05\n",
      " 2.34482556e-05 1.75249820e-05 1.44396888e-05 1.20447949e-05\n",
      " 1.10703769e-05 1.04094729e-05 1.06509042e-05 1.13989929e-05\n",
      " 1.05599074e-05 1.08958276e-05 7.77091331e-06 8.13934538e-06\n",
      " 8.27178196e-06]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.05250178 0.02781962 0.01936165 0.01519677 0.01170658 0.01024334\n",
      " 0.00884617 0.00788441 0.00797996 0.007426   0.00706609 0.00605582\n",
      " 0.00934424 0.00883261 0.00769593 0.00787009 0.00857013 0.00740995\n",
      " 0.00691973 0.00498205 0.00460502 0.00470802 0.00511053 0.00440684\n",
      " 0.00449442]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.29 0.11 0.08 0.09 0.06 0.03 0.04 0.01 0.03 0.01 0.04 0.01 0.02 0.02\n",
      " 0.03 0.02 0.01 0.03 0.   0.   0.01 0.01 0.03 0.01 0.01 0.  ]\n",
      "Using batch size   1, an average step would have taken 0.67262 = 0.00270 + 0.66992 seconds\n",
      "Using batch size   2, an average step would have taken 0.37354 = 0.00166 + 0.37187 seconds\n",
      "Using batch size   3, an average step would have taken 0.27322 = 0.00126 + 0.27196 seconds\n",
      "Using batch size   4, an average step would have taken 0.22351 = 0.00040 + 0.22312 seconds\n",
      "Using batch size   5, an average step would have taken 0.16908 = 0.00051 + 0.16857 seconds\n",
      "Using batch size   6, an average step would have taken 0.16474 = 0.00078 + 0.16396 seconds\n",
      "Using batch size   7, an average step would have taken 0.14467 = 0.00016 + 0.14451 seconds\n",
      "Using batch size   8, an average step would have taken 0.13826 = 0.00067 + 0.13759 seconds\n",
      "Using batch size   9, an average step would have taken 0.13322 = 0.00032 + 0.13289 seconds\n",
      "Using batch size  10, an average step would have taken 0.13380 = 0.00192 + 0.13188 seconds\n",
      "Using batch size  11, an average step would have taken 0.13430 = 0.00048 + 0.13382 seconds\n",
      "Using batch size  12, an average step would have taken 0.12259 = 0.00054 + 0.12205 seconds\n",
      "Using batch size  13, an average step would have taken 0.15463 = 0.00045 + 0.15418 seconds\n",
      "Using batch size  14, an average step would have taken 0.15666 = 0.00036 + 0.15630 seconds\n",
      "Using batch size  15, an average step would have taken 0.14586 = 0.00071 + 0.14514 seconds\n",
      "Using batch size  16, an average step would have taken 0.15420 = 0.00027 + 0.15393 seconds\n",
      "Using batch size  17, an average step would have taken 0.16870 = 0.00030 + 0.16840 seconds\n",
      "Using batch size  18, an average step would have taken 0.15588 = 0.00021 + 0.15567 seconds\n",
      "Using batch size  19, an average step would have taken 0.15391 = 0.00031 + 0.15360 seconds\n",
      "Using batch size  20, an average step would have taken 0.12042 = 0.00029 + 0.12013 seconds\n",
      "Using batch size  21, an average step would have taken 0.11763 = 0.00026 + 0.11737 seconds\n",
      "Using batch size  22, an average step would have taken 0.12191 = 0.00032 + 0.12158 seconds\n",
      "Using batch size  23, an average step would have taken 0.13449 = 0.00025 + 0.13423 seconds\n",
      "Using batch size  24, an average step would have taken 0.12125 = 0.00026 + 0.12099 seconds\n",
      "Using batch size  25, an average step would have taken 0.11257 = 0.00021 + 0.11236 seconds\n",
      "batch size was 25, optimal batch size would have been 25\n",
      "setting batch size to 25: expected step duration: 0.11257\n",
      "improvement compared to old batch size (25): 1.0x\n",
      "improvement compared to worst batch size (1): 6.0x\n",
      "improvement compared to smallest batch size (1): 6.0x\n",
      "improvement compared to largest batch size (25): 1.0x\n",
      "next batch size tuning in 200 steps, after step 800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 610: 3.72271e-03, stepsizes = 3.4e-02/8.8e-04: d. reduced by 0.18% (6.5451e-06) (took 0.21229 seconds)\n",
      "  Success rate too high, increasing source step: 0.45 (100), 0.70 (30)\n",
      "Step 620: 3.66432e-03, stepsizes = 3.4e-02/1.3e-03: d. reduced by 0.18% (6.4424e-06) (took 0.18776 seconds)\n",
      "Step 630: 3.64506e-03, stepsizes = 3.4e-02/1.3e-03: d. reduced by 0.26% (9.6192e-06) (took 0.17721 seconds)\n",
      "Step 640: 3.58787e-03, stepsizes = 3.4e-02/1.3e-03: d. reduced by 0.26% (9.4682e-06) (took 0.25095 seconds)\n",
      "Step 650: 3.53159e-03, stepsizes = 3.4e-02/1.3e-03:  (took 0.19817 seconds)\n",
      "Step 660: 3.50377e-03, stepsizes = 3.4e-02/1.3e-03:  (took 0.19861 seconds)\n",
      "  Success rate too low, decreasing source step:  0.28 (100), 0.10 (30)\n",
      "Step 670: 3.48535e-03, stepsizes = 3.4e-02/8.8e-04: d. reduced by 0.26% (9.1978e-06) (took 0.15432 seconds)\n",
      "Step 680: 3.44276e-03, stepsizes = 3.4e-02/8.8e-04: d. reduced by 0.18% (6.0529e-06) (took 0.16922 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.15 (100), 0.29 ( 7)\n",
      "Step 690: 3.40667e-03, stepsizes = 2.3e-02/5.9e-04:  (took 0.18223 seconds)\n",
      "Step 700: 3.38282e-03, stepsizes = 2.3e-02/5.9e-04: d. reduced by 0.12% (3.9632e-06) (took 0.20906 seconds)\n",
      "Step 710: 3.35520e-03, stepsizes = 2.3e-02/5.9e-04: d. reduced by 0.12% (3.9309e-06) (took 0.20378 seconds)\n",
      "  Success rate too low, decreasing source step:  0.32 ( 75), 0.17 (30)\n",
      "Step 720: 3.32392e-03, stepsizes = 2.3e-02/3.9e-04: d. reduced by 0.12% (3.8943e-06) (took 0.21002 seconds)\n",
      "Step 730: 3.29808e-03, stepsizes = 2.3e-02/3.9e-04: d. reduced by 0.08% (2.5752e-06) (took 0.17528 seconds)\n",
      "Step 740: 3.27244e-03, stepsizes = 2.3e-02/3.9e-04: d. reduced by 0.08% (2.5552e-06) (took 0.23747 seconds)\n",
      "  Success rate too high, increasing source step: 0.46 (100), 0.73 (30)\n",
      "Step 750: 3.24699e-03, stepsizes = 2.3e-02/5.9e-04: d. reduced by 0.08% (2.5353e-06) (took 0.19013 seconds)\n",
      "Step 760: 3.21296e-03, stepsizes = 2.3e-02/5.9e-04: d. reduced by 0.12% (3.7642e-06) (took 0.19544 seconds)\n",
      "Step 770: 3.19420e-03, stepsizes = 2.3e-02/5.9e-04:  (took 0.21228 seconds)\n",
      "Step 780: 3.17555e-03, stepsizes = 2.3e-02/5.9e-04: d. reduced by 0.12% (3.7203e-06) (took 0.16007 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.17 (100), 0.18 (17)\n",
      "Step 790: 3.14595e-03, stepsizes = 1.5e-02/3.9e-04:  (took 0.16785 seconds)\n",
      "Step 800: 3.12881e-03, stepsizes = 1.5e-02/3.9e-04:  (took 0.20513 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 280.92712\n",
      "   1.4% for generation (3.91256)\n",
      "   12.9% for spherical prediction (36.20092)\n",
      "   71.7% for prediction (201.32955)\n",
      "   0.0% for hyperparameter update (0.07430)\n",
      "   14.0% for the rest (39.40979)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.11207543e-04 1.24871731e-04 9.02016958e-05 2.45115587e-05\n",
      " 3.53580051e-05 4.94519869e-05 8.93371210e-06 3.90149653e-05\n",
      " 2.15161982e-05 1.23999119e-04 2.43718959e-05 2.69313653e-05\n",
      " 2.34482556e-05 1.75249820e-05 1.44396888e-05 1.20447949e-05\n",
      " 1.10703769e-05 1.04094729e-05 1.06509042e-05 1.13989929e-05\n",
      " 1.05599074e-05 1.08958276e-05 7.77091331e-06 8.13934538e-06\n",
      " 8.43700590e-06]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.05250178 0.02781962 0.01936165 0.01519677 0.01170658 0.01024334\n",
      " 0.00884617 0.00788441 0.00797996 0.007426   0.00706609 0.00605582\n",
      " 0.00934424 0.00883261 0.00769593 0.00787009 0.00857013 0.00740995\n",
      " 0.00691973 0.00498205 0.00460502 0.00470802 0.00511053 0.00440684\n",
      " 0.00456746]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.32  0.12  0.045 0.045 0.05  0.045 0.05  0.05  0.025 0.02  0.02  0.02\n",
      " 0.015 0.015 0.035 0.02  0.01  0.005 0.015 0.025 0.005 0.    0.    0.01\n",
      " 0.    0.035]\n",
      "Using batch size   1, an average step would have taken 0.71584 = 0.00287 + 0.71297 seconds\n",
      "Using batch size   2, an average step would have taken 0.39876 = 0.00177 + 0.39699 seconds\n",
      "Using batch size   3, an average step would have taken 0.29094 = 0.00134 + 0.28960 seconds\n",
      "Using batch size   4, an average step would have taken 0.23699 = 0.00043 + 0.23656 seconds\n",
      "Using batch size   5, an average step would have taken 0.17701 = 0.00053 + 0.17648 seconds\n",
      "Using batch size   6, an average step would have taken 0.17527 = 0.00083 + 0.17444 seconds\n",
      "Using batch size   7, an average step would have taken 0.14867 = 0.00016 + 0.14851 seconds\n",
      "Using batch size   8, an average step would have taken 0.14454 = 0.00069 + 0.14384 seconds\n",
      "Using batch size   9, an average step would have taken 0.13610 = 0.00032 + 0.13578 seconds\n",
      "Using batch size  10, an average step would have taken 0.13694 = 0.00196 + 0.13498 seconds\n",
      "Using batch size  11, an average step would have taken 0.13907 = 0.00050 + 0.13857 seconds\n",
      "Using batch size  12, an average step would have taken 0.12784 = 0.00056 + 0.12728 seconds\n",
      "Using batch size  13, an average step would have taken 0.15682 = 0.00046 + 0.15636 seconds\n",
      "Using batch size  14, an average step would have taken 0.15861 = 0.00036 + 0.15825 seconds\n",
      "Using batch size  15, an average step would have taken 0.14774 = 0.00074 + 0.14700 seconds\n",
      "Using batch size  16, an average step would have taken 0.15600 = 0.00027 + 0.15573 seconds\n",
      "Using batch size  17, an average step would have taken 0.17187 = 0.00032 + 0.17155 seconds\n",
      "Using batch size  18, an average step would have taken 0.15805 = 0.00021 + 0.15784 seconds\n",
      "Using batch size  19, an average step would have taken 0.15453 = 0.00031 + 0.15422 seconds\n",
      "Using batch size  20, an average step would have taken 0.12130 = 0.00029 + 0.12101 seconds\n",
      "Using batch size  21, an average step would have taken 0.11915 = 0.00026 + 0.11889 seconds\n",
      "Using batch size  22, an average step would have taken 0.12512 = 0.00034 + 0.12478 seconds\n",
      "Using batch size  23, an average step would have taken 0.13756 = 0.00027 + 0.13729 seconds\n",
      "Using batch size  24, an average step would have taken 0.12467 = 0.00027 + 0.12440 seconds\n",
      "Using batch size  25, an average step would have taken 0.11440 = 0.00021 + 0.11419 seconds\n",
      "batch size was 25, optimal batch size would have been 25\n",
      "setting batch size to 25: expected step duration: 0.11440\n",
      "improvement compared to old batch size (25): 1.0x\n",
      "improvement compared to worst batch size (1): 6.3x\n",
      "improvement compared to smallest batch size (1): 6.3x\n",
      "improvement compared to largest batch size (25): 1.0x\n",
      "next batch size tuning in 400 steps, after step 1200\n",
      "  Success rate too low, decreasing source step:  0.44 ( 50), 0.17 (30)\n",
      "Step 810: 3.10690e-03, stepsizes = 1.5e-02/2.6e-04: d. reduced by 0.08% (2.4259e-06) (took 0.34322 seconds)\n",
      "Step 820: 3.09078e-03, stepsizes = 1.5e-02/2.6e-04: d. reduced by 0.05% (1.6086e-06) (took 0.17715 seconds)\n",
      "Step 830: 3.07474e-03, stepsizes = 1.5e-02/2.6e-04: d. reduced by 0.05% (1.6002e-06) (took 0.25358 seconds)\n",
      "  Boundary too linear, increasing steps:     0.55 (100), 0.50 (30)\n",
      "Step 840: 3.05878e-03, stepsizes = 2.3e-02/3.9e-04: d. reduced by 0.05% (1.5919e-06) (took 0.18897 seconds)\n",
      "  Success rate too high, increasing source step: 0.76 ( 25), 0.57 (30)\n",
      "Step 850: 3.03737e-03, stepsizes = 2.3e-02/5.9e-04: d. reduced by 0.08% (2.3717e-06) (took 0.24155 seconds)\n",
      "Step 860: 3.03027e-03, stepsizes = 2.3e-02/5.9e-04:  (took 0.13392 seconds)\n",
      "Step 870: 3.01611e-03, stepsizes = 2.3e-02/5.9e-04:  (took 0.16363 seconds)\n",
      "Step 880: 3.00905e-03, stepsizes = 2.3e-02/5.9e-04:  (took 0.17038 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.09 (100), 0.00 ( 9)\n",
      "Step 890: 3.00905e-03, stepsizes = 1.5e-02/3.9e-04:  (took 0.11890 seconds)\n",
      "Step 900: 2.99967e-03, stepsizes = 1.5e-02/3.9e-04:  (took 0.17694 seconds)\n",
      "Step 910: 2.99733e-03, stepsizes = 1.5e-02/3.9e-04:  (took 0.20454 seconds)\n",
      "Step 920: 2.99032e-03, stepsizes = 1.5e-02/3.9e-04:  (took 0.13188 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.15 (100), 0.00 (24)\n",
      "Step 930: 2.98566e-03, stepsizes = 1.0e-02/2.6e-04:  (took 0.18118 seconds)\n",
      "Step 940: 2.97635e-03, stepsizes = 1.0e-02/2.6e-04: d. reduced by 0.05% (1.5490e-06) (took 0.24293 seconds)\n",
      "Step 950: 2.96553e-03, stepsizes = 1.0e-02/2.6e-04: d. reduced by 0.05% (1.5434e-06) (took 0.18258 seconds)\n",
      "Step 960: 2.95475e-03, stepsizes = 1.0e-02/2.6e-04: d. reduced by 0.05% (1.5379e-06) (took 0.20724 seconds)\n",
      "Step 970: 2.94707e-03, stepsizes = 1.0e-02/2.6e-04: d. reduced by 0.05% (1.5338e-06) (took 0.19141 seconds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 980: 2.93636e-03, stepsizes = 1.0e-02/2.6e-04: d. reduced by 0.05% (1.5283e-06) (took 0.17679 seconds)\n",
      "Step 990: 2.92568e-03, stepsizes = 1.0e-02/2.6e-04: d. reduced by 0.05% (1.5226e-06) (took 0.18668 seconds)\n",
      "Step 1000: 2.91353e-03, stepsizes = 1.0e-02/2.6e-04: d. reduced by 0.05% (1.5163e-06) (took 0.19769 seconds)\n",
      "Step 1010: 2.90899e-03, stepsizes = 1.0e-02/2.6e-04: d. reduced by 0.05% (1.5141e-06) (took 0.18742 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.20 (30)\n",
      "Step 1020: 2.90143e-03, stepsizes = 6.7e-03/1.7e-04: d. reduced by 0.05% (1.5100e-06) (took 0.21976 seconds)\n",
      "  Success rate too low, decreasing source step:  0.40 ( 25), 0.17 (30)\n",
      "Step 1030: 2.89439e-03, stepsizes = 6.7e-03/1.2e-04:  (took 0.20240 seconds)\n",
      "Step 1040: 2.88771e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (6.6770e-07) (took 0.25303 seconds)\n",
      "Step 1050: 2.88170e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (6.6641e-07) (took 0.17978 seconds)\n",
      "Step 1060: 2.87571e-03, stepsizes = 6.7e-03/1.2e-04:  (took 0.18899 seconds)\n",
      "Step 1070: 2.86973e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (6.6367e-07) (took 0.21024 seconds)\n",
      "Step 1080: 2.86311e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (6.6213e-07) (took 0.16896 seconds)\n",
      "Step 1090: 2.85914e-03, stepsizes = 6.7e-03/1.2e-04:  (took 0.18312 seconds)\n",
      "Step 1100: 2.85253e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (6.5966e-07) (took 0.20705 seconds)\n",
      "Step 1110: 2.84594e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (6.5810e-07) (took 0.30851 seconds)\n",
      "Step 1120: 2.84003e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (6.5681e-07) (took 0.17815 seconds)\n",
      "Step 1130: 2.83347e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (6.5525e-07) (took 0.22018 seconds)\n",
      "Step 1140: 2.82758e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (6.5393e-07) (took 0.17675 seconds)\n",
      "Step 1150: 2.82170e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (6.5253e-07) (took 0.23373 seconds)\n",
      "Step 1160: 2.81518e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (6.5109e-07) (took 0.21759 seconds)\n",
      "  Boundary too linear, increasing steps:     0.54 (100), 0.53 (30)\n",
      "  Success rate too high, increasing source step: 0.54 (100), 0.53 (30)\n",
      "Step 1170: 2.80868e-03, stepsizes = 1.0e-02/2.6e-04: d. reduced by 0.02% (6.4955e-07) (took 0.21825 seconds)\n",
      "Step 1180: 2.80138e-03, stepsizes = 1.0e-02/2.6e-04: d. reduced by 0.05% (1.4580e-06) (took 0.18257 seconds)\n",
      "Step 1190: 2.78975e-03, stepsizes = 1.0e-02/2.6e-04: d. reduced by 0.05% (1.4519e-06) (took 0.17348 seconds)\n",
      "Step 1200: 2.78539e-03, stepsizes = 1.0e-02/2.6e-04: d. reduced by 0.05% (1.4497e-06) (took 0.21341 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 332.62897\n",
      "   1.8% for generation (6.07513)\n",
      "   12.2% for spherical prediction (40.68902)\n",
      "   73.0% for prediction (242.75665)\n",
      "   0.0% for hyperparameter update (0.10840)\n",
      "   12.9% for the rest (42.99976)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.11207543e-04 1.24871731e-04 9.02016958e-05 2.45115587e-05\n",
      " 3.53580051e-05 4.94519869e-05 8.93371210e-06 3.90149653e-05\n",
      " 2.15161982e-05 1.23999119e-04 2.43718959e-05 2.69313653e-05\n",
      " 2.34482556e-05 1.75249820e-05 1.44396888e-05 1.20447949e-05\n",
      " 1.10703769e-05 1.04094729e-05 1.06509042e-05 1.13989929e-05\n",
      " 1.05599074e-05 1.08958276e-05 7.77091331e-06 8.13934538e-06\n",
      " 8.54350029e-06]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.05250178 0.02781962 0.01936165 0.01519677 0.01170658 0.01024334\n",
      " 0.00884617 0.00788441 0.00797996 0.007426   0.00706609 0.00605582\n",
      " 0.00934424 0.00883261 0.00769593 0.00787009 0.00857013 0.00740995\n",
      " 0.00691973 0.00498205 0.00460502 0.00470802 0.00511053 0.00440684\n",
      " 0.00458514]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.315  0.11   0.0925 0.08   0.03   0.05   0.0325 0.045  0.0325 0.0225\n",
      " 0.0125 0.02   0.015  0.0175 0.01   0.02   0.0125 0.015  0.005  0.005\n",
      " 0.015  0.0125 0.005  0.0125 0.005  0.0075]\n",
      "Using batch size   1, an average step would have taken 0.67749 = 0.00271 + 0.67478 seconds\n",
      "Using batch size   2, an average step would have taken 0.37860 = 0.00168 + 0.37692 seconds\n",
      "Using batch size   3, an average step would have taken 0.27479 = 0.00126 + 0.27352 seconds\n",
      "Using batch size   4, an average step would have taken 0.22568 = 0.00040 + 0.22528 seconds\n",
      "Using batch size   5, an average step would have taken 0.17011 = 0.00051 + 0.16960 seconds\n",
      "Using batch size   6, an average step would have taken 0.16769 = 0.00079 + 0.16689 seconds\n",
      "Using batch size   7, an average step would have taken 0.14436 = 0.00016 + 0.14420 seconds\n",
      "Using batch size   8, an average step would have taken 0.13902 = 0.00067 + 0.13835 seconds\n",
      "Using batch size   9, an average step would have taken 0.13178 = 0.00032 + 0.13146 seconds\n",
      "Using batch size  10, an average step would have taken 0.13367 = 0.00191 + 0.13176 seconds\n",
      "Using batch size  11, an average step would have taken 0.13469 = 0.00049 + 0.13420 seconds\n",
      "Using batch size  12, an average step would have taken 0.12339 = 0.00054 + 0.12285 seconds\n",
      "Using batch size  13, an average step would have taken 0.15390 = 0.00045 + 0.15345 seconds\n",
      "Using batch size  14, an average step would have taken 0.15744 = 0.00036 + 0.15708 seconds\n",
      "Using batch size  15, an average step would have taken 0.14661 = 0.00072 + 0.14589 seconds\n",
      "Using batch size  16, an average step would have taken 0.15474 = 0.00027 + 0.15447 seconds\n",
      "Using batch size  17, an average step would have taken 0.17013 = 0.00031 + 0.16982 seconds\n",
      "Using batch size  18, an average step would have taken 0.15697 = 0.00021 + 0.15676 seconds\n",
      "Using batch size  19, an average step would have taken 0.15468 = 0.00031 + 0.15437 seconds\n",
      "Using batch size  20, an average step would have taken 0.12086 = 0.00029 + 0.12057 seconds\n",
      "Using batch size  21, an average step would have taken 0.11793 = 0.00026 + 0.11768 seconds\n",
      "Using batch size  22, an average step would have taken 0.12366 = 0.00033 + 0.12333 seconds\n",
      "Using batch size  23, an average step would have taken 0.13602 = 0.00026 + 0.13576 seconds\n",
      "Using batch size  24, an average step would have taken 0.12296 = 0.00026 + 0.12270 seconds\n",
      "Using batch size  25, an average step would have taken 0.11484 = 0.00021 + 0.11463 seconds\n",
      "batch size was 25, optimal batch size would have been 25\n",
      "setting batch size to 25: expected step duration: 0.11484\n",
      "improvement compared to old batch size (25): 1.0x\n",
      "improvement compared to worst batch size (1): 5.9x\n",
      "improvement compared to smallest batch size (1): 5.9x\n",
      "improvement compared to largest batch size (25): 1.0x\n",
      "next batch size tuning in 800 steps, after step 2000\n",
      "Step 1210: 2.77816e-03, stepsizes = 1.0e-02/2.6e-04: d. reduced by 0.05% (1.4459e-06) (took 0.18365 seconds)\n",
      "Step 1220: 2.77382e-03, stepsizes = 1.0e-02/2.6e-04:  (took 0.18002 seconds)\n",
      "Step 1230: 2.76806e-03, stepsizes = 1.0e-02/2.6e-04:  (took 0.16641 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.13 (100), 0.17 (30)\n",
      "  Success rate too low, decreasing source step:  0.13 (100), 0.17 (30)\n",
      "Step 1240: 2.76662e-03, stepsizes = 6.7e-03/1.2e-04:  (took 0.19641 seconds)\n",
      "Step 1250: 2.76087e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (6.3851e-07) (took 0.21004 seconds)\n",
      "Step 1260: 2.75513e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (6.3714e-07) (took 0.16957 seconds)\n",
      "Step 1270: 2.74876e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (6.3575e-07) (took 0.18948 seconds)\n",
      "  Success rate too high, increasing source step: 0.49 (100), 0.60 (30)\n",
      "Step 1280: 2.74241e-03, stepsizes = 6.7e-03/1.7e-04: d. reduced by 0.02% (6.3415e-07) (took 0.21964 seconds)\n",
      "  Boundary too linear, increasing steps:     0.53 (100), 0.20 (10)\n",
      "Step 1290: 2.73766e-03, stepsizes = 1.0e-02/2.6e-04: d. reduced by 0.03% (9.4973e-07) (took 0.16592 seconds)\n",
      "Step 1300: 2.73766e-03, stepsizes = 1.0e-02/2.6e-04:  (took 0.16614 seconds)\n",
      "Step 1310: 2.73055e-03, stepsizes = 1.0e-02/2.6e-04:  (took 0.20165 seconds)\n",
      "  Success rate too low, decreasing source step:  0.29 ( 75), 0.07 (30)\n",
      "Step 1320: 2.72487e-03, stepsizes = 1.0e-02/1.7e-04:  (took 0.21572 seconds)\n",
      "Step 1330: 2.71732e-03, stepsizes = 1.0e-02/1.7e-04: d. reduced by 0.03% (9.4274e-07) (took 0.22443 seconds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1340: 2.71355e-03, stepsizes = 1.0e-02/1.7e-04:  (took 0.18655 seconds)\n",
      "Step 1350: 2.71073e-03, stepsizes = 1.0e-02/1.7e-04:  (took 0.19043 seconds)\n",
      "Step 1360: 2.70228e-03, stepsizes = 1.0e-02/1.7e-04: d. reduced by 0.03% (9.3746e-07) (took 0.20458 seconds)\n",
      "  Success rate too low, decreasing source step:  0.26 (100), 0.17 (30)\n",
      "Step 1370: 2.69573e-03, stepsizes = 1.0e-02/1.2e-04: d. reduced by 0.03% (9.3517e-07) (took 0.18735 seconds)\n",
      "Step 1380: 2.68950e-03, stepsizes = 1.0e-02/1.2e-04: d. reduced by 0.02% (6.2200e-07) (took 0.19278 seconds)\n",
      "Step 1390: 2.68391e-03, stepsizes = 1.0e-02/1.2e-04: d. reduced by 0.02% (6.2062e-07) (took 0.22613 seconds)\n",
      "  Success rate too high, increasing source step: 0.42 (100), 0.67 (30)\n",
      "Step 1400: 2.67833e-03, stepsizes = 1.0e-02/1.7e-04: d. reduced by 0.02% (6.1943e-07) (took 0.21417 seconds)\n",
      "Step 1410: 2.66998e-03, stepsizes = 1.0e-02/1.7e-04: d. reduced by 0.03% (9.2632e-07) (took 0.17173 seconds)\n",
      "Step 1420: 2.66351e-03, stepsizes = 1.0e-02/1.7e-04: d. reduced by 0.03% (9.2400e-07) (took 0.17188 seconds)\n",
      "Step 1430: 2.65889e-03, stepsizes = 1.0e-02/1.7e-04:  (took 0.20074 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.18 (100), 0.17 (18)\n",
      "Step 1440: 2.65613e-03, stepsizes = 6.7e-03/1.2e-04:  (took 0.18289 seconds)\n",
      "Step 1450: 2.65122e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (6.1312e-07) (took 0.26850 seconds)\n",
      "Step 1460: 2.64754e-03, stepsizes = 6.7e-03/1.2e-04:  (took 0.20524 seconds)\n",
      "Step 1470: 2.64387e-03, stepsizes = 6.7e-03/1.2e-04:  (took 0.19316 seconds)\n",
      "Step 1480: 2.64143e-03, stepsizes = 6.7e-03/1.2e-04:  (took 0.14540 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.13 (30)\n",
      "  Success rate too low, decreasing source step:  0.19 (100), 0.13 (30)\n",
      "Step 1490: 2.63594e-03, stepsizes = 4.4e-03/5.1e-05:  (took 0.18595 seconds)\n",
      "Step 1500: 2.63323e-03, stepsizes = 4.4e-03/5.1e-05: d. reduced by 0.01% (2.7056e-07) (took 0.26110 seconds)\n",
      "Step 1510: 2.63053e-03, stepsizes = 4.4e-03/5.1e-05: d. reduced by 0.01% (2.7045e-07) (took 0.25644 seconds)\n",
      "Step 1520: 2.62782e-03, stepsizes = 4.4e-03/5.1e-05: d. reduced by 0.01% (2.7010e-07) (took 0.24660 seconds)\n",
      "  Boundary too linear, increasing steps:     0.52 (100), 0.40 (30)\n",
      "Step 1530: 2.62512e-03, stepsizes = 6.7e-03/7.7e-05: d. reduced by 0.01% (2.6984e-07) (took 0.19676 seconds)\n",
      "Step 1540: 2.62148e-03, stepsizes = 6.7e-03/7.7e-05: d. reduced by 0.02% (4.0412e-07) (took 0.22125 seconds)\n",
      "Step 1550: 2.61866e-03, stepsizes = 6.7e-03/7.7e-05:  (took 0.21021 seconds)\n",
      "Step 1560: 2.61462e-03, stepsizes = 6.7e-03/7.7e-05: d. reduced by 0.02% (4.0307e-07) (took 0.19386 seconds)\n",
      "Step 1570: 2.61100e-03, stepsizes = 6.7e-03/7.7e-05: d. reduced by 0.02% (4.0248e-07) (took 0.26407 seconds)\n",
      "Step 1580: 2.60778e-03, stepsizes = 6.7e-03/7.7e-05: d. reduced by 0.02% (4.0197e-07) (took 0.18319 seconds)\n",
      "  Success rate too high, increasing source step: 0.41 (100), 0.53 (30)\n",
      "Step 1590: 2.60376e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (4.0147e-07) (took 0.20133 seconds)\n",
      "Step 1600: 2.59835e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (6.0094e-07) (took 0.20028 seconds)\n",
      "Step 1610: 2.59775e-03, stepsizes = 6.7e-03/1.2e-04:  (took 0.15179 seconds)\n",
      "Step 1620: 2.59715e-03, stepsizes = 6.7e-03/1.2e-04:  (took 0.17801 seconds)\n",
      "Step 1630: 2.59355e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (5.9979e-07) (took 0.17017 seconds)\n",
      "  Success rate too low, decreasing source step:  0.21 (100), 0.07 (30)\n",
      "Step 1640: 2.59235e-03, stepsizes = 6.7e-03/7.7e-05:  (took 0.19271 seconds)\n",
      "Step 1650: 2.58915e-03, stepsizes = 6.7e-03/7.7e-05: d. reduced by 0.02% (3.9913e-07) (took 0.26894 seconds)\n",
      "Step 1660: 2.58557e-03, stepsizes = 6.7e-03/7.7e-05: d. reduced by 0.02% (3.9870e-07) (took 0.19105 seconds)\n",
      "  Success rate too high, increasing source step: 0.35 (100), 0.60 (30)\n",
      "Step 1670: 2.58238e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (3.9812e-07) (took 0.16134 seconds)\n",
      "Step 1680: 2.58059e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (5.9678e-07) (took 0.21172 seconds)\n",
      "Step 1690: 2.57641e-03, stepsizes = 6.7e-03/1.2e-04: d. reduced by 0.02% (5.9581e-07) (took 0.23644 seconds)\n",
      "Step 1700: 2.57641e-03, stepsizes = 6.7e-03/1.2e-04:  (took 0.19067 seconds)\n",
      "Step 1710: 2.57284e-03, stepsizes = 6.7e-03/1.2e-04:  (took 0.14937 seconds)\n",
      "  Success rate too low, decreasing source step:  0.24 (100), 0.10 (30)\n",
      "Step 1720: 2.57165e-03, stepsizes = 6.7e-03/7.7e-05: d. reduced by 0.02% (5.9469e-07) (took 0.15877 seconds)\n",
      "Step 1730: 2.56769e-03, stepsizes = 6.7e-03/7.7e-05: d. reduced by 0.02% (3.9587e-07) (took 0.23849 seconds)\n",
      "Step 1740: 2.56532e-03, stepsizes = 6.7e-03/7.7e-05: d. reduced by 0.02% (3.9550e-07) (took 0.19168 seconds)\n",
      "Step 1750: 2.56374e-03, stepsizes = 6.7e-03/7.7e-05:  (took 0.16357 seconds)\n",
      "Step 1760: 2.56097e-03, stepsizes = 6.7e-03/7.7e-05: d. reduced by 0.02% (3.9479e-07) (took 0.20834 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.30 (30)\n",
      "Step 1770: 2.55900e-03, stepsizes = 4.4e-03/5.1e-05: d. reduced by 0.02% (3.9445e-07) (took 0.19246 seconds)\n",
      "Step 1780: 2.55663e-03, stepsizes = 4.4e-03/5.1e-05: d. reduced by 0.01% (2.6275e-07) (took 0.21881 seconds)\n",
      "Step 1790: 2.55427e-03, stepsizes = 4.4e-03/5.1e-05: d. reduced by 0.01% (2.6253e-07) (took 0.19533 seconds)\n",
      "Step 1800: 2.55191e-03, stepsizes = 4.4e-03/5.1e-05: d. reduced by 0.01% (2.6219e-07) (took 0.24614 seconds)\n",
      "Step 1810: 2.54929e-03, stepsizes = 4.4e-03/5.1e-05: d. reduced by 0.01% (2.6208e-07) (took 0.17469 seconds)\n",
      "Step 1820: 2.54693e-03, stepsizes = 4.4e-03/5.1e-05:  (took 0.17622 seconds)\n",
      "Step 1830: 2.54510e-03, stepsizes = 4.4e-03/5.1e-05: d. reduced by 0.01% (2.6158e-07) (took 0.27504 seconds)\n",
      "Step 1840: 2.54248e-03, stepsizes = 4.4e-03/5.1e-05: d. reduced by 0.01% (2.6129e-07) (took 0.20647 seconds)\n",
      "  Success rate too high, increasing source step: 0.48 (100), 0.53 (30)\n",
      "Step 1850: 2.54013e-03, stepsizes = 4.4e-03/7.7e-05: d. reduced by 0.01% (2.6100e-07) (took 0.27419 seconds)\n",
      "Step 1860: 2.53779e-03, stepsizes = 4.4e-03/7.7e-05:  (took 0.20582 seconds)\n",
      "Step 1870: 2.53779e-03, stepsizes = 4.4e-03/7.7e-05:  (took 0.12124 seconds)\n",
      "Step 1880: 2.53739e-03, stepsizes = 4.4e-03/7.7e-05: d. reduced by 0.02% (3.9124e-07) (took 0.19086 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.06 (100), 0.17 ( 6)\n",
      "Step 1890: 2.53661e-03, stepsizes = 3.0e-03/5.1e-05:  (took 0.18115 seconds)\n",
      "Step 1900: 2.53427e-03, stepsizes = 3.0e-03/5.1e-05: d. reduced by 0.01% (2.6050e-07) (took 0.19309 seconds)\n",
      "Step 1910: 2.53244e-03, stepsizes = 3.0e-03/5.1e-05: d. reduced by 0.01% (2.6022e-07) (took 0.20599 seconds)\n",
      "  Success rate too low, decreasing source step:  0.39 ( 75), 0.10 (30)\n",
      "Step 1920: 2.53192e-03, stepsizes = 3.0e-03/3.4e-05:  (took 0.20158 seconds)\n",
      "Step 1930: 2.53054e-03, stepsizes = 3.0e-03/3.4e-05: d. reduced by 0.01% (1.7337e-07) (took 0.17364 seconds)\n",
      "Step 1940: 2.52898e-03, stepsizes = 3.0e-03/3.4e-05: d. reduced by 0.01% (1.7322e-07) (took 0.19166 seconds)\n",
      "Step 1950: 2.52794e-03, stepsizes = 3.0e-03/3.4e-05: d. reduced by 0.01% (1.7316e-07) (took 0.17570 seconds)\n",
      "Step 1960: 2.52638e-03, stepsizes = 3.0e-03/3.4e-05: d. reduced by 0.01% (1.7312e-07) (took 0.15832 seconds)\n",
      "  Success rate too low, decreasing source step:  0.29 (100), 0.13 (30)\n",
      "Step 1970: 2.52465e-03, stepsizes = 3.0e-03/2.3e-05: d. reduced by 0.01% (1.7293e-07) (took 0.22245 seconds)\n",
      "Step 1980: 2.52361e-03, stepsizes = 3.0e-03/2.3e-05: d. reduced by 0.00% (1.1528e-07) (took 0.20442 seconds)\n",
      "Step 1990: 2.52257e-03, stepsizes = 3.0e-03/2.3e-05: d. reduced by 0.00% (1.1511e-07) (took 0.27147 seconds)\n",
      "Step 2000: 2.52142e-03, stepsizes = 3.0e-03/2.3e-05: d. reduced by 0.00% (1.1523e-07) (took 0.22334 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 435.83390\n",
      "   2.4% for generation (10.46009)\n",
      "   11.5% for spherical prediction (50.02521)\n",
      "   74.6% for prediction (325.30808)\n",
      "   0.0% for hyperparameter update (0.19807)\n",
      "   11.4% for the rest (49.84245)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.11207543e-04 1.24871731e-04 9.02016958e-05 2.45115587e-05\n",
      " 3.53580051e-05 4.94519869e-05 8.93371210e-06 3.90149653e-05\n",
      " 2.15161982e-05 1.23999119e-04 2.43718959e-05 2.69313653e-05\n",
      " 2.34482556e-05 1.75249820e-05 1.44396888e-05 1.20447949e-05\n",
      " 1.10703769e-05 1.04094729e-05 1.06509042e-05 1.13989929e-05\n",
      " 1.05599074e-05 1.08958276e-05 7.77091331e-06 8.13934538e-06\n",
      " 8.65664294e-06]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.05250178 0.02781962 0.01936165 0.01519677 0.01170658 0.01024334\n",
      " 0.00884617 0.00788441 0.00797996 0.007426   0.00706609 0.00605582\n",
      " 0.00934424 0.00883261 0.00769593 0.00787009 0.00857013 0.00740995\n",
      " 0.00691973 0.00498205 0.00460502 0.00470802 0.00511053 0.00440684\n",
      " 0.00458566]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.32875 0.10125 0.07    0.04625 0.04375 0.05    0.05    0.02375 0.0225\n",
      " 0.02375 0.0225  0.02625 0.0225  0.02375 0.01625 0.0125  0.01125 0.01625\n",
      " 0.0125  0.0125  0.015   0.015   0.0125  0.00875 0.00625 0.00625]\n",
      "Using batch size   1, an average step would have taken 0.72256 = 0.00290 + 0.71967 seconds\n",
      "Using batch size   2, an average step would have taken 0.40141 = 0.00179 + 0.39962 seconds\n",
      "Using batch size   3, an average step would have taken 0.29193 = 0.00134 + 0.29059 seconds\n",
      "Using batch size   4, an average step would have taken 0.23928 = 0.00043 + 0.23885 seconds\n",
      "Using batch size   5, an average step would have taken 0.17950 = 0.00054 + 0.17896 seconds\n",
      "Using batch size   6, an average step would have taken 0.17460 = 0.00082 + 0.17377 seconds\n",
      "Using batch size   7, an average step would have taken 0.15054 = 0.00017 + 0.15037 seconds\n",
      "Using batch size   8, an average step would have taken 0.14610 = 0.00070 + 0.14539 seconds\n",
      "Using batch size   9, an average step would have taken 0.13808 = 0.00033 + 0.13775 seconds\n",
      "Using batch size  10, an average step would have taken 0.13890 = 0.00198 + 0.13692 seconds\n",
      "Using batch size  11, an average step would have taken 0.13898 = 0.00050 + 0.13847 seconds\n",
      "Using batch size  12, an average step would have taken 0.12697 = 0.00055 + 0.12641 seconds\n",
      "Using batch size  13, an average step would have taken 0.15636 = 0.00046 + 0.15590 seconds\n",
      "Using batch size  14, an average step would have taken 0.15958 = 0.00037 + 0.15922 seconds\n",
      "Using batch size  15, an average step would have taken 0.14925 = 0.00077 + 0.14848 seconds\n",
      "Using batch size  16, an average step would have taken 0.15735 = 0.00028 + 0.15707 seconds\n",
      "Using batch size  17, an average step would have taken 0.17234 = 0.00032 + 0.17203 seconds\n",
      "Using batch size  18, an average step would have taken 0.15867 = 0.00021 + 0.15846 seconds\n",
      "Using batch size  19, an average step would have taken 0.15592 = 0.00032 + 0.15560 seconds\n",
      "Using batch size  20, an average step would have taken 0.12203 = 0.00029 + 0.12174 seconds\n",
      "Using batch size  21, an average step would have taken 0.11900 = 0.00026 + 0.11874 seconds\n",
      "Using batch size  22, an average step would have taken 0.12424 = 0.00033 + 0.12391 seconds\n",
      "Using batch size  23, an average step would have taken 0.13679 = 0.00026 + 0.13653 seconds\n",
      "Using batch size  24, an average step would have taken 0.12362 = 0.00027 + 0.12335 seconds\n",
      "Using batch size  25, an average step would have taken 0.11486 = 0.00022 + 0.11464 seconds\n",
      "batch size was 25, optimal batch size would have been 25\n",
      "setting batch size to 25: expected step duration: 0.11486\n",
      "improvement compared to old batch size (25): 1.0x\n",
      "improvement compared to worst batch size (1): 6.3x\n",
      "improvement compared to smallest batch size (1): 6.3x\n",
      "improvement compared to largest batch size (25): 1.0x\n",
      "next batch size tuning in 1600 steps, after step 3600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2010: 2.52039e-03, stepsizes = 3.0e-03/2.3e-05: d. reduced by 0.00% (1.1513e-07) (took 0.24375 seconds)\n",
      "Step 2020: 2.51935e-03, stepsizes = 3.0e-03/2.3e-05: d. reduced by 0.00% (1.1505e-07) (took 0.21995 seconds)\n",
      "Step 2030: 2.51820e-03, stepsizes = 3.0e-03/2.3e-05: d. reduced by 0.00% (1.1507e-07) (took 0.18664 seconds)\n",
      "Step 2040: 2.51705e-03, stepsizes = 3.0e-03/2.3e-05: d. reduced by 0.00% (1.1501e-07) (took 0.23882 seconds)\n",
      "  Success rate too high, increasing source step: 0.42 (100), 0.60 (30)\n",
      "Step 2050: 2.51625e-03, stepsizes = 3.0e-03/3.4e-05: d. reduced by 0.00% (1.1485e-07) (took 0.17324 seconds)\n",
      "Step 2060: 2.51487e-03, stepsizes = 3.0e-03/3.4e-05:  (took 0.14292 seconds)\n",
      "Step 2070: 2.51349e-03, stepsizes = 3.0e-03/3.4e-05: d. reduced by 0.01% (1.7221e-07) (took 0.21078 seconds)\n",
      "Step 2080: 2.51228e-03, stepsizes = 3.0e-03/3.4e-05: d. reduced by 0.01% (1.7209e-07) (took 0.22511 seconds)\n",
      "Step 2090: 2.51142e-03, stepsizes = 3.0e-03/3.4e-05: d. reduced by 0.01% (1.7209e-07) (took 0.15542 seconds)\n",
      "Step 2100: 2.51073e-03, stepsizes = 3.0e-03/3.4e-05: d. reduced by 0.01% (1.7196e-07) (took 0.23295 seconds)\n",
      "Step 2110: 2.50970e-03, stepsizes = 3.0e-03/3.4e-05:  (took 0.18727 seconds)\n",
      "Step 2120: 2.50919e-03, stepsizes = 3.0e-03/3.4e-05:  (took 0.24145 seconds)\n",
      "Step 2130: 2.50781e-03, stepsizes = 3.0e-03/3.4e-05: d. reduced by 0.01% (1.7186e-07) (took 0.20802 seconds)\n",
      "Step 2140: 2.50661e-03, stepsizes = 3.0e-03/3.4e-05:  (took 0.19330 seconds)\n",
      "Step 2150: 2.50541e-03, stepsizes = 3.0e-03/3.4e-05: d. reduced by 0.01% (1.7167e-07) (took 0.19947 seconds)\n",
      "Step 2160: 2.50421e-03, stepsizes = 3.0e-03/3.4e-05:  (took 0.16880 seconds)\n",
      "  Success rate too low, decreasing source step:  0.29 (100), 0.17 (30)\n",
      "Step 2170: 2.50249e-03, stepsizes = 3.0e-03/2.3e-05: d. reduced by 0.01% (1.7137e-07) (took 0.21560 seconds)\n",
      "Step 2180: 2.50135e-03, stepsizes = 3.0e-03/2.3e-05: d. reduced by 0.00% (1.1422e-07) (took 0.20212 seconds)\n",
      "Step 2190: 2.50032e-03, stepsizes = 3.0e-03/2.3e-05: d. reduced by 0.00% (1.1412e-07) (took 0.17893 seconds)\n",
      "Step 2200: 2.49918e-03, stepsizes = 3.0e-03/2.3e-05: d. reduced by 0.00% (1.1409e-07) (took 0.21674 seconds)\n",
      "Step 2210: 2.49838e-03, stepsizes = 3.0e-03/2.3e-05: d. reduced by 0.00% (1.1415e-07) (took 0.18628 seconds)\n",
      "  Success rate too high, increasing source step: 0.31 (100), 0.60 (30)\n",
      "Step 2220: 2.49724e-03, stepsizes = 3.0e-03/3.4e-05: d. reduced by 0.00% (1.1409e-07) (took 0.13862 seconds)\n",
      "Step 2230: 2.49587e-03, stepsizes = 3.0e-03/3.4e-05:  (took 0.18154 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.18 (100), 0.12 ( 8)\n",
      "Step 2240: 2.49467e-03, stepsizes = 2.0e-03/2.3e-05: d. reduced by 0.01% (1.7090e-07) (took 0.16948 seconds)\n",
      "Step 2250: 2.49388e-03, stepsizes = 2.0e-03/2.3e-05:  (took 0.19491 seconds)\n",
      "Step 2260: 2.49297e-03, stepsizes = 2.0e-03/2.3e-05: d. reduced by 0.00% (1.1390e-07) (took 0.19923 seconds)\n",
      "Step 2270: 2.49240e-03, stepsizes = 2.0e-03/2.3e-05:  (took 0.18159 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.19 (27)\n",
      "Step 2280: 2.49137e-03, stepsizes = 1.3e-03/1.5e-05: d. reduced by 0.00% (1.1378e-07) (took 0.15957 seconds)\n",
      "Step 2290: 2.49077e-03, stepsizes = 1.3e-03/1.5e-05: d. reduced by 0.00% (7.5863e-08) (took 0.27887 seconds)\n",
      "Step 2300: 2.49008e-03, stepsizes = 1.3e-03/1.5e-05: d. reduced by 0.00% (7.5842e-08) (took 0.19928 seconds)\n",
      "Step 2310: 2.48948e-03, stepsizes = 1.3e-03/1.5e-05: d. reduced by 0.00% (7.5808e-08) (took 0.23328 seconds)\n",
      "Step 2320: 2.48887e-03, stepsizes = 1.3e-03/1.5e-05: d. reduced by 0.00% (7.5847e-08) (took 0.19182 seconds)\n",
      "Step 2330: 2.48857e-03, stepsizes = 1.3e-03/1.5e-05: d. reduced by 0.00% (7.5870e-08) (took 0.17214 seconds)\n",
      "Step 2340: 2.48811e-03, stepsizes = 1.3e-03/1.5e-05:  (took 0.13101 seconds)\n",
      "Step 2350: 2.48758e-03, stepsizes = 1.3e-03/1.5e-05: d. reduced by 0.00% (7.5765e-08) (took 0.17032 seconds)\n",
      "Step 2360: 2.48682e-03, stepsizes = 1.3e-03/1.5e-05: d. reduced by 0.00% (7.5731e-08) (took 0.26016 seconds)\n",
      "Step 2370: 2.48637e-03, stepsizes = 1.3e-03/1.5e-05: d. reduced by 0.00% (7.5690e-08) (took 0.20467 seconds)\n",
      "Step 2380: 2.48607e-03, stepsizes = 1.3e-03/1.5e-05: d. reduced by 0.00% (7.5763e-08) (took 0.23702 seconds)\n",
      "Step 2390: 2.48561e-03, stepsizes = 1.3e-03/1.5e-05: d. reduced by 0.00% (7.5681e-08) (took 0.19598 seconds)\n",
      "Step 2400: 2.48539e-03, stepsizes = 1.3e-03/1.5e-05:  (took 0.20328 seconds)\n",
      "Step 2410: 2.48486e-03, stepsizes = 1.3e-03/1.5e-05: d. reduced by 0.00% (7.5686e-08) (took 0.20034 seconds)\n",
      "Step 2420: 2.48440e-03, stepsizes = 1.3e-03/1.5e-05:  (took 0.16594 seconds)\n",
      "Step 2430: 2.48402e-03, stepsizes = 1.3e-03/1.5e-05:  (took 0.15247 seconds)\n",
      "Step 2440: 2.48372e-03, stepsizes = 1.3e-03/1.5e-05: d. reduced by 0.00% (7.5603e-08) (took 0.19470 seconds)\n",
      "Step 2450: 2.48327e-03, stepsizes = 1.3e-03/1.5e-05: d. reduced by 0.00% (7.5634e-08) (took 0.17358 seconds)\n",
      "Step 2460: 2.48304e-03, stepsizes = 1.3e-03/1.5e-05:  (took 0.18047 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.27 (30)\n",
      "Step 2470: 2.48266e-03, stepsizes = 8.8e-04/1.0e-05:  (took 0.16023 seconds)\n",
      "Step 2480: 2.48246e-03, stepsizes = 8.8e-04/1.0e-05:  (took 0.13997 seconds)\n",
      "Step 2490: 2.48216e-03, stepsizes = 8.8e-04/1.0e-05:  (took 0.16866 seconds)\n",
      "  Success rate too low, decreasing source step:  0.27 ( 75), 0.13 (30)\n",
      "Step 2500: 2.48191e-03, stepsizes = 8.8e-04/6.8e-06: d. reduced by 0.00% (5.0380e-08) (took 0.18491 seconds)\n",
      "Step 2510: 2.48161e-03, stepsizes = 8.8e-04/6.8e-06: d. reduced by 0.00% (3.3559e-08) (took 0.22200 seconds)\n",
      "Step 2520: 2.48127e-03, stepsizes = 8.8e-04/6.8e-06: d. reduced by 0.00% (3.3593e-08) (took 0.23766 seconds)\n",
      "Step 2530: 2.48093e-03, stepsizes = 8.8e-04/6.8e-06: d. reduced by 0.00% (3.3505e-08) (took 0.13804 seconds)\n",
      "Step 2540: 2.48063e-03, stepsizes = 8.8e-04/6.8e-06: d. reduced by 0.00% (3.3502e-08) (took 0.27585 seconds)\n",
      "Step 2550: 2.48030e-03, stepsizes = 8.8e-04/6.8e-06: d. reduced by 0.00% (3.3660e-08) (took 0.16620 seconds)\n",
      "  Success rate too high, increasing source step: 0.46 (100), 0.57 (30)\n",
      "Step 2560: 2.47996e-03, stepsizes = 8.8e-04/1.0e-05: d. reduced by 0.00% (3.3623e-08) (took 0.18559 seconds)\n",
      "Step 2570: 2.47966e-03, stepsizes = 8.8e-04/1.0e-05:  (took 0.21627 seconds)\n",
      "Step 2580: 2.47941e-03, stepsizes = 8.8e-04/1.0e-05: d. reduced by 0.00% (5.0253e-08) (took 0.23358 seconds)\n",
      "Step 2590: 2.47916e-03, stepsizes = 8.8e-04/1.0e-05: d. reduced by 0.00% (5.0389e-08) (took 0.17515 seconds)\n",
      "Step 2600: 2.47890e-03, stepsizes = 8.8e-04/1.0e-05:  (took 0.19510 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.08 (25)\n",
      "Step 2610: 2.47865e-03, stepsizes = 5.9e-04/6.8e-06:  (took 0.17261 seconds)\n",
      "  Success rate too low, decreasing source step:  0.44 ( 25), 0.17 (30)\n",
      "Step 2620: 2.47835e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (3.3500e-08) (took 0.20459 seconds)\n",
      "Step 2630: 2.47813e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2376e-08) (took 0.19428 seconds)\n",
      "Step 2640: 2.47793e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2380e-08) (took 0.22036 seconds)\n",
      "Step 2650: 2.47772e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2334e-08) (took 0.16715 seconds)\n",
      "Step 2660: 2.47750e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2290e-08) (took 0.20826 seconds)\n",
      "Step 2670: 2.47730e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2353e-08) (took 0.22273 seconds)\n",
      "Step 2680: 2.47717e-03, stepsizes = 5.9e-04/4.5e-06:  (took 0.15183 seconds)\n",
      "Step 2690: 2.47694e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2401e-08) (took 0.15088 seconds)\n",
      "Step 2700: 2.47676e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2347e-08) (took 0.19299 seconds)\n",
      "Step 2710: 2.47661e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2312e-08) (took 0.15173 seconds)\n",
      "Step 2720: 2.47650e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2326e-08) (took 0.17812 seconds)\n",
      "Step 2730: 2.47629e-03, stepsizes = 5.9e-04/4.5e-06:  (took 0.17644 seconds)\n",
      "Step 2740: 2.47609e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2303e-08) (took 0.18553 seconds)\n",
      "Step 2750: 2.47594e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2334e-08) (took 0.18435 seconds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2760: 2.47571e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2307e-08) (took 0.24498 seconds)\n",
      "Step 2770: 2.47549e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2325e-08) (took 0.19677 seconds)\n",
      "  Boundary too linear, increasing steps:     0.51 (100), 0.57 (30)\n",
      "  Success rate too high, increasing source step: 0.51 (100), 0.57 (30)\n",
      "Step 2780: 2.47527e-03, stepsizes = 8.8e-04/1.0e-05: d. reduced by 0.00% (2.2339e-08) (took 0.25286 seconds)\n",
      "Step 2790: 2.47507e-03, stepsizes = 8.8e-04/1.0e-05:  (took 0.19883 seconds)\n",
      "Step 2800: 2.47486e-03, stepsizes = 8.8e-04/1.0e-05: d. reduced by 0.00% (5.0243e-08) (took 0.15519 seconds)\n",
      "Step 2810: 2.47461e-03, stepsizes = 8.8e-04/1.0e-05: d. reduced by 0.00% (5.0226e-08) (took 0.18307 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.17 (100), 0.12 (17)\n",
      "Step 2820: 2.47441e-03, stepsizes = 5.9e-04/6.8e-06:  (took 0.21205 seconds)\n",
      "Step 2830: 2.47435e-03, stepsizes = 5.9e-04/6.8e-06:  (took 0.18248 seconds)\n",
      "  Success rate too low, decreasing source step:  0.28 ( 50), 0.17 (30)\n",
      "Step 2840: 2.47411e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (3.3542e-08) (took 0.22942 seconds)\n",
      "Step 2850: 2.47391e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2361e-08) (took 0.27093 seconds)\n",
      "Step 2860: 2.47369e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2285e-08) (took 0.20365 seconds)\n",
      "Step 2870: 2.47346e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2309e-08) (took 0.26605 seconds)\n",
      "Step 2880: 2.47324e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2274e-08) (took 0.24369 seconds)\n",
      "Step 2890: 2.47302e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2313e-08) (took 0.23749 seconds)\n",
      "  Success rate too high, increasing source step: 0.48 (100), 0.53 (30)\n",
      "Step 2900: 2.47279e-03, stepsizes = 5.9e-04/6.8e-06: d. reduced by 0.00% (2.2265e-08) (took 0.18808 seconds)\n",
      "Step 2910: 2.47256e-03, stepsizes = 5.9e-04/6.8e-06: d. reduced by 0.00% (3.3525e-08) (took 0.21567 seconds)\n",
      "Step 2920: 2.47233e-03, stepsizes = 5.9e-04/6.8e-06: d. reduced by 0.00% (3.3468e-08) (took 0.19175 seconds)\n",
      "Step 2930: 2.47206e-03, stepsizes = 5.9e-04/6.8e-06: d. reduced by 0.00% (3.3507e-08) (took 0.19705 seconds)\n",
      "Step 2940: 2.47179e-03, stepsizes = 5.9e-04/6.8e-06: d. reduced by 0.00% (3.3428e-08) (took 0.18704 seconds)\n",
      "Step 2950: 2.47169e-03, stepsizes = 5.9e-04/6.8e-06:  (took 0.16360 seconds)\n",
      "Step 2960: 2.47156e-03, stepsizes = 5.9e-04/6.8e-06: d. reduced by 0.00% (3.3420e-08) (took 0.22185 seconds)\n",
      "  Success rate too low, decreasing source step:  0.33 (100), 0.10 (30)\n",
      "Step 2970: 2.47139e-03, stepsizes = 5.9e-04/4.5e-06:  (took 0.20904 seconds)\n",
      "Step 2980: 2.47119e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2314e-08) (took 0.17809 seconds)\n",
      "Step 2990: 2.47099e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2226e-08) (took 0.23849 seconds)\n",
      "  Success rate too high, increasing source step: 0.46 (100), 0.67 (30)\n",
      "Step 3000: 2.47079e-03, stepsizes = 5.9e-04/6.8e-06: d. reduced by 0.00% (2.2276e-08) (took 0.23461 seconds)\n",
      "Step 3010: 2.47069e-03, stepsizes = 5.9e-04/6.8e-06: d. reduced by 0.00% (3.3471e-08) (took 0.19464 seconds)\n",
      "Step 3020: 2.47042e-03, stepsizes = 5.9e-04/6.8e-06:  (took 0.25562 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.08 (12)\n",
      "Step 3030: 2.47039e-03, stepsizes = 3.9e-04/4.5e-06:  (took 0.19402 seconds)\n",
      "Step 3040: 2.47023e-03, stepsizes = 3.9e-04/4.5e-06:  (took 0.15708 seconds)\n",
      "Step 3050: 2.47001e-03, stepsizes = 3.9e-04/4.5e-06: d. reduced by 0.00% (2.2339e-08) (took 0.19399 seconds)\n",
      "  Success rate too low, decreasing source step:  0.25 ( 75), 0.07 (30)\n",
      "Step 3060: 2.46994e-03, stepsizes = 3.9e-04/3.0e-06: d. reduced by 0.00% (2.2295e-08) (took 0.22977 seconds)\n",
      "Step 3070: 2.46982e-03, stepsizes = 3.9e-04/3.0e-06: d. reduced by 0.00% (1.4860e-08) (took 0.20692 seconds)\n",
      "Step 3080: 2.46969e-03, stepsizes = 3.9e-04/3.0e-06: d. reduced by 0.00% (1.4828e-08) (took 0.15963 seconds)\n",
      "Step 3090: 2.46958e-03, stepsizes = 3.9e-04/3.0e-06: d. reduced by 0.00% (1.4905e-08) (took 0.18292 seconds)\n",
      "Step 3100: 2.46945e-03, stepsizes = 3.9e-04/3.0e-06: d. reduced by 0.00% (1.4812e-08) (took 0.17991 seconds)\n",
      "Step 3110: 2.46930e-03, stepsizes = 3.9e-04/3.0e-06: d. reduced by 0.00% (1.4963e-08) (took 0.28898 seconds)\n",
      "Step 3120: 2.46915e-03, stepsizes = 3.9e-04/3.0e-06: d. reduced by 0.00% (1.4820e-08) (took 0.21084 seconds)\n",
      "  Boundary too linear, increasing steps:     0.51 (100), 0.37 (30)\n",
      "Step 3130: 2.46900e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (1.4903e-08) (took 0.24630 seconds)\n",
      "Step 3140: 2.46883e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2286e-08) (took 0.16959 seconds)\n",
      "Step 3150: 2.46865e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2272e-08) (took 0.21016 seconds)\n",
      "Step 3160: 2.46845e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2341e-08) (took 0.18082 seconds)\n",
      "Step 3170: 2.46827e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2227e-08) (took 0.20841 seconds)\n",
      "Step 3180: 2.46809e-03, stepsizes = 5.9e-04/4.5e-06: d. reduced by 0.00% (2.2230e-08) (took 0.13019 seconds)\n",
      "Step 3190: 2.46803e-03, stepsizes = 5.9e-04/4.5e-06:  (took 0.16654 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.15 (100), 0.37 (30)\n",
      "Step 3200: 2.46791e-03, stepsizes = 3.9e-04/3.0e-06: d. reduced by 0.00% (2.2273e-08) (took 0.16692 seconds)\n",
      "Step 3210: 2.46779e-03, stepsizes = 3.9e-04/3.0e-06:  (took 0.16908 seconds)\n",
      "Step 3220: 2.46769e-03, stepsizes = 3.9e-04/3.0e-06: d. reduced by 0.00% (1.4865e-08) (took 0.19274 seconds)\n",
      "Step 3230: 2.46760e-03, stepsizes = 3.9e-04/3.0e-06:  (took 0.17959 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.13 (100), 0.33 (30)\n",
      "Step 3240: 2.46757e-03, stepsizes = 2.6e-04/2.0e-06:  (took 0.15171 seconds)\n",
      "Step 3250: 2.46751e-03, stepsizes = 2.6e-04/2.0e-06:  (took 0.18570 seconds)\n",
      "Step 3260: 2.46743e-03, stepsizes = 2.6e-04/2.0e-06:  (took 0.16665 seconds)\n",
      "Step 3270: 2.46737e-03, stepsizes = 2.6e-04/2.0e-06:  (took 0.17744 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.12 (100), 0.20 (30)\n",
      "Step 3280: 2.46730e-03, stepsizes = 1.7e-04/1.3e-06: d. reduced by 0.00% (9.8346e-09) (took 0.16401 seconds)\n",
      "Step 3290: 2.46723e-03, stepsizes = 1.7e-04/1.3e-06: d. reduced by 0.00% (6.6424e-09) (took 0.23955 seconds)\n",
      "  Success rate too high, increasing source step: 0.46 ( 50), 0.57 (30)\n",
      "Step 3300: 2.46716e-03, stepsizes = 1.7e-04/2.0e-06: d. reduced by 0.00% (6.6196e-09) (took 0.20438 seconds)\n",
      "Step 3310: 2.46709e-03, stepsizes = 1.7e-04/2.0e-06: d. reduced by 0.00% (9.9000e-09) (took 0.16705 seconds)\n",
      "Step 3320: 2.46703e-03, stepsizes = 1.7e-04/2.0e-06:  (took 0.19998 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.16 (100), 0.08 (12)\n",
      "Step 3330: 2.46698e-03, stepsizes = 1.2e-04/1.3e-06:  (took 0.21543 seconds)\n",
      "Step 3340: 2.46696e-03, stepsizes = 1.2e-04/1.3e-06:  (took 0.20461 seconds)\n",
      "Step 3350: 2.46694e-03, stepsizes = 1.2e-04/1.3e-06:  (took 0.18683 seconds)\n",
      "Step 3360: 2.46692e-03, stepsizes = 1.2e-04/1.3e-06: d. reduced by 0.00% (6.5753e-09) (took 0.22261 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.03 (30)\n",
      "  Success rate too low, decreasing source step:  0.19 (100), 0.03 (30)\n",
      "Step 3370: 2.46688e-03, stepsizes = 7.7e-05/5.9e-07:  (took 0.23769 seconds)\n",
      "Step 3380: 2.46685e-03, stepsizes = 7.7e-05/5.9e-07: d. reduced by 0.00% (2.9224e-09) (took 0.22898 seconds)\n",
      "Step 3390: 2.46682e-03, stepsizes = 7.7e-05/5.9e-07: d. reduced by 0.00% (2.8971e-09) (took 0.17690 seconds)\n",
      "Step 3400: 2.46679e-03, stepsizes = 7.7e-05/5.9e-07: d. reduced by 0.00% (2.9087e-09) (took 0.19924 seconds)\n",
      "  Success rate too high, increasing source step: 0.33 (100), 0.60 (30)\n",
      "Step 3410: 2.46677e-03, stepsizes = 7.7e-05/8.9e-07: d. reduced by 0.00% (2.8987e-09) (took 0.23198 seconds)\n",
      "Step 3420: 2.46674e-03, stepsizes = 7.7e-05/8.9e-07: d. reduced by 0.00% (4.3126e-09) (took 0.25139 seconds)\n",
      "Step 3430: 2.46672e-03, stepsizes = 7.7e-05/8.9e-07:  (took 0.17414 seconds)\n",
      "Step 3440: 2.46670e-03, stepsizes = 7.7e-05/8.9e-07:  (took 0.20194 seconds)\n",
      "Step 3450: 2.46668e-03, stepsizes = 7.7e-05/8.9e-07: d. reduced by 0.00% (4.4396e-09) (took 0.22696 seconds)\n",
      "Step 3460: 2.46667e-03, stepsizes = 7.7e-05/8.9e-07:  (took 0.22274 seconds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3470: 2.46666e-03, stepsizes = 7.7e-05/8.9e-07:  (took 0.17363 seconds)\n",
      "  Success rate too low, decreasing source step:  0.25 (100), 0.13 (30)\n",
      "Step 3480: 2.46665e-03, stepsizes = 7.7e-05/5.9e-07:  (took 0.22854 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.17 (100), 0.20 ( 5)\n",
      "Step 3490: 2.46662e-03, stepsizes = 5.1e-05/4.0e-07: d. reduced by 0.00% (2.9238e-09) (took 0.16063 seconds)\n",
      "Step 3500: 2.46661e-03, stepsizes = 5.1e-05/4.0e-07: d. reduced by 0.00% (1.9834e-09) (took 0.15173 seconds)\n",
      "Step 3510: 2.46659e-03, stepsizes = 5.1e-05/4.0e-07: d. reduced by 0.00% (1.9324e-09) (took 0.25503 seconds)\n",
      "  Success rate too high, increasing source step: 0.35 ( 75), 0.57 (30)\n",
      "Step 3520: 2.46658e-03, stepsizes = 5.1e-05/5.9e-07: d. reduced by 0.00% (2.0390e-09) (took 0.17533 seconds)\n",
      "Step 3530: 2.46656e-03, stepsizes = 5.1e-05/5.9e-07:  (took 0.28606 seconds)\n",
      "Step 3540: 2.46654e-03, stepsizes = 5.1e-05/5.9e-07:  (took 0.12067 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.12 (100), 0.00 ( 5)\n",
      "Step 3550: 2.46652e-03, stepsizes = 3.4e-05/4.0e-07:  (took 0.10813 seconds)\n",
      "Step 3560: 2.46651e-03, stepsizes = 3.4e-05/4.0e-07:  (took 0.16767 seconds)\n",
      "Step 3570: 2.46650e-03, stepsizes = 3.4e-05/4.0e-07: d. reduced by 0.00% (1.9472e-09) (took 0.22332 seconds)\n",
      "Step 3580: 2.46649e-03, stepsizes = 3.4e-05/4.0e-07:  (took 0.15894 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.12 (24)\n",
      "Step 3590: 2.46649e-03, stepsizes = 2.3e-05/2.6e-07:  (took 0.17359 seconds)\n",
      "Step 3600: 2.46648e-03, stepsizes = 2.3e-05/2.6e-07:  (took 0.16772 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 641.61021\n",
      "   3.0% for generation (19.16350)\n",
      "   10.7% for spherical prediction (68.37924)\n",
      "   76.4% for prediction (490.49564)\n",
      "   0.1% for hyperparameter update (0.36916)\n",
      "   9.9% for the rest (63.20267)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[2.11207543e-04 1.24871731e-04 9.02016958e-05 2.45115587e-05\n",
      " 3.53580051e-05 4.94519869e-05 8.93371210e-06 3.90149653e-05\n",
      " 2.15161982e-05 1.23999119e-04 2.43718959e-05 2.69313653e-05\n",
      " 2.34482556e-05 1.75249820e-05 1.44396888e-05 1.20447949e-05\n",
      " 1.10703769e-05 1.04094729e-05 1.06509042e-05 1.13989929e-05\n",
      " 1.05599074e-05 1.08958276e-05 7.77091331e-06 8.13934538e-06\n",
      " 8.68001710e-06]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.05250178 0.02781962 0.01936165 0.01519677 0.01170658 0.01024334\n",
      " 0.00884617 0.00788441 0.00797996 0.007426   0.00706609 0.00605582\n",
      " 0.00934424 0.00883261 0.00769593 0.00787009 0.00857013 0.00740995\n",
      " 0.00691973 0.00498205 0.00460502 0.00470802 0.00511053 0.00440684\n",
      " 0.0045871 ]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.3025   0.110625 0.065625 0.066875 0.050625 0.044375 0.035625 0.0375\n",
      " 0.029375 0.025625 0.026875 0.026875 0.015625 0.014375 0.014375 0.01125\n",
      " 0.01625  0.015    0.011875 0.010625 0.0125   0.01375  0.010625 0.011875\n",
      " 0.008125 0.01125 ]\n",
      "Using batch size   1, an average step would have taken 0.69225 = 0.00277 + 0.68948 seconds\n",
      "Using batch size   2, an average step would have taken 0.38562 = 0.00172 + 0.38390 seconds\n",
      "Using batch size   3, an average step would have taken 0.28096 = 0.00129 + 0.27967 seconds\n",
      "Using batch size   4, an average step would have taken 0.22941 = 0.00041 + 0.22900 seconds\n",
      "Using batch size   5, an average step would have taken 0.17327 = 0.00052 + 0.17275 seconds\n",
      "Using batch size   6, an average step would have taken 0.16919 = 0.00080 + 0.16839 seconds\n",
      "Using batch size   7, an average step would have taken 0.14645 = 0.00016 + 0.14629 seconds\n",
      "Using batch size   8, an average step would have taken 0.14125 = 0.00068 + 0.14057 seconds\n",
      "Using batch size   9, an average step would have taken 0.13408 = 0.00032 + 0.13376 seconds\n",
      "Using batch size  10, an average step would have taken 0.13479 = 0.00193 + 0.13286 seconds\n",
      "Using batch size  11, an average step would have taken 0.13491 = 0.00049 + 0.13442 seconds\n",
      "Using batch size  12, an average step would have taken 0.12343 = 0.00054 + 0.12289 seconds\n",
      "Using batch size  13, an average step would have taken 0.15463 = 0.00045 + 0.15418 seconds\n",
      "Using batch size  14, an average step would have taken 0.15788 = 0.00036 + 0.15752 seconds\n",
      "Using batch size  15, an average step would have taken 0.14770 = 0.00074 + 0.14695 seconds\n",
      "Using batch size  16, an average step would have taken 0.15550 = 0.00027 + 0.15523 seconds\n",
      "Using batch size  17, an average step would have taken 0.17080 = 0.00031 + 0.17049 seconds\n",
      "Using batch size  18, an average step would have taken 0.15720 = 0.00021 + 0.15699 seconds\n",
      "Using batch size  19, an average step would have taken 0.15457 = 0.00031 + 0.15425 seconds\n",
      "Using batch size  20, an average step would have taken 0.12089 = 0.00029 + 0.12060 seconds\n",
      "Using batch size  21, an average step would have taken 0.11789 = 0.00026 + 0.11764 seconds\n",
      "Using batch size  22, an average step would have taken 0.12329 = 0.00033 + 0.12296 seconds\n",
      "Using batch size  23, an average step would have taken 0.13571 = 0.00026 + 0.13545 seconds\n",
      "Using batch size  24, an average step would have taken 0.12250 = 0.00026 + 0.12224 seconds\n",
      "Using batch size  25, an average step would have taken 0.11489 = 0.00022 + 0.11468 seconds\n",
      "batch size was 25, optimal batch size would have been 25\n",
      "setting batch size to 25: expected step duration: 0.11489\n",
      "improvement compared to old batch size (25): 1.0x\n",
      "improvement compared to worst batch size (1): 6.0x\n",
      "improvement compared to smallest batch size (1): 6.0x\n",
      "improvement compared to largest batch size (25): 1.0x\n",
      "next batch size tuning in 3200 steps, after step 6800\n",
      "Step 3610: 2.46648e-03, stepsizes = 2.3e-05/2.6e-07:  (took 0.06782 seconds)\n",
      "Step 3620: 2.46648e-03, stepsizes = 2.3e-05/2.6e-07:  (took 0.16641 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.05 (100), 0.10 (29)\n",
      "Step 3630: 2.46648e-03, stepsizes = 1.5e-05/1.8e-07:  (took 0.15487 seconds)\n",
      "  Success rate too low, decreasing source step:  0.12 ( 25), 0.10 (30)\n",
      "Step 3640: 2.46648e-03, stepsizes = 1.5e-05/1.2e-07:  (took 0.18149 seconds)\n",
      "Step 3650: 2.46647e-03, stepsizes = 1.5e-05/1.2e-07:  (took 0.25419 seconds)\n",
      "Step 3660: 2.46647e-03, stepsizes = 1.5e-05/1.2e-07:  (took 0.19467 seconds)\n",
      "Step 3670: 2.46646e-03, stepsizes = 1.5e-05/1.2e-07:  (took 0.21484 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.18 (100), 0.00 (18)\n",
      "Step 3680: 2.46646e-03, stepsizes = 1.0e-05/7.8e-08:  (took 0.15264 seconds)\n",
      "Step 3680: 2.46646e-03, stepsizes = 1.0e-05/7.8e-08: \n",
      "Looks like attack has converged after 3681 steps for the first time. Resetting steps to be sure.\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.00 (18)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.00 (19)\n",
      "Step 3690: 2.46646e-03, stepsizes = 4.4e-03/4.4e-03:  (took 0.10655 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.00 (20)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.00 (21)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.00 (22)\n",
      "Step 3700: 2.46646e-03, stepsizes = 1.3e-03/1.3e-03:  (took 0.12303 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.00 (23)\n",
      "  Boundary too non-linear, decreasing steps: 0.02 (100), 0.00 (25)\n",
      "Step 3710: 2.46646e-03, stepsizes = 5.9e-04/5.9e-04:  (took 0.16937 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.05 (100), 0.00 (30)\n",
      "  Success rate too low, decreasing source step:  0.05 (100), 0.00 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.02 (100), 0.00 ( 2)\n",
      "  Boundary too non-linear, decreasing steps: 0.02 (100), 0.00 ( 4)\n",
      "Step 3720: 2.46646e-03, stepsizes = 1.7e-04/1.2e-04:  (took 0.17269 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.05 (100), 0.00 ( 9)\n",
      "  Boundary too non-linear, decreasing steps: 0.04 (100), 0.00 (13)\n",
      "Step 3730: 2.46646e-03, stepsizes = 7.7e-05/5.1e-05:  (took 0.13041 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.11 (100), 0.00 (24)\n",
      "  Boundary too non-linear, decreasing steps: 0.06 (100), 0.00 (30)\n",
      "  Success rate too low, decreasing source step:  0.06 (100), 0.00 (30)\n",
      "  Boundary too non-linear, decreasing steps: 0.04 (100), 0.00 ( 4)\n",
      "Step 3740: 2.46646e-03, stepsizes = 2.3e-05/1.0e-05:  (took 0.10668 seconds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Boundary too non-linear, decreasing steps: 0.08 (100), 0.00 (12)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.00 (13)\n",
      "Step 3750: 2.46646e-03, stepsizes = 1.0e-05/4.5e-06:  (took 0.12884 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.00 (100), 0.00 (13)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.00 (14)\n",
      "  Boundary too non-linear, decreasing steps: 0.03 (100), 0.00 (17)\n",
      "Step 3760: 2.46646e-03, stepsizes = 3.0e-06/1.3e-06:  (took 0.17708 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.00 (18)\n",
      "  Boundary too non-linear, decreasing steps: 0.02 (100), 0.00 (20)\n",
      "Step 3770: 2.46646e-03, stepsizes = 1.3e-06/5.9e-07:  (took 0.18726 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.02 (100), 0.00 (22)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.00 (23)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.00 (24)\n",
      "Step 3780: 2.46646e-03, stepsizes = 4.0e-07/1.8e-07:  (took 0.11583 seconds)\n",
      "  Boundary too non-linear, decreasing steps: 0.01 (100), 0.00 (25)\n",
      "  Boundary too non-linear, decreasing steps: 0.05 (100), 0.00 (30)\n",
      "  Success rate too low, decreasing source step:  0.05 (100), 0.00 (30)\n",
      "Step 3788: 2.46646e-03, stepsizes = 1.8e-07/5.2e-08: \n",
      "Looks like attack has converged after 3789 steps, 100 remaining\n",
      "Step 3789: 2.46646e-03, stepsizes = 1.8e-07/5.2e-08: \n",
      "Looks like attack has converged after 3790 steps, 99 remaining\n",
      "Step 3790: 2.46646e-03, stepsizes = 1.8e-07/5.2e-08:  (took 0.16127 seconds)\n",
      "Step 3790: 2.46646e-03, stepsizes = 1.8e-07/5.2e-08: \n",
      "Looks like attack has converged after 3791 steps, 98 remaining\n",
      "Step 3791: 2.46646e-03, stepsizes = 1.8e-07/5.2e-08: \n",
      "Looks like attack has converged after 3792 steps, 97 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.13 (100), 0.00 (13)\n",
      "Step 3792: 2.46646e-03, stepsizes = 1.2e-07/3.5e-08: \n",
      "Looks like attack has converged after 3793 steps, 96 remaining\n",
      "Step 3793: 2.46646e-03, stepsizes = 1.2e-07/3.5e-08: \n",
      "Looks like attack has converged after 3794 steps, 95 remaining\n",
      "Step 3794: 2.46646e-03, stepsizes = 1.2e-07/3.5e-08: \n",
      "Looks like attack has converged after 3795 steps, 94 remaining\n",
      "Step 3795: 2.46646e-03, stepsizes = 1.2e-07/3.5e-08: \n",
      "Looks like attack has converged after 3796 steps, 93 remaining\n",
      "  Success rate too low, decreasing source step:  0.20 (100), 0.00 (30)\n",
      "Step 3796: 2.46646e-03, stepsizes = 1.2e-07/2.3e-08: \n",
      "Looks like attack has converged after 3797 steps, 92 remaining\n",
      "Step 3797: 2.46646e-03, stepsizes = 1.2e-07/2.3e-08: \n",
      "Looks like attack has converged after 3798 steps, 91 remaining\n",
      "Step 3798: 2.46646e-03, stepsizes = 1.2e-07/2.3e-08: \n",
      "Looks like attack has converged after 3799 steps, 90 remaining\n",
      "Step 3799: 2.46646e-03, stepsizes = 1.2e-07/2.3e-08: \n",
      "Looks like attack has converged after 3800 steps, 89 remaining\n",
      "  Boundary too non-linear, decreasing steps: 0.19 (100), 0.00 (19)\n",
      "Step 3800: 2.46646e-03, stepsizes = 7.8e-08/1.5e-08:  (took 0.14865 seconds)\n",
      "Step 3800: 2.46646e-03, stepsizes = 7.8e-08/1.5e-08: \n",
      "Looks like attack has converged after 3801 steps, 88 remaining\n",
      "Step 3801: 2.46646e-03, stepsizes = 7.8e-08/1.5e-08: \n",
      "Looks like attack has converged after 3802 steps, 87 remaining\n",
      "  Success rate too low, decreasing source step:  0.36 ( 50), 0.00 (30)\n",
      "Step 3802: 2.46646e-03, stepsizes = 7.8e-08/1.0e-08: \n",
      "Looks like attack has converged after 3803 steps, 86 remaining\n",
      "Step 3803: 2.46646e-03, stepsizes = 7.8e-08/1.0e-08: \n",
      "Looks like attack has converged after 3804 steps, 85 remaining\n",
      "Step 3804: 2.46646e-03, stepsizes = 7.8e-08/1.0e-08: \n",
      "Looks like attack has converged after 3805 steps, 84 remaining\n",
      "Step 3805: 2.46646e-03, stepsizes = 7.8e-08/1.0e-08: \n",
      "Looks like attack has converged after 3806 steps, 83 remaining\n",
      "Step 3806: 2.46646e-03, stepsizes = 7.8e-08/1.0e-08: \n",
      "Looks like attack has converged after 3807 steps, 82 remaining\n",
      "  Success rate too low, decreasing source step:  0.28 (100), 0.00 (30)\n",
      "Step 3807: 2.46646e-03, stepsizes = 7.8e-08/6.9e-09: \n",
      "Looks like attack has converged after 3808 steps, 81 remaining\n",
      "Step 3808: 2.46646e-03, stepsizes = 7.8e-08/6.9e-09: \n",
      "Looks like attack has converged after 3809 steps, 80 remaining\n",
      "Step 3809: 2.46646e-03, stepsizes = 7.8e-08/6.9e-09: \n",
      "Looks like attack has converged after 3810 steps, 79 remaining\n",
      "Step 3810: 2.46646e-03, stepsizes = 7.8e-08/6.9e-09:  (took 0.22233 seconds)\n",
      "Step 3810: 2.46646e-03, stepsizes = 7.8e-08/6.9e-09: \n",
      "Looks like attack has converged after 3811 steps, 78 remaining\n",
      "  Success rate too low, decreasing source step:  0.34 (100), 0.00 (30)\n",
      "Step 3811: 2.46646e-03, stepsizes = 7.8e-08/4.6e-09: \n",
      "Looks like attack has converged after 3812 steps, 77 remaining\n",
      "Step 3812: 2.46646e-03, stepsizes = 7.8e-08/4.6e-09: \n",
      "Looks like attack has converged after 3813 steps, 76 remaining\n",
      "Step 3813: 2.46646e-03, stepsizes = 7.8e-08/4.6e-09: \n",
      "Looks like attack has converged after 3814 steps, 75 remaining\n",
      "Step 3814: 2.46646e-03, stepsizes = 7.8e-08/4.6e-09: \n",
      "Looks like attack has converged after 3815 steps, 74 remaining\n",
      "  Success rate too low, decreasing source step:  0.38 (100), 0.00 (30)\n",
      "Step 3815: 2.46646e-03, stepsizes = 7.8e-08/3.1e-09: \n",
      "Looks like attack has converged after 3816 steps, 73 remaining\n",
      "Step 3816: 2.46646e-03, stepsizes = 7.8e-08/3.1e-09: \n",
      "Looks like attack has converged after 3817 steps, 72 remaining\n",
      "Step 3817: 2.46646e-03, stepsizes = 7.8e-08/3.1e-09: \n",
      "Looks like attack has converged after 3818 steps, 71 remaining\n",
      "Step 3818: 2.46646e-03, stepsizes = 7.8e-08/3.1e-09: \n",
      "Looks like attack has converged after 3819 steps, 70 remaining\n",
      "  Success rate too low, decreasing source step:  0.34 (100), 0.00 (30)\n",
      "Step 3819: 2.46646e-03, stepsizes = 7.8e-08/2.0e-09: \n",
      "Looks like attack has converged after 3820 steps, 69 remaining\n",
      "Step 3820: 2.46646e-03, stepsizes = 7.8e-08/2.0e-09:  (took 0.17396 seconds)\n",
      "Step 3820: 2.46646e-03, stepsizes = 7.8e-08/2.0e-09: \n",
      "Looks like attack has converged after 3821 steps, 68 remaining\n",
      "Step 3821: 2.46646e-03, stepsizes = 7.8e-08/2.0e-09: \n",
      "Looks like attack has converged after 3822 steps, 67 remaining\n",
      "Step 3822: 2.46646e-03, stepsizes = 7.8e-08/2.0e-09: \n",
      "Looks like attack has converged after 3823 steps, 66 remaining\n",
      "  Success rate too low, decreasing source step:  0.33 (100), 0.00 (30)\n",
      "Step 3823: 2.46646e-03, stepsizes = 7.8e-08/1.4e-09: \n",
      "Looks like attack has converged after 3824 steps, 65 remaining\n",
      "Step 3824: 2.46646e-03, stepsizes = 7.8e-08/1.4e-09: \n",
      "Looks like attack has converged after 3825 steps, 64 remaining\n",
      "Step 3825: 2.46646e-03, stepsizes = 7.8e-08/1.4e-09: \n",
      "Looks like attack has converged after 3826 steps, 63 remaining\n",
      "Step 3826: 2.46646e-03, stepsizes = 7.8e-08/1.4e-09: \n",
      "Looks like attack has converged after 3827 steps, 62 remaining\n",
      "  Success rate too low, decreasing source step:  0.35 (100), 0.00 (30)\n",
      "Step 3827: 2.46646e-03, stepsizes = 7.8e-08/9.0e-10: \n",
      "Looks like attack has converged after 3828 steps, 61 remaining\n",
      "Step 3828: 2.46646e-03, stepsizes = 7.8e-08/9.0e-10: \n",
      "Looks like attack has converged after 3829 steps, 60 remaining\n",
      "Step 3829: 2.46646e-03, stepsizes = 7.8e-08/9.0e-10: \n",
      "Looks like attack has converged after 3830 steps, 59 remaining\n",
      "  Success rate too low, decreasing source step:  0.38 (100), 0.00 (30)\n",
      "Step 3830: 2.46646e-03, stepsizes = 7.8e-08/6.0e-10:  (took 0.16779 seconds)\n",
      "Step 3830: 2.46646e-03, stepsizes = 7.8e-08/6.0e-10: \n",
      "Looks like attack has converged after 3831 steps, 58 remaining\n",
      "Step 3831: 2.46646e-03, stepsizes = 7.8e-08/6.0e-10: \n",
      "Looks like attack has converged after 3832 steps, 57 remaining\n",
      "Step 3832: 2.46646e-03, stepsizes = 7.8e-08/6.0e-10: \n",
      "Looks like attack has converged after 3833 steps, 56 remaining\n",
      "  Success rate too low, decreasing source step:  0.35 (100), 0.00 (30)\n",
      "Step 3833: 2.46646e-03, stepsizes = 7.8e-08/4.0e-10: \n",
      "Looks like attack has converged after 3834 steps, 55 remaining\n",
      "Step 3834: 2.46646e-03, stepsizes = 7.8e-08/4.0e-10: \n",
      "Looks like attack has converged after 3835 steps, 54 remaining\n",
      "Step 3835: 2.46646e-03, stepsizes = 7.8e-08/4.0e-10: \n",
      "Looks like attack has converged after 3836 steps, 53 remaining\n",
      "Step 3836: 2.46646e-03, stepsizes = 7.8e-08/4.0e-10: \n",
      "Looks like attack has converged after 3837 steps, 52 remaining\n",
      "  Success rate too low, decreasing source step:  0.32 (100), 0.00 (30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3837: 2.46646e-03, stepsizes = 7.8e-08/2.7e-10: \n",
      "Looks like attack has converged after 3838 steps, 51 remaining\n",
      "Step 3838: 2.46646e-03, stepsizes = 7.8e-08/2.7e-10: \n",
      "Looks like attack has converged after 3839 steps, 50 remaining\n",
      "Step 3839: 2.46646e-03, stepsizes = 7.8e-08/2.7e-10: \n",
      "Looks like attack has converged after 3840 steps, 49 remaining\n",
      "Step 3840: 2.46646e-03, stepsizes = 7.8e-08/2.7e-10:  (took 0.21304 seconds)\n",
      "Step 3840: 2.46646e-03, stepsizes = 7.8e-08/2.7e-10: \n",
      "Looks like attack has converged after 3841 steps, 48 remaining\n",
      "  Success rate too low, decreasing source step:  0.39 (100), 0.00 (30)\n",
      "Step 3841: 2.46646e-03, stepsizes = 7.8e-08/1.8e-10: \n",
      "Looks like attack has converged after 3842 steps, 47 remaining\n",
      "Step 3842: 2.46646e-03, stepsizes = 7.8e-08/1.8e-10: \n",
      "Looks like attack has converged after 3843 steps, 46 remaining\n",
      "Step 3843: 2.46646e-03, stepsizes = 7.8e-08/1.8e-10: \n",
      "Looks like attack has converged after 3844 steps, 45 remaining\n",
      "Step 3844: 2.46646e-03, stepsizes = 7.8e-08/1.8e-10: \n",
      "Looks like attack has converged after 3845 steps, 44 remaining\n",
      "  Success rate too low, decreasing source step:  0.37 (100), 0.00 (30)\n",
      "Step 3845: 2.46646e-03, stepsizes = 7.8e-08/1.2e-10: \n",
      "Looks like attack has converged after 3846 steps, 43 remaining\n",
      "Step 3846: 2.46646e-03, stepsizes = 7.8e-08/1.2e-10: \n",
      "Looks like attack has converged after 3847 steps, 42 remaining\n",
      "Step 3847: 2.46646e-03, stepsizes = 7.8e-08/1.2e-10: \n",
      "Looks like attack has converged after 3848 steps, 41 remaining\n",
      "Step 3848: 2.46646e-03, stepsizes = 7.8e-08/1.2e-10: \n",
      "Looks like attack has converged after 3849 steps, 40 remaining\n",
      "  Success rate too low, decreasing source step:  0.31 (100), 0.00 (30)\n",
      "Step 3849: 2.46646e-03, stepsizes = 7.8e-08/7.9e-11: \n",
      "Looks like attack has converged after 3850 steps, 39 remaining\n",
      "Step 3850: 2.46646e-03, stepsizes = 7.8e-08/7.9e-11:  (took 0.19512 seconds)\n",
      "Step 3850: 2.46646e-03, stepsizes = 7.8e-08/7.9e-11: \n",
      "Looks like attack has converged after 3851 steps, 38 remaining\n",
      "Step 3851: 2.46646e-03, stepsizes = 7.8e-08/7.9e-11: \n",
      "Looks like attack has converged after 3852 steps, 37 remaining\n",
      "Step 3852: 2.46646e-03, stepsizes = 7.8e-08/7.9e-11: \n",
      "Looks like attack has converged after 3853 steps, 36 remaining\n",
      "  Success rate too low, decreasing source step:  0.37 (100), 0.00 (30)\n",
      "Step 3853: 2.46646e-03, stepsizes = 7.8e-08/5.3e-11: \n",
      "Looks like attack has converged after 3854 steps, 35 remaining\n",
      "Step 3854: 2.46646e-03, stepsizes = 7.8e-08/5.3e-11: \n",
      "Looks like attack has converged after 3855 steps, 34 remaining\n",
      "Step 3855: 2.46646e-03, stepsizes = 7.8e-08/5.3e-11: \n",
      "Looks like attack has converged after 3856 steps, 33 remaining\n",
      "Step 3856: 2.46646e-03, stepsizes = 7.8e-08/5.3e-11: \n",
      "Looks like attack has converged after 3857 steps, 32 remaining\n",
      "  Success rate too low, decreasing source step:  0.31 (100), 0.00 (30)\n",
      "Step 3857: 2.46646e-03, stepsizes = 7.8e-08/3.5e-11: \n",
      "Looks like attack has converged after 3858 steps, 31 remaining\n",
      "Step 3858: 2.46646e-03, stepsizes = 7.8e-08/3.5e-11: \n",
      "Looks like attack has converged after 3859 steps, 30 remaining\n",
      "Step 3859: 2.46646e-03, stepsizes = 7.8e-08/3.5e-11: \n",
      "Looks like attack has converged after 3860 steps, 29 remaining\n",
      "Step 3860: 2.46646e-03, stepsizes = 7.8e-08/3.5e-11:  (took 0.18365 seconds)\n",
      "Step 3860: 2.46646e-03, stepsizes = 7.8e-08/3.5e-11: \n",
      "Looks like attack has converged after 3861 steps, 28 remaining\n",
      "  Success rate too low, decreasing source step:  0.35 (100), 0.00 (30)\n",
      "Step 3861: 2.46646e-03, stepsizes = 7.8e-08/2.4e-11: \n",
      "Looks like attack has converged after 3862 steps, 27 remaining\n",
      "Step 3862: 2.46646e-03, stepsizes = 7.8e-08/2.4e-11: \n",
      "Looks like attack has converged after 3863 steps, 26 remaining\n",
      "Step 3863: 2.46646e-03, stepsizes = 7.8e-08/2.4e-11: \n",
      "Looks like attack has converged after 3864 steps, 25 remaining\n",
      "Step 3864: 2.46646e-03, stepsizes = 7.8e-08/2.4e-11: \n",
      "Looks like attack has converged after 3865 steps, 24 remaining\n",
      "  Success rate too low, decreasing source step:  0.34 (100), 0.00 (30)\n",
      "Step 3865: 2.46646e-03, stepsizes = 7.8e-08/1.6e-11: \n",
      "Looks like attack has converged after 3866 steps, 23 remaining\n",
      "Step 3866: 2.46646e-03, stepsizes = 7.8e-08/1.6e-11: \n",
      "Looks like attack has converged after 3867 steps, 22 remaining\n",
      "Step 3867: 2.46646e-03, stepsizes = 7.8e-08/1.6e-11: \n",
      "Looks like attack has converged after 3868 steps, 21 remaining\n",
      "  Success rate too low, decreasing source step:  0.40 (100), 0.00 (30)\n",
      "Step 3868: 2.46646e-03, stepsizes = 7.8e-08/1.0e-11: \n",
      "Looks like attack has converged after 3869 steps, 20 remaining\n",
      "Step 3869: 2.46646e-03, stepsizes = 7.8e-08/1.0e-11: \n",
      "Looks like attack has converged after 3870 steps, 19 remaining\n",
      "Step 3870: 2.46646e-03, stepsizes = 7.8e-08/1.0e-11:  (took 0.16640 seconds)\n",
      "Step 3870: 2.46646e-03, stepsizes = 7.8e-08/1.0e-11: \n",
      "Looks like attack has converged after 3871 steps, 18 remaining\n",
      "  Success rate too low, decreasing source step:  0.43 (100), 0.00 (30)\n",
      "Step 3871: 2.46646e-03, stepsizes = 7.8e-08/7.0e-12: \n",
      "Looks like attack has converged after 3872 steps, 17 remaining\n",
      "Step 3872: 2.46646e-03, stepsizes = 7.8e-08/7.0e-12: \n",
      "Looks like attack has converged after 3873 steps, 16 remaining\n",
      "Step 3873: 2.46646e-03, stepsizes = 7.8e-08/7.0e-12: \n",
      "Looks like attack has converged after 3874 steps, 15 remaining\n",
      "Step 3874: 2.46646e-03, stepsizes = 7.8e-08/7.0e-12: \n",
      "Looks like attack has converged after 3875 steps, 14 remaining\n",
      "Step 3875: 2.46646e-03, stepsizes = 7.8e-08/7.0e-12: \n",
      "Looks like attack has converged after 3876 steps, 13 remaining\n",
      "  Success rate too low, decreasing source step:  0.27 (100), 0.00 (30)\n",
      "Step 3876: 2.46646e-03, stepsizes = 7.8e-08/4.6e-12: \n",
      "Looks like attack has converged after 3877 steps, 12 remaining\n",
      "Step 3877: 2.46646e-03, stepsizes = 7.8e-08/4.6e-12: \n",
      "Looks like attack has converged after 3878 steps, 11 remaining\n",
      "Step 3878: 2.46646e-03, stepsizes = 7.8e-08/4.6e-12: \n",
      "Looks like attack has converged after 3879 steps, 10 remaining\n",
      "Step 3879: 2.46646e-03, stepsizes = 7.8e-08/4.6e-12: \n",
      "Looks like attack has converged after 3880 steps, 9 remaining\n",
      "  Success rate too low, decreasing source step:  0.32 (100), 0.00 (30)\n",
      "Step 3880: 2.46646e-03, stepsizes = 7.8e-08/3.1e-12:  (took 0.20324 seconds)\n",
      "Step 3880: 2.46646e-03, stepsizes = 7.8e-08/3.1e-12: \n",
      "Looks like attack has converged after 3881 steps, 8 remaining\n",
      "Step 3881: 2.46646e-03, stepsizes = 7.8e-08/3.1e-12: \n",
      "Looks like attack has converged after 3882 steps, 7 remaining\n",
      "Step 3882: 2.46646e-03, stepsizes = 7.8e-08/3.1e-12: \n",
      "Looks like attack has converged after 3883 steps, 6 remaining\n",
      "Step 3883: 2.46646e-03, stepsizes = 7.8e-08/3.1e-12: \n",
      "Looks like attack has converged after 3884 steps, 5 remaining\n",
      "  Success rate too low, decreasing source step:  0.33 (100), 0.00 (30)\n",
      "Step 3884: 2.46646e-03, stepsizes = 7.8e-08/2.1e-12: \n",
      "Looks like attack has converged after 3885 steps, 4 remaining\n",
      "Step 3885: 2.46646e-03, stepsizes = 7.8e-08/2.1e-12: \n",
      "Looks like attack has converged after 3886 steps, 3 remaining\n",
      "Step 3886: 2.46646e-03, stepsizes = 7.8e-08/2.1e-12: \n",
      "Looks like attack has converged after 3887 steps, 2 remaining\n",
      "Step 3887: 2.46646e-03, stepsizes = 7.8e-08/2.1e-12: \n",
      "Looks like attack has converged after 3888 steps, 1 remaining\n",
      "Time since beginning: 686.80882\n",
      "   3.0% for generation (20.71967)\n",
      "   13.5% for spherical prediction (92.64817)\n",
      "   72.6% for prediction (498.77460)\n",
      "   0.1% for hyperparameter update (0.40784)\n",
      "   10.8% for the rest (74.25854)\n",
      "Neither starting_point nor initialization_attack given. Falling back to BlendedUniformNoiseAttack for initialization.\n",
      "Initial spherical_step = 0.01, source_step = 0.01\n",
      "Using 4 threads to create random numbers\n",
      "Step 0: 7.56810e-02, stepsizes = 1.0e-02/1.0e-02: \n",
      "Step 10: 7.56810e-02, stepsizes = 1.0e-02/1.0e-02:  (took 3.54774 seconds)\n",
      "Step 20: 7.56810e-02, stepsizes = 1.0e-02/1.0e-02:  (took 3.09893 seconds)\n",
      "  Success rate too low, decreasing source step:  0.60 ( 75), 0.00 (30)\n",
      "Step 30: 7.56810e-02, stepsizes = 1.0e-02/6.7e-03:  (took 3.20189 seconds)\n",
      "  Boundary too linear, increasing steps:     0.63 (100), 0.00 (18)\n",
      "Step 40: 7.56810e-02, stepsizes = 1.5e-02/1.0e-02:  (took 3.59080 seconds)\n",
      "  Success rate too low, decreasing source step:  0.48 ( 25), 0.00 (30)\n",
      "Step 50: 7.56810e-02, stepsizes = 1.5e-02/6.7e-03:  (took 2.93751 seconds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 60: 7.46753e-02, stepsizes = 1.5e-02/6.7e-03:  (took 2.44190 seconds)\n",
      "Step 70: 7.36830e-02, stepsizes = 1.5e-02/6.7e-03:  (took 3.04779 seconds)\n",
      "  Boundary too linear, increasing steps:     0.53 (100), 0.00 (30)\n",
      "  Success rate too low, decreasing source step:  0.53 (100), 0.00 (30)\n",
      "Step 80: 7.36830e-02, stepsizes = 2.2e-02/6.7e-03:  (took 3.19784 seconds)\n",
      "Step 90: 7.27038e-02, stepsizes = 2.2e-02/6.7e-03:  (took 3.24510 seconds)\n",
      "Step 100: 6.62045e-02, stepsizes = 2.2e-02/6.7e-03: d. reduced by 1.33% (8.9163e-04) (took 1.17970 seconds)\n",
      "Initializing generation and prediction time measurements. This can take a few seconds.\n",
      "During initialization, a better adversarial has been found. Continuing from there.\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 290.45166\n",
      "   1.3% for generation (3.65606)\n",
      "   17.3% for spherical prediction (50.37973)\n",
      "   69.0% for prediction (200.34252)\n",
      "   0.0% for hyperparameter update (0.01289)\n",
      "   12.4% for the rest (36.06046)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[1.52238329e-03 1.19566917e-04 1.25726064e-04 9.20146704e-05\n",
      " 7.66658783e-05 6.23464584e-05 4.60926367e-05 4.72739339e-05\n",
      " 4.36335434e-05 3.18360329e-05 5.73150383e-05 2.86549330e-05\n",
      " 2.06309663e-05 1.99420112e-05 1.51496463e-05 1.84783712e-05\n",
      " 1.75464525e-05 1.37017097e-05 1.36717535e-05 1.25730038e-05\n",
      " 1.31443785e-05 1.46026454e-05 1.05097974e-05 1.56035854e-05\n",
      " 1.37149811e-05]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.08037698 0.042579   0.0471059  0.03771015 0.02960902 0.02709831\n",
      " 0.02324498 0.02105022 0.02041775 0.01886704 0.01681884 0.01617043\n",
      " 0.01538317 0.01643433 0.0136443  0.01901597 0.0180782  0.01891029\n",
      " 0.01849672 0.01070817 0.00959999 0.00784459 0.00807538 0.00858611\n",
      " 0.00888594]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.9  0.01 0.   0.02 0.01 0.01 0.   0.   0.   0.01 0.01 0.   0.01 0.\n",
      " 0.   0.   0.   0.01 0.   0.   0.01 0.   0.   0.   0.   0.  ]\n",
      "Using batch size   1, an average step would have taken 1.91153 = 0.03553 + 1.87600 seconds\n",
      "Using batch size   2, an average step would have taken 1.03443 = 0.00406 + 1.03037 seconds\n",
      "Using batch size   3, an average step would have taken 1.13784 = 0.00420 + 1.13364 seconds\n",
      "Using batch size   4, an average step would have taken 0.92804 = 0.00345 + 0.92459 seconds\n",
      "Using batch size   5, an average step would have taken 0.69761 = 0.00180 + 0.69581 seconds\n",
      "Using batch size   6, an average step would have taken 0.68971 = 0.00278 + 0.68693 seconds\n",
      "Using batch size   7, an average step would have taken 0.60401 = 0.00126 + 0.60275 seconds\n",
      "Using batch size   8, an average step would have taken 0.55811 = 0.00246 + 0.55565 seconds\n",
      "Using batch size   9, an average step would have taken 0.50562 = 0.00106 + 0.50456 seconds\n",
      "Using batch size  10, an average step would have taken 0.49833 = 0.00096 + 0.49737 seconds\n",
      "Using batch size  11, an average step would have taken 0.48581 = 0.00156 + 0.48425 seconds\n",
      "Using batch size  12, an average step would have taken 0.44694 = 0.00203 + 0.44491 seconds\n",
      "Using batch size  13, an average step would have taken 0.37909 = 0.00058 + 0.37850 seconds\n",
      "Using batch size  14, an average step would have taken 0.40115 = 0.00086 + 0.40029 seconds\n",
      "Using batch size  15, an average step would have taken 0.37876 = 0.00052 + 0.37824 seconds\n",
      "Using batch size  16, an average step would have taken 0.47397 = 0.00066 + 0.47331 seconds\n",
      "Using batch size  17, an average step would have taken 0.46122 = 0.00064 + 0.46058 seconds\n",
      "Using batch size  18, an average step would have taken 0.48900 = 0.00054 + 0.48846 seconds\n",
      "Using batch size  19, an average step would have taken 0.49999 = 0.00060 + 0.49939 seconds\n",
      "Using batch size  20, an average step would have taken 0.34800 = 0.00060 + 0.34740 seconds\n",
      "Using batch size  21, an average step would have taken 0.33796 = 0.00061 + 0.33736 seconds\n",
      "Using batch size  22, an average step would have taken 0.30043 = 0.00066 + 0.29977 seconds\n",
      "Using batch size  23, an average step would have taken 0.26283 = 0.00046 + 0.26238 seconds\n",
      "Using batch size  24, an average step would have taken 0.28015 = 0.00174 + 0.27841 seconds\n",
      "Using batch size  25, an average step would have taken 0.22249 = 0.00034 + 0.22215 seconds\n",
      "batch size was 1, optimal batch size would have been 25\n",
      "setting batch size to 25: expected step duration: 0.22249\n",
      "improvement compared to old batch size (1): 8.6x\n",
      "improvement compared to worst batch size (1): 8.6x\n",
      "improvement compared to smallest batch size (1): 8.6x\n",
      "improvement compared to largest batch size (25): 1.0x\n",
      "next batch size tuning in 100 steps, after step 200\n",
      "  Success rate too low, decreasing source step:  0.51 ( 59), 0.03 (30)\n",
      "Step 110: 6.44566e-02, stepsizes = 2.2e-02/4.4e-03:  (took 0.62352 seconds)\n",
      "Step 120: 5.94903e-02, stepsizes = 2.2e-02/4.4e-03: d. reduced by 0.89% (5.3235e-04) (took 0.66545 seconds)\n",
      "  Boundary too linear, increasing steps:     0.58 (100), 0.27 (30)\n",
      "Step 130: 5.53980e-02, stepsizes = 3.4e-02/6.7e-03:  (took 0.56266 seconds)\n",
      "  Success rate too low, decreasing source step:  0.64 ( 25), 0.03 (30)\n",
      "Step 140: 4.97754e-02, stepsizes = 3.4e-02/4.4e-03: d. reduced by 1.33% (6.7037e-04) (took 0.56829 seconds)\n",
      "Step 150: 4.55328e-02, stepsizes = 3.4e-02/4.4e-03: d. reduced by 0.89% (4.0745e-04) (took 0.58661 seconds)\n",
      "Step 160: 4.16519e-02, stepsizes = 3.4e-02/4.4e-03: d. reduced by 0.89% (3.7272e-04) (took 0.59902 seconds)\n",
      "  Boundary too linear, increasing steps:     0.71 (100), 0.47 (30)\n",
      "Step 170: 3.87867e-02, stepsizes = 5.1e-02/6.7e-03: d. reduced by 0.89% (3.4708e-04) (took 0.91853 seconds)\n",
      "Step 180: 3.43869e-02, stepsizes = 5.1e-02/6.7e-03: d. reduced by 1.33% (4.6312e-04) (took 0.73400 seconds)\n",
      "  Success rate too low, decreasing source step:  0.60 ( 50), 0.17 (30)\n",
      "Step 190: 3.04862e-02, stepsizes = 5.1e-02/4.4e-03: d. reduced by 1.33% (4.1058e-04) (took 0.70300 seconds)\n",
      "Step 200: 2.78877e-02, stepsizes = 5.1e-02/4.4e-03: d. reduced by 0.89% (2.4955e-04) (took 0.81289 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 325.57032\n",
      "   1.3% for generation (4.34750)\n",
      "   16.6% for spherical prediction (54.09321)\n",
      "   70.0% for prediction (227.85945)\n",
      "   0.0% for hyperparameter update (0.02081)\n",
      "   12.1% for the rest (39.24934)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[1.52238329e-03 1.19566917e-04 1.25726064e-04 9.20146704e-05\n",
      " 7.66658783e-05 6.23464584e-05 4.60926367e-05 4.72739339e-05\n",
      " 4.36335434e-05 3.18360329e-05 5.73150383e-05 2.86549330e-05\n",
      " 2.06309663e-05 1.99420112e-05 1.51496463e-05 1.84783712e-05\n",
      " 1.75464525e-05 1.37017097e-05 1.36717535e-05 1.25730038e-05\n",
      " 1.31443785e-05 1.46026454e-05 1.05097974e-05 1.56035854e-05\n",
      " 1.10891625e-05]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.08037698 0.042579   0.0471059  0.03771015 0.02960902 0.02709831\n",
      " 0.02324498 0.02105022 0.02041775 0.01886704 0.01681884 0.01617043\n",
      " 0.01538317 0.01643433 0.0136443  0.01901597 0.0180782  0.01891029\n",
      " 0.01849672 0.01070817 0.00959999 0.00784459 0.00807538 0.00858611\n",
      " 0.01208746]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.17 0.24 0.09 0.06 0.05 0.05 0.03 0.06 0.04 0.02 0.03 0.   0.03 0.03\n",
      " 0.05 0.   0.   0.01 0.   0.01 0.   0.   0.01 0.   0.01 0.01]\n",
      "Using batch size   1, an average step would have taken 0.75511 = 0.01404 + 0.74108 seconds\n",
      "Using batch size   2, an average step would have taken 0.42123 = 0.00141 + 0.41982 seconds\n",
      "Using batch size   3, an average step would have taken 0.49367 = 0.00155 + 0.49212 seconds\n",
      "Using batch size   4, an average step would have taken 0.41696 = 0.00125 + 0.41570 seconds\n",
      "Using batch size   5, an average step would have taken 0.33545 = 0.00087 + 0.33458 seconds\n",
      "Using batch size   6, an average step would have taken 0.33904 = 0.00102 + 0.33802 seconds\n",
      "Using batch size   7, an average step would have taken 0.29762 = 0.00060 + 0.29702 seconds\n",
      "Using batch size   8, an average step would have taken 0.28479 = 0.00088 + 0.28391 seconds\n",
      "Using batch size   9, an average step would have taken 0.28469 = 0.00060 + 0.28408 seconds\n",
      "Using batch size  10, an average step would have taken 0.28104 = 0.00050 + 0.28054 seconds\n",
      "Using batch size  11, an average step would have taken 0.27382 = 0.00091 + 0.27291 seconds\n",
      "Using batch size  12, an average step would have taken 0.26745 = 0.00072 + 0.26673 seconds\n",
      "Using batch size  13, an average step would have taken 0.25273 = 0.00036 + 0.25237 seconds\n",
      "Using batch size  14, an average step would have taken 0.27120 = 0.00042 + 0.27078 seconds\n",
      "Using batch size  15, an average step would have taken 0.24647 = 0.00030 + 0.24617 seconds\n",
      "Using batch size  16, an average step would have taken 0.34506 = 0.00038 + 0.34468 seconds\n",
      "Using batch size  17, an average step would have taken 0.34307 = 0.00038 + 0.34269 seconds\n",
      "Using batch size  18, an average step would have taken 0.37487 = 0.00031 + 0.37456 seconds\n",
      "Using batch size  19, an average step would have taken 0.38429 = 0.00033 + 0.38396 seconds\n",
      "Using batch size  20, an average step would have taken 0.24410 = 0.00033 + 0.24377 seconds\n",
      "Using batch size  21, an average step would have taken 0.23212 = 0.00035 + 0.23177 seconds\n",
      "Using batch size  22, an average step would have taken 0.19982 = 0.00039 + 0.19943 seconds\n",
      "Using batch size  23, an average step would have taken 0.20220 = 0.00029 + 0.20191 seconds\n",
      "Using batch size  24, an average step would have taken 0.22118 = 0.00065 + 0.22053 seconds\n",
      "Using batch size  25, an average step would have taken 0.30246 = 0.00028 + 0.30219 seconds\n",
      "batch size was 25, optimal batch size would have been 22\n",
      "setting batch size to 22: expected step duration: 0.19982\n",
      "improvement compared to old batch size (25): 1.5x\n",
      "improvement compared to worst batch size (1): 3.8x\n",
      "improvement compared to smallest batch size (1): 3.8x\n",
      "improvement compared to largest batch size (25): 1.5x\n",
      "next batch size tuning in 100 steps, after step 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 210: 2.55107e-02, stepsizes = 5.1e-02/4.4e-03: d. reduced by 0.89% (2.2828e-04) (took 0.66690 seconds)\n",
      "  Boundary too linear, increasing steps:     0.60 (100), 0.83 (30)\n",
      "  Success rate too high, increasing source step: 0.60 (100), 0.83 (30)\n",
      "Step 220: 2.33363e-02, stepsizes = 7.6e-02/1.0e-02: d. reduced by 0.89% (2.0883e-04) (took 0.70257 seconds)\n",
      "Step 230: 2.11050e-02, stepsizes = 7.6e-02/1.0e-02: d. reduced by 1.99% (4.2852e-04) (took 0.52678 seconds)\n",
      "Step 240: 2.11050e-02, stepsizes = 7.6e-02/1.0e-02:  (took 0.72237 seconds)\n",
      "Step 250: 1.90870e-02, stepsizes = 7.6e-02/1.0e-02: d. reduced by 1.99% (3.8754e-04) (took 0.61468 seconds)\n",
      "Step 260: 1.72619e-02, stepsizes = 7.6e-02/1.0e-02: d. reduced by 1.99% (3.5049e-04) (took 0.32114 seconds)\n",
      "Step 270: 1.53007e-02, stepsizes = 7.6e-02/1.0e-02: d. reduced by 1.99% (3.1067e-04) (took 0.48316 seconds)\n",
      "  Success rate too low, decreasing source step:  0.42 (100), 0.17 (30)\n",
      "Step 280: 1.49962e-02, stepsizes = 7.6e-02/6.7e-03:  (took 0.69984 seconds)\n",
      "Step 290: 1.36556e-02, stepsizes = 7.6e-02/6.7e-03: d. reduced by 1.33% (1.8391e-04) (took 0.35769 seconds)\n",
      "Step 300: 1.24349e-02, stepsizes = 7.6e-02/6.7e-03:  (took 0.66971 seconds)\n",
      "Estimating optimal batch size\n",
      "Time since beginning: 364.85021\n",
      "   1.4% for generation (5.00848)\n",
      "   15.7% for spherical prediction (57.42199)\n",
      "   71.4% for prediction (260.53892)\n",
      "   0.0% for hyperparameter update (0.02631)\n",
      "   11.5% for the rest (41.85451)\n",
      "current estimate of the time to generate a candidate depending on the batch size:\n",
      "[1.52238329e-03 1.19566917e-04 6.62389729e-05 9.20146704e-05\n",
      " 7.66658783e-05 6.23464584e-05 4.60926367e-05 4.72739339e-05\n",
      " 4.36335434e-05 3.18360329e-05 5.73150383e-05 2.86549330e-05\n",
      " 2.06309663e-05 1.99420112e-05 1.51496463e-05 1.84783712e-05\n",
      " 1.75464525e-05 1.37017097e-05 1.36717535e-05 1.25730038e-05\n",
      " 1.31443785e-05 1.31039014e-05 1.05097974e-05 1.56035854e-05\n",
      " 1.10891625e-05]\n",
      "current estimate of the time to get predictions for a candidate depending on the batch size:\n",
      "[0.08037698 0.042579   0.0471059  0.03771015 0.02960902 0.02709831\n",
      " 0.02324498 0.02105022 0.02041775 0.01886704 0.01681884 0.01617043\n",
      " 0.01538317 0.01643433 0.0136443  0.01901597 0.0180782  0.01891029\n",
      " 0.01849672 0.01070817 0.00959999 0.01099137 0.00807538 0.00858611\n",
      " 0.01208746]\n",
      "Relative frequencies for failing and success after k\n",
      "[0.44 0.09 0.05 0.07 0.04 0.02 0.06 0.05 0.02 0.01 0.02 0.02 0.01 0.\n",
      " 0.03 0.   0.   0.02 0.   0.01 0.   0.01 0.   0.   0.03 0.  ]\n",
      "Using batch size   1, an average step would have taken 1.23177 = 0.02290 + 1.20887 seconds\n",
      "Using batch size   2, an average step would have taken 0.67224 = 0.00245 + 0.66979 seconds\n",
      "Using batch size   3, an average step would have taken 0.75211 = 0.00168 + 0.75043 seconds\n",
      "Using batch size   4, an average step would have taken 0.62273 = 0.00210 + 0.62063 seconds\n",
      "Using batch size   5, an average step would have taken 0.48833 = 0.00126 + 0.48707 seconds\n",
      "Using batch size   6, an average step would have taken 0.47604 = 0.00168 + 0.47436 seconds\n",
      "Using batch size   7, an average step would have taken 0.41834 = 0.00086 + 0.41748 seconds\n",
      "Using batch size   8, an average step would have taken 0.39216 = 0.00147 + 0.39069 seconds\n",
      "Using batch size   9, an average step would have taken 0.37269 = 0.00078 + 0.37191 seconds\n",
      "Using batch size  10, an average step would have taken 0.36796 = 0.00068 + 0.36727 seconds\n",
      "Using batch size  11, an average step would have taken 0.35425 = 0.00107 + 0.35318 seconds\n",
      "Using batch size  12, an average step would have taken 0.33539 = 0.00120 + 0.33420 seconds\n",
      "Using batch size  13, an average step would have taken 0.30522 = 0.00045 + 0.30477 seconds\n",
      "Using batch size  14, an average step would have taken 0.32504 = 0.00060 + 0.32443 seconds\n",
      "Using batch size  15, an average step would have taken 0.30128 = 0.00039 + 0.30089 seconds\n",
      "Using batch size  16, an average step would have taken 0.39847 = 0.00050 + 0.39797 seconds\n",
      "Using batch size  17, an average step would have taken 0.39033 = 0.00048 + 0.38985 seconds\n",
      "Using batch size  18, an average step would have taken 0.42052 = 0.00040 + 0.42012 seconds\n",
      "Using batch size  19, an average step would have taken 0.42992 = 0.00044 + 0.42948 seconds\n",
      "Using batch size  20, an average step would have taken 0.28566 = 0.00044 + 0.28522 seconds\n",
      "Using batch size  21, an average step would have taken 0.27294 = 0.00045 + 0.27249 seconds\n",
      "Using batch size  22, an average step would have taken 0.30861 = 0.00038 + 0.30823 seconds\n",
      "Using batch size  23, an average step would have taken 0.22611 = 0.00035 + 0.22576 seconds\n",
      "Using batch size  24, an average step would have taken 0.24248 = 0.00104 + 0.24143 seconds\n",
      "Using batch size  25, an average step would have taken 0.30246 = 0.00028 + 0.30219 seconds\n",
      "batch size was 22, optimal batch size would have been 23\n",
      "setting batch size to 23: expected step duration: 0.22611\n",
      "improvement compared to old batch size (22): 1.4x\n",
      "improvement compared to worst batch size (1): 5.4x\n",
      "improvement compared to smallest batch size (1): 5.4x\n",
      "improvement compared to largest batch size (25): 1.3x\n",
      "next batch size tuning in 100 steps, after step 400\n",
      "Step 310: 1.19457e-02, stepsizes = 7.6e-02/6.7e-03:  (took 0.55080 seconds)\n",
      "  Success rate too low, decreasing source step:  0.32 (100), 0.10 (30)\n",
      "Step 320: 1.10243e-02, stepsizes = 7.6e-02/4.4e-03:  (took 0.43506 seconds)\n",
      "Step 330: 1.05440e-02, stepsizes = 7.6e-02/4.4e-03:  (took 0.49075 seconds)\n",
      "Step 340: 9.81872e-03, stepsizes = 7.6e-02/4.4e-03:  (took 0.61334 seconds)\n",
      "Step 350: 9.14330e-03, stepsizes = 7.6e-02/4.4e-03: d. reduced by 0.89% (8.1819e-05) (took 0.39276 seconds)\n"
     ]
    }
   ],
   "source": [
    "attack_params = {\n",
    "    'iterations': 10000,\n",
    "    'max_directions': 25,\n",
    "    'starting_point': None,\n",
    "    'initialization_attack': None,\n",
    "    'log_every_n_steps': 10,\n",
    "    'spherical_step': 0.01,\n",
    "    'source_step': 0.01,\n",
    "    'step_adaptation': 1.5,\n",
    "    'batch_size': 1,\n",
    "    'tune_batch_size': True, \n",
    "    'threaded_rnd': True, \n",
    "    'threaded_gen': True, \n",
    "    'alternative_generator': False\n",
    "}\n",
    "\n",
    "num = 100\n",
    "x_adv = np.zeros_like(x_test[:num].numpy())\n",
    "for i in range(100):\n",
    "    x_adv[i] = attack(x_test[i].numpy(), label=y_test[i].numpy(), \n",
    "                      unpack=True, verbose=True, **attack_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31\n"
     ]
    }
   ],
   "source": [
    "y_pred = dknn.classify(torch.tensor(x_adv))\n",
    "print((y_pred.argmax(1) == y_test[:num].numpy()).sum() / num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7054516\n"
     ]
    }
   ],
   "source": [
    "dist = np.sqrt(np.sum((x_adv - x_test[:num].numpy())**2, (1, 2, 3)))\n",
    "print(dist.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd9c7cd2f28>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_adv[1].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0946236"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum((x_adv - x_test[:100].numpy())**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fda1d367d68>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADQNJREFUeJzt3W+MVfWdx/HPZylNjPQBWLHEgnQb3bgaAzoaE3AzamxYbYKN1NQHGzbZMH2AZps0ZA1PypMmjemfrU9IpikpJtSWhFbRGBeDGylRGwejBYpQICzMgkAzJgUT0yDfPphDO8W5v3u5/84dv+9XQube8z1/vrnhM+ecOefcnyNCAPL5h7obAFAPwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+IKnP9HNjtrmdEOixiHAr83W057e9wvZB24dtP9nJugD0l9u9t9/2LEmHJD0gaVzSW5Iei4jfF5Zhzw/0WD/2/HdJOhwRRyPiz5J+IWllB+sD0EedhP96SSemvB+vpv0d2yO2x2yPdbAtAF3WyR/8pju0+MRhfUSMShqVOOwHBkkne/5xSQunvP+ipJOdtQOgXzoJ/1uSbrT9JduflfQNSdu70xaAXmv7sD8iLth+XNL/SJolaVNE7O9aZwB6qu1LfW1tjHN+oOf6cpMPgJmL8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaTaHqJbkmwfk3RO0seSLkTEUDeaAtB7HYW/cm9E/LEL6wHQRxz2A0l1Gv6QtMP2Htsj3WgIQH90eti/LCJO2p4v6RXb70XErqkzVL8U+MUADBhHRHdWZG+QdD4ivl+YpzsbA9BQRLiV+do+7Ld9te3PXXot6SuS9rW7PgD91clh/3WSfm370np+HhEvd6UrAD3XtcP+ljbGYT/Qcz0/7AcwsxF+ICnCDyRF+IGkCD+QFOEHkurGU30prFq1qmFtzZo1xWVPnjxZrH/00UfF+pYtW4r1999/v2Ht8OHDxWWRF3t+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iKR3pbdPTo0Ya1xYsX96+RaZw7d65hbf/+/X3sZLCMj483rD311FPFZcfGxrrdTt/wSC+AIsIPJEX4gaQIP5AU4QeSIvxAUoQfSIrn+VtUemb/tttuKy574MCBYv3mm28u1m+//fZifXh4uGHt7rvvLi574sSJYn3hwoXFeicuXLhQrJ89e7ZYX7BgQdvbPn78eLE+k6/zt4o9P5AU4QeSIvxAUoQfSIrwA0kRfiApwg8k1fR5ftubJH1V0pmIuLWaNk/SLyUtlnRM0qMR8UHTjc3g5/kH2dy5cxvWlixZUlx2z549xfqdd97ZVk+taDZewaFDh4r1ZvdPzJs3r2Ft7dq1xWU3btxYrA+ybj7P/zNJKy6b9qSknRFxo6Sd1XsAM0jT8EfELkkTl01eKWlz9XqzpIe73BeAHmv3nP+6iDglSdXP+d1rCUA/9PzeftsjkkZ6vR0AV6bdPf9p2wskqfp5ptGMETEaEUMRMdTmtgD0QLvh3y5pdfV6taTnu9MOgH5pGn7bz0p6Q9I/2R63/R+SvifpAdt/kPRA9R7ADML39mNgPfLII8X61q1bi/V9+/Y1rN17773FZScmLr/ANXPwvf0Aigg/kBThB5Ii/EBShB9IivADSXGpD7WZP7/8SMjevXs7Wn7VqlUNa9u2bSsuO5NxqQ9AEeEHkiL8QFKEH0iK8ANJEX4gKcIPJMUQ3ahNs6/Pvvbaa4v1Dz4of1v8wYMHr7inTNjzA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBSPM+Pnlq2bFnD2quvvlpcdvbs2cX68PBwsb5r165i/dOK5/kBFBF+ICnCDyRF+IGkCD+QFOEHkiL8QFJNn+e3vUnSVyWdiYhbq2kbJK2RdLaabX1EvNSrJjFzPfjggw1rza7j79y5s1h/44032uoJk1rZ8/9M0opppv8oIpZU/wg+MMM0DX9E7JI00YdeAPRRJ+f8j9v+ne1Ntud2rSMAfdFu+DdK+rKkJZJOSfpBoxltj9gesz3W5rYA9EBb4Y+I0xHxcURclPQTSXcV5h2NiKGIGGq3SQDd11b4bS+Y8vZrkvZ1px0A/dLKpb5nJQ1L+rztcUnfkTRse4mkkHRM0jd72COAHuB5fnTkqquuKtZ3797dsHbLLbcUl73vvvuK9ddff71Yz4rn+QEUEX4gKcIPJEX4gaQIP5AU4QeSYohudGTdunXF+tKlSxvWXn755eKyXMrrLfb8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AUj/Si6KGHHirWn3vuuWL9ww8/bFhbsWK6L4X+mzfffLNYx/R4pBdAEeEHkiL8QFKEH0iK8ANJEX4gKcIPJMXz/Mldc801xfrTTz9drM+aNatYf+mlxgM4cx2/Xuz5gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiCpps/z214o6RlJX5B0UdJoRPzY9jxJv5S0WNIxSY9GxAdN1sXz/H3W7Dp8s2vtd9xxR7F+5MiRYr30zH6zZdGebj7Pf0HStyPiZkl3S1pr+58lPSlpZ0TcKGln9R7ADNE0/BFxKiLerl6fk3RA0vWSVkraXM22WdLDvWoSQPdd0Tm/7cWSlkr6raTrIuKUNPkLQtL8bjcHoHdavrff9hxJ2yR9KyL+ZLd0WiHbI5JG2msPQK+0tOe3PVuTwd8SEb+qJp+2vaCqL5B0ZrplI2I0IoYiYqgbDQPojqbh9+Qu/qeSDkTED6eUtktaXb1eLen57rcHoFdaudS3XNJvJO3V5KU+SVqvyfP+rZIWSTou6esRMdFkXVzq67ObbrqpWH/vvfc6Wv/KlSuL9RdeeKGj9ePKtXqpr+k5f0TsltRoZfdfSVMABgd3+AFJEX4gKcIPJEX4gaQIP5AU4QeS4qu7PwVuuOGGhrUdO3Z0tO5169YV6y+++GJH60d92PMDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFJc5/8UGBlp/C1pixYt6mjdr732WrHe7PsgMLjY8wNJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUlznnwGWL19erD/xxBN96gSfJuz5gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiCpptf5bS+U9IykL0i6KGk0In5se4OkNZLOVrOuj4iXetVoZvfcc0+xPmfOnLbXfeTIkWL9/Pnzba8bg62Vm3wuSPp2RLxt+3OS9th+par9KCK+37v2APRK0/BHxClJp6rX52wfkHR9rxsD0FtXdM5ve7GkpZJ+W0163PbvbG+yPbfBMiO2x2yPddQpgK5qOfy250jaJulbEfEnSRslfVnSEk0eGfxguuUiYjQihiJiqAv9AuiSlsJve7Ymg78lIn4lSRFxOiI+joiLkn4i6a7etQmg25qG37Yl/VTSgYj44ZTpC6bM9jVJ+7rfHoBeaeWv/csk/Zukvbbfqaatl/SY7SWSQtIxSd/sSYfoyLvvvlus33///cX6xMREN9vBAGnlr/27JXmaEtf0gRmMO/yApAg/kBThB5Ii/EBShB9IivADSbmfQyzbZjxnoMciYrpL85/Anh9IivADSRF+ICnCDyRF+IGkCD+QFOEHkur3EN1/lPR/U95/vpo2iAa1t0HtS6K3dnWztxtanbGvN/l8YuP22KB+t9+g9jaofUn01q66euOwH0iK8ANJ1R3+0Zq3XzKovQ1qXxK9tauW3mo95wdQn7r3/ABqUkv4ba+wfdD2YdtP1tFDI7aP2d5r+526hxirhkE7Y3vflGnzbL9i+w/Vz2mHSauptw22/7/67N6x/WBNvS20/b+2D9jeb/s/q+m1fnaFvmr53Pp+2G97lqRDkh6QNC7pLUmPRcTv+9pIA7aPSRqKiNqvCdv+F0nnJT0TEbdW056SNBER36t+cc6NiP8akN42SDpf98jN1YAyC6aOLC3pYUn/rho/u0Jfj6qGz62OPf9dkg5HxNGI+LOkX0haWUMfAy8idkm6fNSMlZI2V683a/I/T9816G0gRMSpiHi7en1O0qWRpWv97Ap91aKO8F8v6cSU9+MarCG/Q9IO23tsj9TdzDSuq4ZNvzR8+vya+7lc05Gb++mykaUH5rNrZ8Trbqsj/NN9xdAgXXJYFhG3S/pXSWurw1u0pqWRm/tlmpGlB0K7I153Wx3hH5e0cMr7L0o6WUMf04qIk9XPM5J+rcEbffj0pUFSq59nau7nrwZp5ObpRpbWAHx2gzTidR3hf0vSjba/ZPuzkr4haXsNfXyC7aurP8TI9tWSvqLBG314u6TV1evVkp6vsZe/MygjNzcaWVo1f3aDNuJ1LTf5VJcy/lvSLEmbIuK7fW9iGrb/UZN7e2nyicef19mb7WclDWvyqa/Tkr4j6TlJWyUtknRc0tcjou9/eGvQ27AmD13/OnLzpXPsPve2XNJvJO2VdLGavF6T59e1fXaFvh5TDZ8bd/gBSXGHH5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpP4CIJjqosJxHysAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0].numpy().reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(x_adv, open('x_adv_boundary_adv0.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAATTTCCCCCC', 'CCCAAATTCTTC', 'TTCTTATTGTTG', 'TTGTTATTGTTG']\n",
      "AAATTTCCCCCC\n",
      "AAATTCTTC\n",
      "AAATTTCCCCCCAAATTCTTC\n",
      "AAATTTCCCCCCAAATTCTTC\n",
      "['AAATTTCCCCCCAAATTCTTC', 'TTCTTATTGTTG', 'TTGTTATTGTTG']\n",
      "['AAATTTCCCCCCAAATTCTTC', 'TTCTTATTGTTG', 'TTGTTATTGTTG']\n",
      "AAATTTCCCCCCAAATTCTTC\n",
      "TTATTGTTG\n",
      "AAATTTCCCCCCAAATTCTTCTTATTGTTG\n",
      "AAATTTCCCCCCAAATTCTTCTTATTGTTG\n",
      "['AAATTTCCCCCCAAATTCTTCTTATTGTTG', 'TTGTTATTGTTG']\n",
      "['AAATTTCCCCCCAAATTCTTCTTATTGTTG', 'TTGTTATTGTTG']\n",
      "AAATTTCCCCCCAAATTCTTCTTATTGTTG\n",
      "TTATTGTTG\n",
      "AAATTTCCCCCCAAATTCTTCTTATTGTTGTTATTGTTG\n",
      "AAATTTCCCCCCAAATTCTTCTTATTGTTGTTATTGTTG\n",
      "['AAATTTCCCCCCAAATTCTTCTTATTGTTGTTATTGTTG']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "st = ['AAATTTCCCCCC','CCCAAATTCTTC','TTCTTATTGTTG','TTGTTATTGTTG']\n",
    "\n",
    "while j < len(st):\n",
    "\n",
    "    if st[i][0:3] == st[j][-3:]:\n",
    "        st[i] = st[j][0:-3] + st[i]\n",
    "        st = np.delete(st, j)\n",
    "    elif st[j][0:3] == st[i][-3:]:\n",
    "        print(st)\n",
    "        print(st[i])\n",
    "        print(st[j][3:])\n",
    "        print(st[i] + st[j][3:])\n",
    "        st[i] = st[i] + st[j][3:]\n",
    "        print(st[i])\n",
    "        st.pop(j)\n",
    "        print(st)\n",
    "    else:\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAATTTCCCCCC', 'TTCTTATTGTTG', 'TTGTTATTGTTG'], dtype='<U12')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = np.array(['AAATTTCCCCCC','CCCAAATTCTTC','TTCTTATTGTTG','TTGTTATTGTTG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "st[0] = st[0] + st[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAATTTCCCCCC', 'CCCAAATTCTTC', 'TTCTTATTGTTG', 'TTGTTATTGTTG'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
