{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import foolbox\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from lib.dataset_utils import *\n",
    "from lib.cifar_resnet import *\n",
    "from lib.adv_model import *\n",
    "from lib.dknn_attack_v2 import DKNNAttackV2\n",
    "from lib.cwl2_attack import CWL2Attack\n",
    "from lib.dknn import DKNNL2\n",
    "from lib.utils import *\n",
    "from lib.lip_model import *\n",
    "from lib.cifar10_model import *\n",
    "\n",
    "# from lib.cifar10_dcgan import Discriminator, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6ad42467b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set all random seeds\n",
    "seed = 2019\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_valid, y_valid), (x_test, y_test) = load_cifar10_all(\n",
    "    '/data', val_size=0.1, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NCAModel(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc_): Linear(in_features=512, out_features=20, bias=True)\n",
       "  (fc): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'adv_cifar10_nca_exp3.h5'\n",
    "# model_name = 'adv_cifar10_nca_exp19.h5'\n",
    "net = NCAModel(PreActBlock, [2, 2, 2, 2],\n",
    "               normalize=False, output_dim=20, init_it=1,\n",
    "               train_it=False, train_data=(x_train, y_train))\n",
    "\n",
    "# Set up model directory\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models/')\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = net.to(device)\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.recompute_train_rep()\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch_size = 200\n",
    "    num_batches = int(np.ceil(len(x_test) / batch_size))\n",
    "    logits = np.zeros((len(x_test), 10))\n",
    "    for i in range(num_batches):\n",
    "        logits[i * batch_size:(i + 1) * batch_size] = net.compute_logits(\n",
    "            x_test[i * batch_size:(i + 1) * batch_size].cuda()).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7656\n"
     ]
    }
   ],
   "source": [
    "ind = logits.argmax(1) == y_test.numpy()\n",
    "ind = np.where(ind)[0]\n",
    "print(len(ind) / len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lib.cwl2_attack import CWL2AttackNCA\n",
    "attack = CWL2AttackNCA(net)\n",
    "num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    step: 0; loss: 0.491; l2dist: 0.000\n",
      "    step: 50; loss: 0.459; l2dist: 0.134\n",
      "    step: 100; loss: 0.462; l2dist: 0.135\n",
      "binary step: 0; number of successful adv: 6/100\n",
      "    step: 0; loss: 9.277; l2dist: 2.134\n",
      "    step: 50; loss: 2.318; l2dist: 0.931\n",
      "    step: 100; loss: 2.319; l2dist: 0.940\n",
      "binary step: 1; number of successful adv: 61/100\n",
      "    step: 0; loss: 25.875; l2dist: 2.134\n",
      "    step: 50; loss: 4.732; l2dist: 1.296\n",
      "    step: 100; loss: 4.713; l2dist: 1.299\n",
      "    step: 150; loss: 4.702; l2dist: 1.300\n",
      "    step: 200; loss: 4.702; l2dist: 1.302\n",
      "binary step: 2; number of successful adv: 91/100\n",
      "    step: 0; loss: 60.676; l2dist: 2.136\n",
      "    step: 50; loss: 6.266; l2dist: 1.791\n",
      "    step: 100; loss: 6.180; l2dist: 1.790\n",
      "    step: 150; loss: 6.143; l2dist: 1.790\n",
      "    step: 200; loss: 6.127; l2dist: 1.808\n",
      "    step: 250; loss: 6.113; l2dist: 1.805\n",
      "    step: 300; loss: 6.112; l2dist: 1.808\n",
      "    step: 350; loss: 6.105; l2dist: 1.805\n",
      "    step: 400; loss: 6.095; l2dist: 1.807\n",
      "    step: 450; loss: 6.094; l2dist: 1.814\n",
      "binary step: 3; number of successful adv: 98/100\n",
      "    step: 0; loss: 220.692; l2dist: 2.131\n",
      "    step: 50; loss: 10.506; l2dist: 2.542\n",
      "    step: 100; loss: 9.727; l2dist: 2.474\n",
      "    step: 150; loss: 9.376; l2dist: 2.454\n",
      "    step: 200; loss: 9.337; l2dist: 2.441\n",
      "    step: 250; loss: 9.240; l2dist: 2.441\n",
      "    step: 300; loss: 9.228; l2dist: 2.449\n",
      "    step: 350; loss: 9.214; l2dist: 2.442\n",
      "    step: 400; loss: 9.169; l2dist: 2.427\n",
      "    step: 450; loss: 9.203; l2dist: 2.457\n",
      "binary step: 4; number of successful adv: 99/100\n",
      "    step: 0; loss: 686.724; l2dist: 2.139\n",
      "    step: 50; loss: 21.195; l2dist: 3.293\n",
      "    step: 100; loss: 19.276; l2dist: 3.017\n",
      "    step: 150; loss: 18.335; l2dist: 2.863\n",
      "    step: 200; loss: 18.199; l2dist: 2.842\n",
      "    step: 250; loss: 18.080; l2dist: 2.827\n",
      "    step: 300; loss: 18.062; l2dist: 2.837\n",
      "    step: 350; loss: 17.801; l2dist: 2.778\n",
      "    step: 400; loss: 17.686; l2dist: 2.764\n",
      "    step: 450; loss: 17.650; l2dist: 2.766\n",
      "binary step: 5; number of successful adv: 99/100\n",
      "    step: 0; loss: 6012.354; l2dist: 2.140\n",
      "    step: 50; loss: 18.826; l2dist: 4.247\n",
      "    step: 100; loss: 14.126; l2dist: 3.665\n",
      "    step: 150; loss: 10.440; l2dist: 3.127\n",
      "    step: 200; loss: 7.788; l2dist: 2.653\n",
      "    step: 250; loss: 5.706; l2dist: 2.219\n",
      "    step: 300; loss: 4.370; l2dist: 1.872\n",
      "    step: 350; loss: 3.594; l2dist: 1.634\n",
      "    step: 400; loss: 3.111; l2dist: 1.471\n",
      "    step: 450; loss: 3.258; l2dist: 1.442\n",
      "binary step: 6; number of successful adv: 100/100\n",
      "    step: 0; loss: 3312.683; l2dist: 2.127\n",
      "    step: 50; loss: 15.641; l2dist: 3.865\n",
      "    step: 100; loss: 10.118; l2dist: 3.081\n",
      "    step: 150; loss: 6.848; l2dist: 2.469\n",
      "    step: 200; loss: 4.770; l2dist: 1.982\n",
      "    step: 250; loss: 3.703; l2dist: 1.668\n",
      "    step: 300; loss: 3.131; l2dist: 1.479\n",
      "    step: 350; loss: 2.788; l2dist: 1.361\n",
      "    step: 400; loss: 3.174; l2dist: 1.404\n",
      "binary step: 7; number of successful adv: 100/100\n",
      "    step: 0; loss: 1970.902; l2dist: 2.132\n",
      "    step: 50; loss: 12.553; l2dist: 3.450\n",
      "    step: 100; loss: 6.950; l2dist: 2.505\n",
      "    step: 150; loss: 4.504; l2dist: 1.913\n",
      "    step: 200; loss: 3.506; l2dist: 1.597\n",
      "    step: 250; loss: 3.422; l2dist: 1.504\n",
      "    step: 300; loss: 2.944; l2dist: 1.369\n",
      "    step: 350; loss: 2.708; l2dist: 1.300\n",
      "    step: 400; loss: 2.542; l2dist: 1.253\n",
      "    step: 450; loss: 2.506; l2dist: 1.237\n",
      "binary step: 8; number of successful adv: 100/100\n",
      "    step: 0; loss: 1964.559; l2dist: 2.137\n",
      "    step: 50; loss: 12.573; l2dist: 3.452\n",
      "    step: 100; loss: 6.908; l2dist: 2.503\n",
      "    step: 150; loss: 4.548; l2dist: 1.917\n",
      "    step: 200; loss: 3.465; l2dist: 1.588\n",
      "    step: 250; loss: 2.943; l2dist: 1.414\n",
      "    step: 300; loss: 2.808; l2dist: 1.340\n",
      "    step: 350; loss: 2.649; l2dist: 1.286\n",
      "    step: 400; loss: 2.525; l2dist: 1.247\n",
      "    step: 450; loss: 2.450; l2dist: 1.234\n",
      "binary step: 9; number of successful adv: 100/100\n",
      "    step: 0; loss: 96.968; l2dist: 9.658\n",
      "    step: 50; loss: 2.426; l2dist: 1.218\n",
      "    step: 100; loss: 1.123; l2dist: 0.670\n",
      "    step: 150; loss: 0.867; l2dist: 0.494\n",
      "    step: 200; loss: 0.763; l2dist: 0.410\n",
      "    step: 250; loss: 0.634; l2dist: 0.338\n",
      "    step: 300; loss: 0.572; l2dist: 0.292\n",
      "    step: 350; loss: 0.545; l2dist: 0.264\n",
      "    step: 400; loss: 0.530; l2dist: 0.247\n",
      "    step: 450; loss: 0.519; l2dist: 0.232\n",
      "binary step: 0; number of successful adv: 100/100\n",
      "    step: 0; loss: 102.583; l2dist: 9.956\n",
      "    step: 50; loss: 4.661; l2dist: 1.825\n",
      "    step: 100; loss: 3.188; l2dist: 1.440\n",
      "    step: 150; loss: 2.915; l2dist: 1.339\n",
      "    step: 200; loss: 2.783; l2dist: 1.293\n",
      "    step: 250; loss: 2.668; l2dist: 1.246\n",
      "    step: 300; loss: 2.585; l2dist: 1.218\n",
      "    step: 350; loss: 2.563; l2dist: 1.201\n",
      "    step: 400; loss: 2.536; l2dist: 1.187\n",
      "    step: 450; loss: 2.526; l2dist: 1.184\n",
      "binary step: 1; number of successful adv: 100/100\n",
      "    step: 0; loss: 102.399; l2dist: 9.946\n",
      "    step: 50; loss: 5.666; l2dist: 2.152\n",
      "    step: 100; loss: 3.809; l2dist: 1.707\n",
      "    step: 150; loss: 3.287; l2dist: 1.504\n",
      "    step: 200; loss: 3.146; l2dist: 1.473\n",
      "    step: 250; loss: 2.997; l2dist: 1.422\n",
      "    step: 300; loss: 2.889; l2dist: 1.402\n",
      "    step: 350; loss: 2.884; l2dist: 1.400\n",
      "    step: 400; loss: 2.888; l2dist: 1.396\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 102.403; l2dist: 9.943\n",
      "    step: 50; loss: 5.379; l2dist: 2.027\n",
      "    step: 100; loss: 3.729; l2dist: 1.641\n",
      "    step: 150; loss: 3.396; l2dist: 1.509\n",
      "    step: 200; loss: 3.188; l2dist: 1.477\n",
      "    step: 250; loss: 3.050; l2dist: 1.438\n",
      "    step: 300; loss: 3.035; l2dist: 1.432\n",
      "    step: 350; loss: 2.948; l2dist: 1.390\n",
      "    step: 400; loss: 2.951; l2dist: 1.408\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 102.963; l2dist: 9.947\n",
      "    step: 50; loss: 5.503; l2dist: 2.024\n",
      "    step: 100; loss: 3.668; l2dist: 1.604\n",
      "    step: 150; loss: 3.257; l2dist: 1.496\n",
      "    step: 200; loss: 3.107; l2dist: 1.450\n",
      "    step: 250; loss: 2.978; l2dist: 1.407\n",
      "    step: 300; loss: 2.882; l2dist: 1.381\n",
      "    step: 350; loss: 2.854; l2dist: 1.364\n",
      "    step: 400; loss: 2.811; l2dist: 1.353\n",
      "    step: 450; loss: 2.832; l2dist: 1.368\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 102.539; l2dist: 9.940\n",
      "    step: 50; loss: 5.494; l2dist: 2.110\n",
      "    step: 100; loss: 3.744; l2dist: 1.687\n",
      "    step: 150; loss: 3.399; l2dist: 1.604\n",
      "    step: 200; loss: 3.339; l2dist: 1.575\n",
      "    step: 250; loss: 3.152; l2dist: 1.543\n",
      "    step: 300; loss: 3.039; l2dist: 1.498\n",
      "    step: 350; loss: 3.051; l2dist: 1.509\n",
      "binary step: 5; number of successful adv: 100/100\n",
      "    step: 0; loss: 102.544; l2dist: 9.945\n",
      "    step: 50; loss: 5.393; l2dist: 2.081\n",
      "    step: 100; loss: 3.739; l2dist: 1.693\n",
      "    step: 150; loss: 3.404; l2dist: 1.595\n",
      "    step: 200; loss: 3.257; l2dist: 1.557\n",
      "    step: 250; loss: 3.194; l2dist: 1.537\n",
      "    step: 300; loss: 3.045; l2dist: 1.513\n",
      "    step: 350; loss: 2.974; l2dist: 1.475\n",
      "    step: 400; loss: 2.973; l2dist: 1.490\n",
      "    step: 450; loss: 2.910; l2dist: 1.452\n",
      "binary step: 6; number of successful adv: 100/100\n",
      "    step: 0; loss: 102.550; l2dist: 9.949\n",
      "    step: 50; loss: 5.416; l2dist: 2.094\n",
      "    step: 100; loss: 3.783; l2dist: 1.711\n",
      "    step: 150; loss: 3.408; l2dist: 1.609\n",
      "    step: 200; loss: 3.277; l2dist: 1.565\n",
      "    step: 250; loss: 3.086; l2dist: 1.505\n",
      "    step: 300; loss: 3.015; l2dist: 1.506\n",
      "    step: 350; loss: 2.979; l2dist: 1.487\n",
      "    step: 400; loss: 2.937; l2dist: 1.480\n",
      "    step: 450; loss: 2.935; l2dist: 1.470\n",
      "binary step: 7; number of successful adv: 100/100\n",
      "    step: 0; loss: 102.510; l2dist: 9.949\n",
      "    step: 50; loss: 5.341; l2dist: 2.078\n",
      "    step: 100; loss: 3.755; l2dist: 1.692\n",
      "    step: 150; loss: 3.408; l2dist: 1.604\n",
      "    step: 200; loss: 3.255; l2dist: 1.552\n",
      "    step: 250; loss: 3.112; l2dist: 1.523\n",
      "    step: 300; loss: 3.030; l2dist: 1.495\n",
      "    step: 350; loss: 3.018; l2dist: 1.496\n",
      "    step: 400; loss: 2.991; l2dist: 1.493\n",
      "    step: 450; loss: 2.972; l2dist: 1.474\n",
      "binary step: 8; number of successful adv: 100/100\n",
      "    step: 0; loss: 102.485; l2dist: 9.948\n",
      "    step: 50; loss: 5.198; l2dist: 1.971\n",
      "    step: 100; loss: 3.600; l2dist: 1.605\n",
      "    step: 150; loss: 3.299; l2dist: 1.491\n",
      "    step: 200; loss: 3.130; l2dist: 1.454\n",
      "    step: 250; loss: 2.995; l2dist: 1.410\n",
      "    step: 300; loss: 2.937; l2dist: 1.381\n",
      "    step: 350; loss: 2.874; l2dist: 1.376\n",
      "    step: 400; loss: 2.881; l2dist: 1.360\n",
      "binary step: 9; number of successful adv: 100/100\n"
     ]
    }
   ],
   "source": [
    "x_adv = attack(x_test[ind][:num].cuda(), y_test[ind][:num].cuda(), \n",
    "               targeted=False, init_mode=2,\n",
    "               binary_search_steps=10, max_iterations=500, confidence=0,\n",
    "               learning_rate=1e-2, initial_const=1, abort_early=True,\n",
    "               rand_start_std=0.1, check_adv_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2142, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_adv.cpu() - x_test[ind][:num]).view(num, -1).norm(2, 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& 0.0083 & 0.0063 & 0.0033\n"
     ]
    }
   ],
   "source": [
    "pert = (x_adv.cpu() - x_test[ind]).view(x_adv.size(0), -1).norm(2, 1)\n",
    "d1 = (len(ind) - (pert[ind_adv] < 0.5).sum().numpy()) / y_test.size(0)\n",
    "d2 = (len(ind) - (pert[ind_adv] < 1).sum().numpy()) / y_test.size(0)\n",
    "d3 = (len(ind) - (pert[ind_adv] < 1.5).sum().numpy()) / y_test.size(0)\n",
    "print('& %.4f & %.4f & %.4f' % (d1, d2, d3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2168, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pert[ind_adv].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_train = np.zeros((len(y_train), 10))\n",
    "nb = dknn.get_neighbors(x_train, k=100)[0][1]\n",
    "for i in range(len(y_train)):\n",
    "    ys_train[i] = np.bincount(y_train[nb[i]], minlength=10) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## DkNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers = ['fc']\n",
    "dknn = DKNNL2(net, x_train, y_train, x_valid, y_valid, \n",
    "              layers, k=100, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7708\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = dknn.classify(x_test)\n",
    "    ind = np.where(y_pred.argmax(1) == y_test.numpy())[0]\n",
    "    print((y_pred.argmax(1) == y_test.numpy()).sum() / y_test.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def attack_batch(attack, x, y, init_mode, init_mode_k, batch_size):\n",
    "    x_adv = torch.zeros_like(x)\n",
    "    total_num = x.size(0)\n",
    "    num_batches = total_num // batch_size\n",
    "    for i in range(num_batches):\n",
    "        begin = i * batch_size\n",
    "        end = (i + 1) * batch_size\n",
    "        x_adv[begin:end] = attack(\n",
    "            x[begin:end], y[begin:end], 2, guide_layer='fc', m=200,\n",
    "            init_mode=init_mode, init_mode_k=init_mode_k,\n",
    "            binary_search_steps=10, max_iterations=1000, learning_rate=1e-2,\n",
    "            initial_const=1e0, max_linf=None, random_start=True,\n",
    "            thres_steps=200, check_adv_steps=200, verbose=False)\n",
    "    return x_adv\n",
    "\n",
    "num = 100\n",
    "\n",
    "def full_eval(dknn):\n",
    "    with torch.no_grad():\n",
    "        y_pred = dknn.classify(x_test)\n",
    "        ind = np.where(y_pred.argmax(1) == y_test.numpy())[0]\n",
    "    print((y_pred.argmax(1) == y_test.numpy()).sum() / y_test.size(0))\n",
    "    \n",
    "    dist_all = np.zeros(num) + 1e9\n",
    "    attack = DKNNAttackV2(dknn)\n",
    "    \n",
    "    x_adv = attack_batch(\n",
    "        attack, x_test[ind][:num].cuda(), y_test[ind][:num], 1, 1, 100)\n",
    "    with torch.no_grad():\n",
    "        y_pred = dknn.classify(x_adv)\n",
    "        ind_adv = y_pred.argmax(1) != y_test[ind][:num].numpy()\n",
    "        dist = (x_adv.cpu() - x_test[ind][:num]).view(\n",
    "            num, -1).norm(2, 1).numpy()\n",
    "    for i in range(num):\n",
    "        if ind_adv[i] and (dist[i] < dist_all[i]):\n",
    "            dist_all[i] = dist[i]\n",
    "            \n",
    "    for k in range(1, 6):\n",
    "        x_adv = attack_batch(\n",
    "            attack, x_test[ind][:num].cuda(), y_test[ind][:num], 2, k, 100)\n",
    "        with torch.no_grad():\n",
    "            y_pred = dknn.classify(x_adv)\n",
    "            ind_adv = y_pred.argmax(1) != y_test[ind][:num].numpy()\n",
    "            dist = (x_adv.cpu() - x_test[ind][:num]).view(\n",
    "                num, -1).norm(2, 1).numpy()\n",
    "        for i in range(num):\n",
    "            if ind_adv[i] and (dist[i] < dist_all[i]):\n",
    "                dist_all[i] = dist[i]\n",
    "                \n",
    "    adv_acc = (dist_all == 1e9).mean()\n",
    "    print('adv accuracy: %.4f, mean dist: %.4f' % (\n",
    "        adv_acc, dist_all[dist_all < 1e9].mean()))\n",
    "    return dist_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7708\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dist = full_eval(dknn)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1592309394478797"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## CW Attack on AT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreActResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'adv_cifar10_exp6.h5'\n",
    "net = PreActResNet(PreActBlock, [2, 2, 2, 2])\n",
    "config = {'epsilon': 1,\n",
    "          'num_steps': 10,\n",
    "          'step_size': 0.2,\n",
    "          'random_start': True,\n",
    "          'loss_func': 'xent'}\n",
    "net = PGDL2Model(net, config)\n",
    "\n",
    "# Set up model directory\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models/')\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = net.to(device)\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "net = net.basic_net\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch_size = 200\n",
    "    num_batches = int(np.ceil(len(x_test) / batch_size))\n",
    "    logits = np.zeros((len(x_test), 10))\n",
    "    for i in range(num_batches):\n",
    "        logits[i * batch_size:(i + 1) * batch_size] = net(\n",
    "            x_test[i * batch_size:(i + 1) * batch_size].cuda()).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7565\n"
     ]
    }
   ],
   "source": [
    "ind = logits.argmax(1) == y_test.numpy()\n",
    "ind = np.where(ind)[0]\n",
    "print(len(ind) / len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lib.cwl2_attack import CWL2Attack\n",
    "\n",
    "attack = CWL2Attack(net, x_train=x_train, y_train=y_train)\n",
    "\n",
    "def attack_batch(x, y, batch_size):\n",
    "    x_adv = torch.zeros_like(x)\n",
    "    total_num = x.size(0)\n",
    "    num_batches = total_num // batch_size\n",
    "    for i in range(num_batches):\n",
    "        begin = i * batch_size\n",
    "        end = (i + 1) * batch_size\n",
    "        x_adv[begin:end] = attack(\n",
    "            x[begin:end], y[begin:end], targeted=False,\n",
    "            init_mode=2, binary_search_steps=10, max_iterations=500,\n",
    "            confidence=0, learning_rate=1e-2, initial_const=1, \n",
    "            abort_early=False, rand_start_std=0.1, check_adv_steps=100)\n",
    "    return x_adv\n",
    "\n",
    "num = 100\n",
    "x_adv = attack_batch(x_test[ind][:num].cuda(), y_test[ind][:num].cuda(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4624, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_adv.cpu() - x_test[ind][:num]).view(num, -1).norm(2, 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## RotNet\n",
    "\n",
    "Train small network on top of pre-trained rotation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {'num_classes': 4, 'num_stages': 4}\n",
    "net = NetworkInNetwork(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('saved_models/model_net_epoch200')['network'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net._feature_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net_wrap = NINWrapper(net, block=2)\n",
    "net_wrap = net_wrap.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_wrap.fc = nn.Sequential(\n",
    "#     nn.Linear(12288, 200),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(200, 200),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(200, 128))\n",
    "net_wrap.fc = nn.Sequential(\n",
    "    nn.Linear(12288, 2000),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(2000, 400),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(400, 128))\n",
    "net_wrap = net_wrap.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_wrap.load_state_dict(torch.load('saved_models/transfer_cifar10_exp11.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PreActResNet(PreActBlock, [2, 2, 2, 2], num_classes=4)\n",
    "net.load_state_dict(torch.load('saved_models/rot_cifar10_exp0.h5'))\n",
    "net_wrap = ResNetWrapper(net, block=3, dim=16384)\n",
    "for param in net_wrap.parameters():\n",
    "    param.requires_grad = False\n",
    "# net_wrap.fc = nn.Sequential(\n",
    "#     nn.Linear(16384, 2000),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(2000, 400),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(400, 128),\n",
    "# )\n",
    "net_wrap.fc = nn.Sequential(\n",
    "    nn.BatchNorm1d(16384),\n",
    "    nn.Linear(16384, 2000),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm1d(2000),\n",
    "    nn.Linear(2000, 400),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm1d(400),\n",
    "    nn.Linear(400, 128),\n",
    ")\n",
    "net_wrap.load_state_dict(torch.load('saved_models/transfer_cifar10_exp18.h5'))\n",
    "net_wrap = net_wrap.to('cuda').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers = ['fc']\n",
    "\n",
    "dknn = DKNNL2(net_wrap, x_train, y_train, x_valid, y_valid, layers, \n",
    "              k=1, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7015\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = dknn.classify(x_test)\n",
    "    print((y_pred.argmax(1) == y_test.numpy()).sum() / y_test.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0011\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    num = 0\n",
    "    for i in range(x_test.size(0) // 100):\n",
    "        begin = i * 100\n",
    "        end = (i + 1) * 100\n",
    "        y_pred = net_wrap(x_test[begin:end].to('cuda'))\n",
    "        num += (y_pred.argmax(1).cpu() == y_test[begin:end]).sum().numpy()\n",
    "    print(num / y_test.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adv = pickle.load(open('x_adv/x_adv_adv_cifar10_exp0.h5.p', 'rb'))\n",
    "# x_adv = pickle.load(open('x_adv/x_ba_cifar10_adv2_0.2_0.001.p', 'rb'))\n",
    "# x_adv = pickle.load(open('x_adv/x_adv_cifar10_resnet_exp2.h5.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.utils.save_image(x_adv[:10], 'cifar10_cw_adv.png', nrow=10, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.utils.save_image(x_test[:10], 'cifar10_test.png', nrow=10, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = x_adv[:10].cpu() - x_test[:10]\n",
    "torchvision.utils.save_image(diff, 'diff_cw_adv.png', nrow=10, padding=0, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1601, 0.1639, 0.0439, 0.0925, 0.2344, 0.1875, 0.1263, 0.0629, 0.1313,\n",
       "        0.0308, 0.1699, 0.2601, 0.1186, 0.2549, 0.2104, 0.0949, 0.0168, 0.1908,\n",
       "        0.2373, 0.2276, 0.0749, 0.1144, 0.0599, 0.3487, 0.0113, 0.1286, 0.0399,\n",
       "        0.1052, 0.1184, 0.1812, 0.1033, 0.1054, 0.1015, 0.0491, 0.2473, 0.1405,\n",
       "        0.1351, 0.3051, 0.2656, 0.1246, 0.1826, 0.1177, 0.1306, 0.2810, 0.2485,\n",
       "        0.0251, 0.0446, 0.2726, 0.0799, 0.2484, 0.1870, 0.0150, 0.0376, 0.1555,\n",
       "        0.1845, 0.0784, 0.0302, 0.0403, 0.0080, 0.1847, 0.1957, 0.1100, 0.0935,\n",
       "        0.1443, 0.0339, 0.1736, 0.0629, 0.1216, 0.0863, 0.1177, 0.0650, 0.1191,\n",
       "        0.1149, 0.3842, 0.2538, 0.1573, 0.1572, 0.1589, 0.0625, 0.2314, 0.1450,\n",
       "        0.0575, 0.0426, 0.0426, 0.0458, 0.2055, 0.2434, 0.1804, 0.0808, 0.2458,\n",
       "        0.2491, 0.0758, 0.0949, 0.1004, 0.0661, 0.2742, 0.2168, 0.0666, 0.0765,\n",
       "        0.2380])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_adv - x_test[ind])[:100].view(100, -1).norm(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_adv.cpu() - x_test[ind][:100]).view(100, -1).norm(2, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
