{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import foolbox\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from lib.dataset_utils import *\n",
    "from lib.mnist_model import *\n",
    "from lib.adv_model import *\n",
    "from lib.dknn_attack_v2 import DKNNAttackV2\n",
    "from lib.cwl2_attack import CWL2Attack\n",
    "from lib.dknn import DKNNL2\n",
    "from lib.knn_defense import *\n",
    "from lib.utils import *\n",
    "from lib.lip_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all random seeds\n",
    "seed = 2020\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid), (x_test, y_test) = load_mnist_all(\n",
    "    '/data', val_size=0.1, shuffle=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'mnist_basic.h5'\n",
    "# net = BasicModel()\n",
    "\n",
    "model_name = 'adv_mnist_exp6.h5'\n",
    "basic_net = BasicModel()\n",
    "config = {'epsilon': 0.3,\n",
    "          'num_steps': 40,\n",
    "          'step_size': 0.01,\n",
    "          'random_start': True,\n",
    "          'loss_func': 'xent'}\n",
    "net = PGDL2Model(basic_net, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicModel(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3))\n",
       "  (relu1): ReLU(inplace=True)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(6, 6), stride=(2, 2), padding=(3, 3))\n",
       "  (relu2): ReLU(inplace=True)\n",
       "  (conv3): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu3): ReLU(inplace=True)\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up model directory\n",
    "# save_dir = os.path.join(os.getcwd(), 'saved_models/mnist/')\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models/')\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "net = net.to(device)\n",
    "# if device == 'cuda':\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "#     cudnn.benchmark = True\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "# net = net.module\n",
    "net = net.basic_net\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers = ['conv1', 'conv2', 'conv3']\n",
    "knn = CVPR_Defense(net, x_train, y_train, layers, \n",
    "                   k=50, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.968\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = knn.get_output(x_test)\n",
    "    ind = np.where(y_pred.argmax(1) == y_test.numpy())[0]\n",
    "    print((y_pred.argmax(1) == y_test.numpy()).sum() / y_test.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_batch(attack, x, y, init_mode, init_mode_k, batch_size):\n",
    "    x_adv = torch.zeros_like(x)\n",
    "    total_num = x.size(0)\n",
    "    num_batches = total_num // batch_size\n",
    "    for i in range(num_batches):\n",
    "        begin = i * batch_size\n",
    "        end = (i + 1) * batch_size\n",
    "        x_adv[begin:end] = attack(\n",
    "            x[begin:end], y[begin:end], 2, m=200,\n",
    "            init_mode=init_mode, init_mode_k=init_mode_k,\n",
    "            binary_search_steps=10, max_iterations=1000, learning_rate=1e-1,\n",
    "            initial_const=1e-2, max_linf=None, random_start=True,\n",
    "            thres_steps=200, check_adv_steps=200, verbose=False)\n",
    "    return x_adv\n",
    "\n",
    "num = 100\n",
    "\n",
    "def full_eval(knn):\n",
    "    with torch.no_grad():\n",
    "        y_pred = knn.get_output(x_test)\n",
    "        ind = np.where(y_pred.argmax(1) == y_test.numpy())[0]\n",
    "    print((y_pred.argmax(1) == y_test.numpy()).sum() / y_test.size(0))\n",
    "    \n",
    "    dist_all = np.zeros(num) + 1e9\n",
    "    attack = CVPR_Attack(knn)\n",
    "    \n",
    "    x_adv = attack_batch(\n",
    "        attack, x_test[ind][:num].cuda(), y_test[ind][:num], 1, 1, 100)\n",
    "    with torch.no_grad():\n",
    "        y_pred = knn.get_output(x_adv)\n",
    "        ind_adv = y_pred.argmax(1) != y_test[ind][:num].numpy()\n",
    "        dist = (x_adv.cpu() - x_test[ind][:num]).view(\n",
    "            num, -1).norm(2, 1).numpy()\n",
    "    for i in range(num):\n",
    "        if ind_adv[i] and (dist[i] < dist_all[i]):\n",
    "            dist_all[i] = dist[i]\n",
    "            \n",
    "    for k in range(1, 6):\n",
    "        x_adv = attack_batch(\n",
    "            attack, x_test[ind][:num].cuda(), y_test[ind][:num], 2, k, 100)\n",
    "        with torch.no_grad():\n",
    "            y_pred = knn.get_output(x_adv)\n",
    "            ind_adv = y_pred.argmax(1) != y_test[ind][:num].numpy()\n",
    "            dist = (x_adv.cpu() - x_test[ind][:num]).view(\n",
    "                num, -1).norm(2, 1).numpy()\n",
    "        for i in range(num):\n",
    "            if ind_adv[i] and (dist[i] < dist_all[i]):\n",
    "                dist_all[i] = dist[i]\n",
    "                \n",
    "    adv_acc = (dist_all == 1e9).mean()\n",
    "    print('adv accuracy: %.4f, mean dist: %.4f' % (\n",
    "        adv_acc, dist_all[dist_all < 1e9].mean()))\n",
    "    return dist_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.968\n",
      "adv accuracy: 0.0000, mean dist: 2.3979\n",
      "654.7994983196259\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dist = full_eval(knn)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attack = DKNNAttackV2(dknn)\n",
    "num = 100\n",
    "x_adv = attack_batch(\n",
    "    attack, x_test[ind][:num].cuda(), y_test[ind][:num], 1, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adv accuracy: 0.1600, mean dist: 3.4508\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = knn.get_output(x_adv)\n",
    "    ind_adv = np.where(y_pred.argmax(1) != y_test[ind][:num].numpy())[0]\n",
    "    adv_acc = (y_pred.argmax(1) == y_test[ind][:num].numpy()).sum() \\\n",
    "        / y_pred.shape[0]\n",
    "    dist = (x_adv.cpu() - x_test[ind][:num]).view(\n",
    "        num, -1).norm(2, 1)[ind_adv].mean()\n",
    "print('adv accuracy: %.4f, mean dist: %.4f' % (adv_acc, dist.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    step: 0; loss: 1.563; dist: 0.033\n",
      "    step: 100; loss: 1.497; dist: 0.279\n",
      "    step: 200; loss: 1.497; dist: 0.287\n",
      "    step: 300; loss: 1.497; dist: 0.291\n",
      "    step: 400; loss: 1.498; dist: 0.291\n",
      "    step: 500; loss: 1.498; dist: 0.293\n",
      "    step: 600; loss: 1.498; dist: 0.294\n",
      "    step: 700; loss: 1.497; dist: 0.294\n",
      "    step: 800; loss: 1.497; dist: 0.293\n",
      "    step: 900; loss: 1.497; dist: 0.295\n",
      "binary step: 0; num successful adv: 2/100\n",
      "binary step: 0; num successful adv so far: 2/100\n",
      "    step: 0; loss: 15.615; dist: 0.032\n",
      "    step: 100; loss: 8.965; dist: 1.732\n",
      "    step: 200; loss: 8.926; dist: 1.739\n",
      "    step: 300; loss: 8.907; dist: 1.745\n",
      "    step: 400; loss: 8.908; dist: 1.742\n",
      "    step: 500; loss: 8.907; dist: 1.743\n",
      "    step: 600; loss: 8.903; dist: 1.754\n",
      "    step: 700; loss: 8.906; dist: 1.740\n",
      "    step: 800; loss: 8.903; dist: 1.739\n",
      "    step: 900; loss: 8.893; dist: 1.730\n",
      "binary step: 1; num successful adv: 5/100\n",
      "binary step: 1; num successful adv so far: 7/100\n",
      "    step: 0; loss: 154.108; dist: 0.032\n",
      "    step: 100; loss: 32.968; dist: 3.222\n",
      "    step: 200; loss: 32.487; dist: 3.170\n",
      "    step: 300; loss: 32.311; dist: 3.161\n",
      "    step: 400; loss: 32.368; dist: 3.182\n",
      "    step: 500; loss: 32.214; dist: 3.181\n",
      "    step: 600; loss: 32.306; dist: 3.184\n",
      "    step: 700; loss: 32.292; dist: 3.177\n",
      "    step: 800; loss: 32.222; dist: 3.186\n",
      "    step: 900; loss: 32.167; dist: 3.180\n",
      "binary step: 2; num successful adv: 52/100\n",
      "binary step: 2; num successful adv so far: 54/100\n",
      "    step: 0; loss: 675.594; dist: 0.032\n",
      "    step: 100; loss: 95.356; dist: 3.723\n",
      "    step: 200; loss: 93.176; dist: 3.663\n",
      "    step: 300; loss: 92.583; dist: 3.649\n",
      "    step: 400; loss: 92.347; dist: 3.662\n",
      "    step: 500; loss: 92.016; dist: 3.661\n",
      "    step: 600; loss: 91.945; dist: 3.657\n",
      "    step: 700; loss: 92.110; dist: 3.667\n",
      "    step: 800; loss: 91.478; dist: 3.658\n",
      "    step: 900; loss: 91.681; dist: 3.661\n",
      "binary step: 3; num successful adv: 54/100\n",
      "binary step: 3; num successful adv so far: 71/100\n",
      "    step: 0; loss: 3593.132; dist: 0.033\n",
      "    step: 100; loss: 381.474; dist: 3.905\n",
      "    step: 200; loss: 373.358; dist: 3.889\n",
      "    step: 300; loss: 369.485; dist: 3.899\n",
      "    step: 400; loss: 368.667; dist: 3.891\n",
      "    step: 500; loss: 367.477; dist: 3.885\n",
      "    step: 600; loss: 366.816; dist: 3.915\n",
      "    step: 700; loss: 366.902; dist: 3.938\n",
      "    step: 800; loss: 365.431; dist: 3.911\n",
      "    step: 900; loss: 364.738; dist: 3.929\n",
      "binary step: 4; num successful adv: 51/100\n",
      "binary step: 4; num successful adv so far: 76/100\n",
      "    step: 0; loss: 29906.818; dist: 0.032\n",
      "    step: 100; loss: 3179.342; dist: 3.917\n",
      "    step: 200; loss: 3105.329; dist: 3.921\n",
      "    step: 300; loss: 3079.744; dist: 3.935\n",
      "    step: 400; loss: 3065.832; dist: 3.959\n",
      "    step: 500; loss: 3055.556; dist: 3.977\n",
      "    step: 600; loss: 3049.337; dist: 3.993\n",
      "    step: 700; loss: 3042.682; dist: 4.001\n",
      "    step: 800; loss: 3041.949; dist: 3.982\n",
      "    step: 900; loss: 3038.379; dist: 4.009\n",
      "binary step: 5; num successful adv: 45/100\n",
      "binary step: 5; num successful adv so far: 78/100\n",
      "    step: 0; loss: 288273.781; dist: 0.032\n",
      "    step: 100; loss: 31235.502; dist: 3.907\n",
      "    step: 200; loss: 30443.125; dist: 3.906\n",
      "    step: 300; loss: 30192.574; dist: 3.941\n",
      "    step: 400; loss: 30057.398; dist: 3.948\n",
      "    step: 500; loss: 30008.504; dist: 3.980\n",
      "    step: 600; loss: 29974.469; dist: 3.965\n",
      "    step: 700; loss: 29865.379; dist: 4.005\n",
      "    step: 800; loss: 29858.877; dist: 4.009\n",
      "    step: 900; loss: 29813.523; dist: 4.034\n",
      "binary step: 6; num successful adv: 47/100\n",
      "binary step: 6; num successful adv so far: 81/100\n",
      "    step: 0; loss: 2542926.750; dist: 0.032\n",
      "    step: 100; loss: 265461.062; dist: 3.882\n",
      "    step: 200; loss: 258915.391; dist: 3.918\n",
      "    step: 300; loss: 257612.594; dist: 3.922\n",
      "    step: 400; loss: 255779.547; dist: 3.926\n",
      "    step: 500; loss: 254972.156; dist: 3.969\n",
      "    step: 600; loss: 255062.859; dist: 3.958\n",
      "    step: 700; loss: 254635.953; dist: 3.958\n",
      "    step: 800; loss: 254047.641; dist: 3.966\n",
      "    step: 900; loss: 254047.375; dist: 3.998\n",
      "binary step: 7; num successful adv: 46/100\n",
      "binary step: 7; num successful adv so far: 84/100\n",
      "    step: 0; loss: 22912138.000; dist: 0.032\n",
      "    step: 100; loss: 2563617.500; dist: 3.893\n",
      "    step: 200; loss: 2505197.500; dist: 3.905\n",
      "    step: 300; loss: 2482040.500; dist: 3.914\n",
      "    step: 400; loss: 2474682.250; dist: 3.929\n",
      "    step: 500; loss: 2465182.250; dist: 3.954\n",
      "    step: 600; loss: 2464327.250; dist: 3.934\n",
      "    step: 700; loss: 2461386.500; dist: 3.986\n",
      "    step: 800; loss: 2451748.500; dist: 3.970\n",
      "    step: 900; loss: 2450736.500; dist: 3.994\n",
      "binary step: 8; num successful adv: 40/100\n",
      "binary step: 8; num successful adv so far: 84/100\n",
      "    step: 0; loss: 227600336.000; dist: 0.032\n",
      "    step: 100; loss: 25542838.000; dist: 3.866\n",
      "    step: 200; loss: 24971596.000; dist: 3.880\n",
      "    step: 300; loss: 24663216.000; dist: 3.927\n",
      "    step: 400; loss: 24608502.000; dist: 3.933\n",
      "    step: 500; loss: 24519060.000; dist: 3.930\n",
      "    step: 600; loss: 24510264.000; dist: 3.966\n",
      "    step: 700; loss: 24445076.000; dist: 3.967\n",
      "    step: 800; loss: 24444754.000; dist: 3.978\n",
      "    step: 900; loss: 24402084.000; dist: 3.983\n",
      "binary step: 9; num successful adv: 44/100\n",
      "binary step: 9; num successful adv so far: 84/100\n"
     ]
    }
   ],
   "source": [
    "attack = CVPR_Attack(knn)\n",
    "num = 100\n",
    "x_adv = attack(\n",
    "    x_test[ind][:num].cuda(), y_test[ind][:num], 2, m=100,\n",
    "    init_mode=1, init_mode_k=1,\n",
    "    binary_search_steps=10, max_iterations=1000, learning_rate=1e-1,\n",
    "    initial_const=1e-2, max_linf=None, random_start=True,\n",
    "    thres_steps=1000, check_adv_steps=1000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.6985"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
